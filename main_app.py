# program_merged.py - æ•´åˆç‰ˆ AI ç­–ç•¥åˆ†æèˆ‡å¸‚å ´åˆ†æå¹³å°
# æ•´åˆäº†ï¼š
# 1. ä¾†è‡ª program.py çš„å¸‚å ´åˆ†æå„€è¡¨æ¿ã€Gemini AI æ–°èåˆ†æã€å€‹è‚¡æ·±åº¦å ±å‘Šå’Œè‡ªå‹•åŒ–æ’ç¨‹ä»»å‹™
# 2. ä¾†è‡ª stock_ga_web.py çš„ä½¿ç”¨è€…èªè­‰ç³»çµ±ã€ç­–ç•¥è¨“ç·´å™¨ã€æ‰‹å‹•å›æ¸¬å’Œç­–ç•¥æ¸…å–®åŠŸèƒ½

import os
import logging
import re
import json
from datetime import datetime, timedelta, date
from flask import Flask, request, jsonify, render_template, send_from_directory, redirect, url_for
from flask_cors import CORS
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import csv
# === å¾ stock_ga_web.py ç§»æ¤ï¼šä½¿ç”¨è€…èªè­‰èˆ‡è³‡æ–™åº«ç›¸é—œæ¨¡çµ„ ===
from flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user
from werkzeug.security import generate_password_hash, check_password_hash
import traceback

# Google Gemini AI
try:
    from google import genai
    from google.genai import types as genai_types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# è³‡æ–™åº«é€£æ¥
import pymysql

# ğŸ†• æ–°å¢ï¼šæ’ç¨‹ã€æ™‚å€ã€æ™‚é–“èˆ‡è¿½è¹¤æ¨¡çµ„
from apscheduler.schedulers.background import BackgroundScheduler
import pytz
import atexit
import time
import traceback

# ==============================================================================
# >>> (æ–°æ•´åˆ) æ–°èæƒ…ç·’åˆ†ææ‰€éœ€æ¨¡çµ„ <<<
# ==============================================================================
import feedparser
import urllib.parse
import random

# FinBERT ç›¸é—œå‡½å¼åº« (è»Ÿæ€§ä¾è³´)
try:
    import torch
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    FINBERT_AVAILABLE = True
except ImportError:
    FINBERT_AVAILABLE = False

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å»ºç«‹Flaskæ‡‰ç”¨
app = Flask(__name__)
CORS(app)

# === å¾ stock_ga_web.py ç§»æ¤ï¼šFlask-Login è¨­å®š ===
app.secret_key = os.getenv('SECRET_KEY', os.urandom(24))
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login_page'
login_manager.login_message = "è«‹å…ˆç™»å…¥ä»¥è¨ªå•æ­¤é é¢ã€‚"
login_manager.login_message_category = "info"

# ğŸ†• æ–°å¢ï¼šå°å…¥å›æ¸¬å¼•æ“æ¨¡çµ„ (å®‰å…¨æª¢æŸ¥)
try:
    from ga_engine import (
        ga_load_data, ga_precompute_indicators, run_strategy_numba_core,
        format_ga_gene_parameters_to_text, STRATEGY_CONFIG_SHARED_GA,
        GA_PARAMS_CONFIG, GENE_MAP, check_ga_buy_signal_at_latest_point
    )
    from ga_engine_b import (
        load_stock_data_b, precompute_indicators_b, run_strategy_numba_core_b,
        format_gene_parameters_to_text_b, STRATEGY_CONFIG_B,GA_PARAMS_CONFIG_B
    )
    # === å¾ stock_ga_web.py ç§»æ¤ï¼šGA å¼•æ“é¡å¤–åŠŸèƒ½ ===
    from ga_engine import genetic_algorithm_unified
    from ga_engine_b import genetic_algorithm_unified_b, run_strategy_b
    from utils import execute_db_query, calculate_performance_metrics, calc_trade_extremes
    
    ENGINES_IMPORTED = True
    logger.info("âœ… æˆåŠŸå°å…¥æ‰€æœ‰å¿…è¦çš„å›æ¸¬å¼•æ“æ¨¡çµ„ã€‚")
except ImportError as e:
    logger.error(f"âŒ å°å…¥å›æ¸¬å¼•æ“æ¨¡çµ„å¤±æ•—: {e}ã€‚æ’ç¨‹å›æ¸¬åŠŸèƒ½å°‡è¢«ç¦ç”¨ã€‚")
    ENGINES_IMPORTED = False

# è³‡æ–™åº«è¨­å®š
DB_CONFIG = {
    'host': os.getenv("DB_HOST", "localhost"),
    'user': os.getenv("DB_USER", "root"),
    'password': os.getenv("DB_PASSWORD"),
    'database': os.getenv("DB_NAME", "finsimu_db"),
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor,
    'connect_timeout': 15
}

# Gemini AI è¨­å®š
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
gemini_client = None

# å®‰å…¨è¨­å®š
safety_settings_gemini = []
if GEMINI_API_KEY and GEMINI_AVAILABLE:
    try:
        gemini_client = genai.Client(api_key=GEMINI_API_KEY)
        safety_settings_gemini = [
            genai_types.SafetySetting(
                category="HARM_CATEGORY_HARASSMENT",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_HATE_SPEECH",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_DANGEROUS_CONTENT",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            )
        ]
        logger.info("Gemini AI å®¢æˆ¶ç«¯å·²æˆåŠŸé…ç½®")
    except Exception as e:
        logger.error(f"é…ç½® Gemini AI å¤±æ•—: {e}")

def log_new_ticker_to_csv(ticker: str, market: str):
    """
    æª¢æŸ¥ä¸¦è¨˜éŒ„æ–°çš„è‚¡ç¥¨ä»£è™Ÿåˆ°å°æ‡‰çš„ CSV æª”æ¡ˆä¸­ã€‚(ç©©å¥ç‰ˆ)
    - ticker: ç¶“éé©—è­‰çš„å®Œæ•´è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚ 'AAPL', '2330.TW')
    - market: 'US' æˆ– 'TW'
    """
    try:
        if market == 'TW':
            filepath = 'tw_stock.csv'
            header_name = 'è‚¡ç¥¨ä»£è™Ÿ'
        elif market == 'US':
            filepath = 'usa_stock.csv'
            header_name = 'Symbol'
        else:
            logger.warning(f"[Ticker Logging] æœªçŸ¥çš„å¸‚å ´é¡å‹ '{market}'ï¼Œè·³éè¨˜éŒ„ '{ticker}'ã€‚")
            return

        file_exists = os.path.exists(filepath)
        existing_tickers = set()

        # è®€å–ç¾æœ‰ä»£è™Ÿä»¥é¿å…é‡è¤‡
        if file_exists and os.path.getsize(filepath) > 0:
            try:
                df = pd.read_csv(filepath, encoding='utf-8-sig')
                if header_name in df.columns:
                    existing_tickers = set(df[header_name].astype(str).str.strip())
            except pd.errors.EmptyDataError:
                logger.warning(f"[Ticker Logging] CSV æª”æ¡ˆ '{filepath}' ç‚ºç©ºã€‚")
            except Exception as e:
                logger.error(f"[Ticker Logging] è®€å– CSV '{filepath}' å¤±æ•—: {e}")
                return

        # å¦‚æœä»£è™Ÿä¸å­˜åœ¨ï¼Œå‰‡ä½¿ç”¨ pandas å°‡å…¶é™„åŠ åˆ°æª”æ¡ˆä¸­
        if ticker not in existing_tickers:
            logger.info(f"[Ticker Logging] ç™¼ç¾æ–°ä»£è™Ÿ '{ticker}'ï¼Œå¯«å…¥ '{filepath}'...")
            try:
                # å‰µå»ºä¸€å€‹åªåŒ…å«æ–°ä»£è™Ÿçš„ DataFrame
                new_ticker_df = pd.DataFrame([{header_name: ticker}])
                
                # ä½¿ç”¨ to_csv çš„é™„åŠ æ¨¡å¼ ('a') é€²è¡Œå¯«å…¥
                # header=not file_exists: åªæœ‰åœ¨æª”æ¡ˆä¸å­˜åœ¨æ™‚æ‰å¯«å…¥æ¨™é ­
                # index=False: ä¸å¯«å…¥ DataFrame çš„ç´¢å¼•
                new_ticker_df.to_csv(
                    filepath, 
                    mode='a', 
                    header=not file_exists or os.path.getsize(filepath) == 0,
                    index=False, 
                    encoding='utf-8-sig'
                )
                logger.info(f"âœ… [Ticker Logging] å·²æˆåŠŸå°‡ '{ticker}' æ·»åŠ åˆ° '{filepath}'ã€‚")
            except Exception as e:
                logger.error(f"âŒ [Ticker Logging] å¯«å…¥æª”æ¡ˆ '{filepath}' å¤±æ•—: {e}")

    except Exception as e:
        logger.error(f"âŒ [Ticker Logging] è¨˜éŒ„æ–°è‚¡ç¥¨ä»£è™Ÿæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")

# === å¾ stock_ga_web.py ç§»æ¤ï¼šUser é¡åˆ¥å’Œèªè­‰ç³»çµ± ===
class User(UserMixin):
    """ä¸€å€‹ç¬¦åˆ Flask-Login è¦æ±‚çš„ä½¿ç”¨è€…é¡åˆ¥"""
    def __init__(self, user_data):
        self.id = user_data['id']
        self.username = user_data['username']
        self.email = user_data['email']
        self.password_hash = user_data['password_hash']

@login_manager.user_loader
def load_user(user_id):
    """Flask-Login éœ€è¦é€™å€‹å‡½å¼ä¾†å¾ session ä¸­é‡æ–°è¼‰å…¥ä½¿ç”¨è€…ç‰©ä»¶"""
    user_data = execute_db_query("SELECT * FROM users WHERE id = %s", (user_id,), fetch_one=True)
    if user_data:
        return User(user_data)
    return None

# ==============================================================================
# >>> ä»¥ä¸‹ç‚ºåŸå§‹ program.py çš„å‡½å¼ (å®Œå…¨æœªä¿®æ”¹) <<<
# ==============================================================================

def format_market_cap(market_cap, currency='USD'):
    """æ ¼å¼åŒ–å¸‚å€¼é¡¯ç¤º"""
    if not market_cap:
        return 'æœªæä¾›'
    currency_symbol = {'USD': '$', 'TWD': 'NT$', 'EUR': 'â‚¬', 'JPY': 'Â¥'}.get(currency, currency)
    if market_cap >= 1e12:
        return f"{currency_symbol}{market_cap/1e12:.1f}å…†"
    elif market_cap >= 1e9:
        return f"{currency_symbol}{market_cap/1e9:.1f}B"
    elif market_cap >= 1e6:
        return f"{currency_symbol}{market_cap/1e6:.0f}M"
    else:
        return f"{currency_symbol}{market_cap:,.0f}"

def get_latest_vix():
    """ä½¿ç”¨ yfinance ç²å–æœ€æ–°çš„ VIX æŒ‡æ•¸"""
    try:
        vix_ticker = yf.Ticker("^VIX")
        hist = vix_ticker.history(period="5d")
        if not hist.empty:
            latest_vix = hist['Close'].iloc[-1]
            logger.info(f"æˆåŠŸç²å–æœ€æ–°VIXæŒ‡æ•¸: {latest_vix:.2f}")
            return round(latest_vix, 2)
        else:
            logger.warning("ç„¡æ³•ç²å–VIXæ­·å²æ•¸æ“šã€‚")
            return None
    except Exception as e:
        logger.error(f"ç²å–VIXæŒ‡æ•¸å¤±æ•—: {e}")
        return None

def get_latest_sentiment_from_csv(csv_path='2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv'):
    """å¾CSVæª”æ¡ˆè®€å–æœ€æ–°çš„å¸‚å ´æƒ…ç·’åˆ†æ•¸å’Œæ‘˜è¦"""
    try:
        if not os.path.exists(csv_path):
            logger.warning(f"æƒ…ç·’åˆ†æCSVæª”æ¡ˆä¸å­˜åœ¨: {csv_path}")
            return None, None
        df = pd.read_csv(csv_path)
        if not df.empty:
            if 'æƒ…ç·’åˆ†æ•¸' in df.columns and 'é‡å¤§æ–°èæ‘˜è¦' in df.columns:
                latest_sentiment = df.iloc[-1]
                score = latest_sentiment['æƒ…ç·’åˆ†æ•¸']
                summary = latest_sentiment['é‡å¤§æ–°èæ‘˜è¦']
                logger.info(f"æˆåŠŸå¾CSVç²å–æœ€æ–°æƒ…ç·’åˆ†æ•¸: {score}")
                return score, summary
            else:
                logger.warning("CSVæª”æ¡ˆä¸­ç¼ºå°‘ 'æƒ…ç·’åˆ†æ•¸' æˆ– 'é‡å¤§æ–°èæ‘˜è¦' æ¬„ä½ã€‚")
                return None, None
        else:
            logger.warning("æƒ…ç·’åˆ†æCSVæª”æ¡ˆç‚ºç©ºã€‚")
            return None, None
    except Exception as e:
        logger.error(f"è®€å–æƒ…ç·’åˆ†æCSVå¤±æ•—: {e}")
        return None, None

class EnhancedStockAnalyzer:
    """å¢å¼·ç‰ˆè‚¡ç¥¨åˆ†æå™¨ - æ•´åˆåŸºæœ¬é¢ã€æŠ€è¡“é¢èˆ‡AIç­–ç•¥"""
    def __init__(self, ticker: str):
        self.ticker_input = ticker.strip().upper()
        # æˆ‘å€‘ä¸å†å¼·åˆ¶é è¨­å¾Œç¶´ï¼Œè®“ get_basic_stock_data å‡½å¼å»æ™ºæ…§åˆ¤æ–·
        self.ticker = self.ticker_input 
        self.market = "US" # é è¨­ç‚ºç¾è‚¡
        
        # åƒ…åšåˆæ­¥çš„å¸‚å ´é¡å‹åˆ¤æ–·ï¼Œå¯¦éš›æœ‰æ•ˆçš„ ticker å°‡åœ¨ç²å–æ•¸æ“šæ™‚ç¢ºèª
        if self.ticker.endswith(".TW") or self.ticker.endswith(".TWO"):
            self.market = "TW"
        elif re.fullmatch(r'\d{4,6}', self.ticker):
            # å¦‚æœæ˜¯æ•¸å­—ä»£ç¢¼ï¼Œæš«æ™‚æ¨™è¨˜ç‚ºå°è‚¡ï¼Œç­‰å¾…å¾ŒçºŒç¢ºèª
            self.market = "TW"
        
        logger.info(f"åˆå§‹åŒ–å¢å¼·åˆ†æå™¨ï¼š{self.ticker_input} (å¸‚å ´ï¼š{self.market})")

    # æ‰¾åˆ°ä¸¦æ›¿æ› EnhancedStockAnalyzer çš„ get_basic_stock_data å‡½å¼
    def get_basic_stock_data(self):
        """ç²å–åŸºæœ¬è‚¡ç¥¨æ•¸æ“š - å¢å¼·ç‰ˆ (æ•´åˆ.TW/.TWOè‡ªå‹•é‡è©¦)"""
        try:
            # <<<<<<< é€™è£¡æ˜¯æ–°çš„æ™ºæ…§é‡è©¦é‚è¼¯ >>>>>>>
            is_tw_stock_code = re.fullmatch(r'\d{4,6}[A-Z]?', self.ticker_input)
            stock = None
            hist_data = pd.DataFrame() # åˆå§‹åŒ–ä¸€å€‹ç©ºçš„ DataFrame

            if is_tw_stock_code:
                logger.info(f"åµæ¸¬åˆ°å°è‚¡æ•¸å­—ä»£è™Ÿ {self.ticker_input}ï¼Œå°‡ä¾åºå˜—è©¦ .TW å’Œ .TWO å¾Œç¶´ã€‚")
                for suffix in ['.TW', '.TWO']:
                    potential_ticker = f"{self.ticker_input}{suffix}"
                    logger.info(f"æ­£åœ¨å˜—è©¦ä½¿ç”¨ {potential_ticker}...")
                    try:
                        temp_stock = yf.Ticker(potential_ticker)
                        temp_hist = temp_stock.history(period="1y")
                        if not temp_hist.empty:
                            logger.info(f"æˆåŠŸä½¿ç”¨ {potential_ticker} ç²å–æ•¸æ“šã€‚")
                            self.ticker = potential_ticker  # é‡è¦ï¼šæ›´æ–°é¡åˆ¥å¯¦ä¾‹ä¸­æœ‰æ•ˆçš„ ticker
                            self.market = "TW"
                            stock = temp_stock
                            hist_data = temp_hist
                            break  # æˆåŠŸæ‰¾åˆ°æ•¸æ“šï¼Œè·³å‡ºè¿´åœˆ
                    except Exception:
                        logger.warning(f"å˜—è©¦ {potential_ticker} å¤±æ•—ï¼Œç¹¼çºŒä¸‹ä¸€å€‹ã€‚")
                        continue
            
            # å¦‚æœä¸æ˜¯å°è‚¡ä»£è™Ÿï¼Œæˆ–æ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—ï¼Œå‰‡åŸ·è¡ŒåŸå§‹é‚è¼¯
            if stock is None:
                logger.info(f"åŸ·è¡Œæ¨™æº–æŸ¥è©¢ï¼š{self.ticker}")
                stock = yf.Ticker(self.ticker)
                hist_data = stock.history(period="1y")

            # åœ¨æ‰€æœ‰å˜—è©¦å¾Œï¼Œæœ€çµ‚æª¢æŸ¥æ•¸æ“šæ˜¯å¦ç‚ºç©º
            if hist_data.empty:
                raise ValueError(f"ç„¡æ³•ç²å– {self.ticker_input} çš„æ­·å²æ•¸æ“š (å·²å˜—è©¦ .TW å’Œ .TWO)")
            # <<<<<<< æ™ºæ…§é‡è©¦é‚è¼¯çµæŸ >>>>>>>

            info = stock.info
            current_price = hist_data['Close'].iloc[-1]
            prev_close = hist_data['Close'].iloc[-2] if len(hist_data) >= 2 else current_price
            change = current_price - prev_close
            change_pct = (change / prev_close * 100) if prev_close != 0 else 0
            
            change_str = f"{change:+.2f}"
            change_pct_str = f"{change_pct:+.2f}%"
            price_change_str = f"{change_str} ({change_pct_str})"
            
            return {
                "success": True, "ticker": self.ticker, 
                "company_name": info.get('longName', info.get('shortName', self.ticker)),
                "market": self.market, "current_price": round(float(current_price), 2), 
                "price_change": round(float(change), 2),
                "price_change_pct": round(float(change_pct), 2), 
                "price_change_str": price_change_str,
                "currency": info.get('currency', 'TWD' if self.market == 'TW' else 'USD'), 
                "market_cap": info.get('marketCap'),
                "pe_ratio": round(info.get('trailingPE'), 2) if info.get('trailingPE') else None,
                "forward_pe": round(info.get('forwardPE'), 2) if info.get('forwardPE') else None,
                "eps": round(info.get('trailingEps'), 2) if info.get('trailingEps') else None,
                "roe": round(info.get('returnOnEquity'), 4) if info.get('returnOnEquity') else None,
                "dividend_yield": round(info.get('dividendYield'), 4) if info.get('dividendYield') else None,
                "beta": round(info.get('beta'), 2) if info.get('beta') else None,
                "price_to_book": round(info.get('priceToBook'), 2) if info.get('priceToBook') else None,
                "debt_to_equity": round(info.get('debtToEquity'), 2) if info.get('debtToEquity') else None,
                "volume": int(hist_data['Volume'].iloc[-1]) if not pd.isna(hist_data['Volume'].iloc[-1]) else 0,
                "day_high": round(float(hist_data['High'].iloc[-1]), 2), 
                "day_low": round(float(hist_data['Low'].iloc[-1]), 2),
                "year_high": round(float(hist_data['High'].max()), 2), 
                "year_low": round(float(hist_data['Low'].min()), 2),
                "historical_data": hist_data, 
                "analysis_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        except Exception as e:
            logger.error(f"ç²å–åŸºæœ¬è‚¡ç¥¨æ•¸æ“šå¤±æ•—ï¼š{e}")
            # æä¾›æ›´æ˜ç¢ºçš„éŒ¯èª¤è¨Šæ¯
            error_message = f"ç„¡æ³•ç²å–è‚¡ç¥¨ {self.ticker_input} çš„æ•¸æ“šã€‚è«‹æª¢æŸ¥ä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚å°æ–¼å°è‚¡ï¼Œæˆ‘å€‘å·²è‡ªå‹•å˜—è©¦ .TW å’Œ .TWO å¾Œç¶´ã€‚éŒ¯èª¤è©³æƒ…: {e}"
            return {"success": False, "error": error_message}

    def get_technical_indicators(self, hist_data):
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
        try:
            close_prices = hist_data['Close']
            ma_5 = close_prices.rolling(window=5).mean().iloc[-1] if len(close_prices) >= 5 else None
            ma_10 = close_prices.rolling(window=10).mean().iloc[-1] if len(close_prices) >= 10 else None
            ma_20 = close_prices.rolling(window=20).mean().iloc[-1] if len(close_prices) >= 20 else None
            ma_60 = close_prices.rolling(window=60).mean().iloc[-1] if len(close_prices) >= 60 else None
            ma_120 = close_prices.rolling(window=120).mean().iloc[-1] if len(close_prices) >= 120 else None
            
            delta = close_prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            current_rsi = rsi.iloc[-1] if len(rsi) >= 14 else None
            
            bb_period = 20
            bb_std = 2
            if len(close_prices) >= bb_period:
                bb_middle = close_prices.rolling(window=bb_period).mean()
                bb_std_dev = close_prices.rolling(window=bb_period).std()
                bb_upper = bb_middle + (bb_std_dev * bb_std)
                bb_lower = bb_middle - (bb_std_dev * bb_std)
                bb_upper_val = bb_upper.iloc[-1]
                bb_lower_val = bb_lower.iloc[-1]
                bb_middle_val = bb_middle.iloc[-1]
            else:
                bb_upper_val = bb_lower_val = bb_middle_val = None
                
            def format_to_2_decimal(value):
                return round(float(value), 2) if value and not pd.isna(value) else None
                
            return {
                "ma_5": format_to_2_decimal(ma_5), "ma_10": format_to_2_decimal(ma_10), 
                "ma_20": format_to_2_decimal(ma_20),
                "ma_60": format_to_2_decimal(ma_60), "ma_120": format_to_2_decimal(ma_120), 
                "rsi": format_to_2_decimal(current_rsi),
                "bb_upper": format_to_2_decimal(bb_upper_val), 
                "bb_middle": format_to_2_decimal(bb_middle_val), 
                "bb_lower": format_to_2_decimal(bb_lower_val)
            }
        except Exception as e:
            logger.error(f"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™å¤±æ•—: {e}")
            return {}

    def get_ai_strategies_data(self):
        """ç²å–AIç­–ç•¥æ•¸æ“šï¼ˆå¾è³‡æ–™åº«è®€å–çœŸå¯¦å›æ¸¬æ—¥æœŸï¼‰- (ä¿®æ”¹ç‰ˆï¼šåªç²å– Rank 1)"""
        try:
            market_type = "TW" if self.market == "TW" else "US"
            common_fields = "ai_strategy_gene, strategy_rank, strategy_details, period_return_pct, max_drawdown_pct, win_rate_pct, total_trades, average_trade_return_pct, max_trade_drop_pct, max_trade_gain_pct, game_start_date, game_end_date"
            
            # <<<< ä¿®æ”¹é»ï¼šå°‡ LIMIT 3 æ”¹ç‚º LIMIT 1ï¼ŒåªæŠ“å–æ¯å€‹ç³»çµ±çš„æœ€ä½³ç­–ç•¥ >>>>
            system_a_query = f"SELECT {common_fields} FROM ai_vs_user_games WHERE user_id = 2 AND market_type = %s AND stock_ticker = %s ORDER BY strategy_rank ASC LIMIT 1"
            system_b_query = f"SELECT {common_fields} FROM ai_vs_user_games WHERE user_id = 3 AND market_type = %s AND stock_ticker = %s ORDER BY strategy_rank ASC LIMIT 1"
            
            system_a_strategies = execute_db_query(system_a_query, (market_type, self.ticker), fetch_all=True)
            system_b_strategies = execute_db_query(system_b_query, (market_type, self.ticker), fetch_all=True)
            
            start_date_str, end_date_str = "N/A", "N/A"
            first_strategy = (system_a_strategies or system_b_strategies or [None])[0]
            if first_strategy and first_strategy.get('game_start_date'):
                start_date_obj, end_date_obj = first_strategy['game_start_date'], first_strategy['game_end_date']
                if isinstance(start_date_obj, date): start_date_str = start_date_obj.strftime('%Y-%m-%d')
                if isinstance(end_date_obj, date): end_date_str = end_date_obj.strftime('%Y-%m-%d')
                
            return { 
                "system_a": system_a_strategies or [], "system_b": system_b_strategies or [], 
                "market_type": market_type,
                "backtest_start_date": start_date_str, "backtest_end_date": end_date_str,
                "backtest_period_description": f"å›æ¸¬æœŸé–“ï¼š{start_date_str} è‡³ {end_date_str}"
            }
        except Exception as e:
            logger.error(f"ç²å–AIç­–ç•¥æ•¸æ“šå¤±æ•—ï¼š{e}")
            return { 
                "system_a": [], "system_b": [], "market_type": "", 
                "backtest_start_date": "N/A", "backtest_end_date": "N/A", 
                "backtest_period_description": "å›æ¸¬æœŸé–“ï¼šç„¡æ³•ç²å–" 
            }
# åœ¨ main_app.py ä¸­æ–°å¢é€™å€‹å‡½å¼
# åœ¨ main_app.py ä¸­ï¼Œæ‰¾åˆ°ä¸¦å®Œæ•´æ›¿æ›é€™å€‹å‡½å¼

def create_backtest_chart_assets(ticker, system_type, rank, portfolio, prices, dates, buys, sells):
    """ç‚ºå›æ¸¬çµæœå‰µå»ºéœæ…‹PNGå’Œäº’å‹•HTMLï¼Œä¸¦è¿”å›URL - (æ–°å¢æ¸…æ™°åœ–ä¾‹)"""
    try:
        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, 
                          row_heights=[0.7, 0.3],
                          subplot_titles=(f'{ticker} åƒ¹æ ¼èµ°å‹¢èˆ‡äº¤æ˜“ä¿¡è™Ÿ', 'æŠ•è³‡çµ„åˆåƒ¹å€¼è®ŠåŒ–'))
        
        # è‚¡åƒ¹èˆ‡è²·è³£é»
        fig.add_trace(go.Scatter(
            x=dates, y=prices, mode='lines', name='æ”¶ç›¤åƒ¹', 
            line=dict(color='rgba(102, 126, 234, 0.7)')
        ), row=1, col=1)
        
        if buys:
            fig.add_trace(go.Scatter(
                x=[s['date'] for s in buys], y=[s['price'] for s in buys], 
                mode='markers', 
                # <<<<<<< è®Šæ›´é» 1: ç‚ºè²·å…¥ä¿¡è™Ÿå‘½å >>>>>>>
                name='è²·å…¥ä¿¡è™Ÿ', 
                marker=dict(symbol='triangle-up', size=10, color='#27AE60', line=dict(width=1, color='white'))
            ), row=1, col=1)
        
        if sells:
            fig.add_trace(go.Scatter(
                x=[s['date'] for s in sells], y=[s['price'] for s in sells], 
                mode='markers', 
                # <<<<<<< è®Šæ›´é» 2: ç‚ºè³£å‡ºä¿¡è™Ÿå‘½å >>>>>>>
                name='è³£å‡ºä¿¡è™Ÿ', 
                marker=dict(symbol='triangle-down', size=10, color='#E74C3C', line=dict(width=1, color='white'))
            ), row=1, col=1)

        # æŠ•è³‡çµ„åˆåƒ¹å€¼
        if portfolio is not None and len(portfolio) > 0:
             fig.add_trace(go.Scatter(
                x=dates, y=portfolio, mode='lines', name='çµ„åˆåƒ¹å€¼', 
                line=dict(color='purple')
            ), row=2, col=1)

        # <<<<<<< è®Šæ›´é» 3: å•Ÿç”¨ä¸¦è¨­å®šåœ–ä¾‹æ¨£å¼ >>>>>>>
        fig.update_layout(
            template='plotly_white', 
            height=500, 
            margin=dict(l=40, r=20, t=50, b=30), 
            showlegend=True,  # <-- å•Ÿç”¨åœ–ä¾‹
            legend=dict(
                orientation="h",  # æ°´å¹³æ’åˆ—
                yanchor="bottom",
                y=1.03,           # æ”¾åœ¨åœ–è¡¨é ‚éƒ¨ä¹‹ä¸Š
                xanchor="right",
                x=1
            )
        )
        # <<<<<<< è®Šæ›´é»çµæŸ >>>>>>>
        
        base_filename = f"{ticker.replace('.', '_')}_{system_type}_Rank{rank}_backtest"
        
        # å„²å­˜éœæ…‹åœ–ç‰‡
        img_filename = f"{base_filename}.png"
        img_path = os.path.join('static/charts', img_filename)
        fig.write_image(img_path, scale=2)
        
        # å„²å­˜äº’å‹•HTML
        html_filename = f"{base_filename}.html"
        html_path = os.path.join('charts', html_filename)
        fig.write_html(html_path, include_plotlyjs='cdn', config={'displayModeBar': True})
        
        logger.info(f"å›æ¸¬åœ–è¡¨å·²ç”Ÿæˆï¼ˆå¸¶åœ–ä¾‹ï¼‰ï¼š{img_filename} å’Œ {html_filename}")
        return f"/static/charts/{img_filename}", f"/charts/{html_filename}"
        
    except Exception as e:
        logger.error(f"å‰µå»ºå›æ¸¬åœ–è¡¨å¤±æ•—: {e}")
        return None, None
    
def create_enhanced_stock_chart(ticker, company_name, hist_data):
    """å‰µå»ºè‚¡åƒ¹åœ–è¡¨ï¼ŒåŒæ™‚ç”Ÿæˆéœæ…‹PNGå’Œäº’å‹•HTML"""
    try:
        fig = make_subplots(rows=1, cols=1, shared_xaxes=True, vertical_spacing=0.06)
        
        fig.add_trace(go.Candlestick(
            x=hist_data.index, open=hist_data['Open'], high=hist_data['High'], 
            low=hist_data['Low'], close=hist_data['Close'], name=f'{ticker} è‚¡åƒ¹', 
            increasing_line_color='#26C6DA', decreasing_line_color='#EF5350'
        ), row=1, col=1)
        
        fig.update_layout(
            # ç§»é™¤åœ–è¡¨å…§çš„å¤§æ¨™é¡Œï¼Œè®“åœ–æ›´ä¹¾æ·¨
            template='plotly_white', height=500, 
            font=dict(family="Arial", size=12),
            margin=dict(l=40, r=20, t=20, b=30), # ç¸®å°é‚Šè·
            xaxis_rangeslider_visible=False,
            showlegend=False # æ‰‹æ©Ÿä¸Šé€šå¸¸ä¸é¡¯ç¤ºåœ–ä¾‹
        )
        
        base_filename = f"{ticker.replace('.', '_')}_stock_chart"
        
        # å„²å­˜éœæ…‹åœ–ç‰‡
        img_filename = f"{base_filename}.png"
        img_path = os.path.join('static/charts', img_filename)
        fig.write_image(img_path, scale=2) # scale=2 è®“åœ–ç‰‡æ›´æ¸…æ™°
        
        # å„²å­˜äº’å‹•HTML (ç§»é™¤Plotlyæ§åˆ¶æ¬„)
        html_filename = f"{base_filename}.html"
        html_path = os.path.join('charts', html_filename)
        fig.write_html(html_path, include_plotlyjs='cdn', config={'displayModeBar': True}) # åœ¨å…¨è¢å¹•æ¨¡å¼é¡¯ç¤ºæ§åˆ¶æ¬„
        
        logger.info(f"åœ–è¡¨å·²ç”Ÿæˆï¼š{img_filename} å’Œ {html_filename}")
        return f"/static/charts/{img_filename}", f"/charts/{html_filename}"
    
    except Exception as e:
        logger.error(f"å‰µå»ºåœ–è¡¨å¤±æ•—ï¼š{e}")
        return None, None

def generate_enhanced_news_analysis(stock_data, tech_indicators, strategies_data, latest_vix, latest_sentiment):
    """ä½¿ç”¨ Gemini AI ç”ŸæˆåŒ…å«æœ€æ–°æ–°èçš„æ·±åº¦åˆ†æå ±å‘Š - ğŸ”¥ å®Œæ•´æŒ‡æ¨™ç‰ˆæœ¬"""
    if not gemini_client:
        return "Gemini AI æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨"
    
    try:
        # ğŸ”¥ ä¿®æ”¹ï¼šæº–å‚™å®Œæ•´ç­–ç•¥æ•¸æ“šæ‘˜è¦
        system_a_summary = ""
        if strategies_data.get('system_a'):
            system_a_summary = "System A (28åŸºå› å¤šç­–ç•¥):\n"
            for strategy in strategies_data['system_a'][:3]:
                system_a_summary += f" Rank {strategy['strategy_rank']}:\n"
                system_a_summary += f" ğŸ“ˆ ç¸½å ±é…¬ç‡: {strategy.get('period_return_pct', 0):.2f}%\n"
                system_a_summary += f" ğŸ’° å¹³å‡äº¤æ˜“å ±é…¬: {strategy.get('average_trade_return_pct', 0):.3f}%\n"
                system_a_summary += f" ğŸ¯ å‹ç‡: {strategy.get('win_rate_pct', 0):.1f}%\n"
                system_a_summary += f" ğŸ”¢ äº¤æ˜“æ¬¡æ•¸: {strategy.get('total_trades', 0)}\n"
                system_a_summary += f" ğŸ“‰ æœ€å¤§å›æ’¤: {strategy.get('max_drawdown_pct', 0):.2f}%\n"
                system_a_summary += f" ğŸ“‰ æœ€å¤§è·Œå¹…: {strategy.get('max_trade_drop_pct', 0):.2f}%\n"
                system_a_summary += f" ğŸ“ˆ æœ€å¤§æ¼²å¹…: {strategy.get('max_trade_gain_pct', 0):.2f}%\n"
        
        system_b_summary = ""
        if strategies_data.get('system_b'):
            system_b_summary = "System B (10åŸºå› RSIç­–ç•¥):\n"
            for strategy in strategies_data['system_b'][:3]:
                system_b_summary += f" Rank {strategy['strategy_rank']}:\n"
                system_b_summary += f" ğŸ“ˆ ç¸½å ±é…¬ç‡: {strategy.get('period_return_pct', 0):.2f}%\n"
                system_b_summary += f" ğŸ’° å¹³å‡äº¤æ˜“å ±é…¬: {strategy.get('average_trade_return_pct', 0):.3f}%\n"
                system_b_summary += f" ğŸ¯ å‹ç‡: {strategy.get('win_rate_pct', 0):.1f}%\n"
                system_b_summary += f" ğŸ”¢ äº¤æ˜“æ¬¡æ•¸: {strategy.get('total_trades', 0)}\n"
                system_b_summary += f" ğŸ“‰ æœ€å¤§å›æ’¤: {strategy.get('max_drawdown_pct', 0):.2f}%\n"
                system_b_summary += f" ğŸ“‰ æœ€å¤§è·Œå¹…: {strategy.get('max_trade_drop_pct', 0):.2f}%\n"
                system_b_summary += f" ğŸ“ˆ æœ€å¤§æ¼²å¹…: {strategy.get('max_trade_gain_pct', 0):.2f}%\n"
        
        system_a_details = ""
        if strategies_data.get('system_a'):
            system_a_details = "System A (28åŸºå› å¤šç­–ç•¥):\n"
            for strategy in strategies_data['system_a'][:1]:
                system_a_details += f" Rank {strategy['strategy_rank']}:\n"
                system_a_details += f" ç­–ç•¥è©³æƒ…: {strategy.get('strategy_details')}\n"
        
        system_b_details = ""
        if strategies_data.get('system_b'):
            system_b_details = "System B (10åŸºå› RSIç­–ç•¥):\n"
            for strategy in strategies_data['system_b'][:1]:
                system_b_details += f" Rank {strategy['strategy_rank']}:\n"
                system_b_details += f" ç­–ç•¥è©³æƒ…: {strategy.get('strategy_details')}\n"
        
        # ğŸ†• æ–°å¢ï¼šå›æ¸¬æ™‚é–“è³‡è¨Š
        backtest_info = f"å›æ¸¬æœŸé–“: {strategies_data.get('backtest_start_date', 'N/A')} è‡³ {strategies_data.get('backtest_end_date', 'N/A')}"
        
        # æ§‹å»ºåŒ…å«æ–°èæŸ¥è©¢çš„æç¤ºè©
        prompt = f"""ä½ æ˜¯é ‚å°–çš„é‡åŒ–æŠ•è³‡åˆ†æå¸«ï¼Œè«‹ç‚ºè‚¡ç¥¨ {stock_data['company_name']} ({stock_data['ticker']}) æ’°å¯«ä¸€ä»½åŒ…å«æœ€æ–°æ–°èçš„æŠ•è³‡åˆ†æå ±å‘Šã€‚(ä¸è¦åŠ å…¥è‡ªæˆ‘ä»‹ç´¹åŠå•å€™)

è«‹å…ˆæœå°‹ä»¥ä¸‹é—œéµå­—çš„æœ€æ–°æ–°èï¼š
- "{stock_data['company_name']} stock news"
- "{stock_data['ticker']} adxã€ macdã€kdjä»Šæ—¥æŠ€è¡“æŒ‡æ¨™"
- "{stock_data['ticker']} earnings"
- "{stock_data['company_name']} financial results"
- "market news today"
- "{stock_data['ticker']} åŒæ¥­ç«¶çˆ­"

åŸºæœ¬é¢æ•¸æ“šï¼š
- ç•¶å‰è‚¡åƒ¹: {stock_data['current_price']:.2f} {stock_data['currency']}
- å¸‚å€¼: {format_market_cap(stock_data.get('market_cap'), stock_data['currency'])}
- æœ¬ç›Šæ¯”: {stock_data.get('pe_ratio', 'æœªæä¾›')}
- æ¯è‚¡ç›ˆé¤˜: {stock_data.get('eps', 'æœªæä¾›')}
- ROE: {f"{stock_data.get('roe', 0)*100:.2f}%" if stock_data.get('roe') else 'æœªæä¾›'}
- Betaå€¼: {stock_data.get('beta', 'æœªæä¾›')}

æŠ€è¡“æŒ‡æ¨™ï¼š
- RSI: {tech_indicators.get('rsi', 'æœªæä¾›')}
- 5æ—¥å‡ç·š: {tech_indicators.get('ma_5', 'æœªæä¾›')}
- 10æ—¥å‡ç·š: {tech_indicators.get('ma_10', 'æœªæä¾›')}
- 20æ—¥å‡ç·š: {tech_indicators.get('ma_20', 'æœªæä¾›')}
- 60æ—¥å‡ç·š: {tech_indicators.get('ma_60', 'æœªæä¾›')}
- 120æ—¥å‡ç·š: {tech_indicators.get('ma_120', 'æœªæä¾›')}
- å¸ƒæ—å¸¶ä¸Šè»Œ: {tech_indicators.get('bb_upper', 'æœªæä¾›')}
- å¸ƒæ—å¸¶ä¸‹è»Œ: {tech_indicators.get('bb_lower', 'æœªæä¾›')}

é‡åŒ–ç­–ç•¥å›æ¸¬çµæœï¼ˆ{backtest_info}ï¼‰ï¼š

ç­–ç•¥1è©³æƒ…:
{system_a_summary}
{system_a_details}

ç­–ç•¥2è©³æƒ…:
{system_b_summary}
{system_b_details}

è«‹åš´æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼æ’°å¯«åˆ†æå ±å‘Šï¼Œæ¯å€‹éƒ¨åˆ†éƒ½ä½¿ç”¨ç¨ç«‹çš„ `##` æ¨™é¡Œï¼š

##  æœ€æ–°æ–°èåˆ†æ
[æ ¹æ“šæœå°‹åˆ°çš„æœ€æ–°æ–°èåˆ†æå°è‚¡åƒ¹çš„å½±éŸ¿ï¼Œ100-120å­—]

##  åŸºæœ¬é¢åˆ†æ
[æœå°‹ä¸¦åˆ†æå…¬å¸è²¡å‹™é«”è³ªã€ç²åˆ©èƒ½åŠ›ã€ä¼°å€¼æ°´æº–ç­‰é‚„æœ‰åŒæ¥­æ¯”è¼ƒï¼Œ120-150å­—]

##  è¿‘æœŸè¶¨å‹¢
[æœå°‹ç¶²è·¯åŠåŸºæ–¼æŠ€è¡“æŒ‡æ¨™åˆ†æè‚¡åƒ¹è¶¨å‹¢ç­‰ï¼Œ60-100å­—]

##  ç­–ç•¥è§£è®€ (æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)(!!å¦‚æœè©²è‚¡ç¥¨æ²’æœ‰æä¾›ç­–ç•¥ï¼Œè«‹ç›´æ¥å›è¦†"æ­¤è‚¡ç¥¨ç›®å‰å°šç„¡è¨“ç·´å¥½ç­–ç•¥ï¼Œç³»çµ±å°‡è‡ªå‹•å°‡å…¶ç´å…¥ä¸‹ä¸€æ‰¹æ¬¡çš„è¨“ç·´æ¸…å–®ä¸­ã€‚"!!)
[è«‹åŸºæ–¼ä¸Šæ–¹æä¾›çš„ **ç­–ç•¥ 1** å’Œ **ç­–ç•¥ 2** çš„æ•¸æ“šï¼Œæ’°å¯«ä¸€ä»½å°ˆæ¥­åˆ†æ (100-200å­—)ã€‚è«‹å‹™å¿…éµå¾ªä»¥ä¸‹è¦é»ï¼š
- **ç¦æ­¢ä½¿ç”¨ 'System A' æˆ– 'System B' ç­‰å…§éƒ¨è¡“èª**ï¼Œåªèƒ½ç›´æ¥ä½¿ç”¨ "ç­–ç•¥ 1" å’Œ "ç­–ç•¥ 2 " ä¾†ç¨±å‘¼å®ƒå€‘ï¼Œä¸éœ€åŠ å…¥(28åŸºå› å¤šç­–ç•¥æˆ–10åŸºå› RSIç­–ç•¥ä½œè§£é‡‹)ã€‚
- **æ¯”è¼ƒè¡¨ç¾å·®ç•°**: åˆ†æå…©å¥—ç­–ç•¥çš„é¢¨éšªæ”¶ç›Šç‰¹å¾µã€‚å“ªä¸€å€‹çœ‹èµ·ä¾†æ›´ç©©å¥ï¼Ÿå“ªå€‹æ¯”è¼ƒå¥½ï¼Ÿç‚ºä»€éº¼ï¼Ÿ
- **è§£è®€é—œéµæŒ‡æ¨™**: æ ¹æ“šæä¾›çš„ã€Œç­–ç•¥è©³æƒ…ã€ï¼Œè§£è®€å®ƒå€‘åˆ†åˆ¥ä¾è³´å“ªäº›æ ¸å¿ƒæŠ€è¡“æŒ‡æ¨™ã€‚
- **é æ¸¬è¿‘æœŸä¿¡è™Ÿ**: çµåˆç•¶å‰æŠ€è¡“æŒ‡æ¨™ï¼Œæé†’è¿‘æœŸæ˜¯å¦å¯èƒ½å‡ºç¾è²·å…¥æˆ–è³£å‡ºä¿¡è™Ÿã€‚(ä¸è¦æåˆ°æœ‰æ•¸æ“šç¼ºå¤±çš„éƒ¨åˆ†ï¼Œè¬¹èªªæ˜æœ‰æ•¸æ“šæ”¯æŒçš„éƒ¨åˆ†å³å¯)]

VIX ææ…ŒæŒ‡æ•¸:{latest_vix if latest_vix is not None else 'æœªèƒ½ç²å–'} (è¨»ï¼šæŒ‡æ•¸è¶Šé«˜ï¼Œå¸‚å ´ææ…Œç¨‹åº¦è¶Šé«˜)
å¸‚å ´æƒ…ç·’åˆ†æ•¸:{latest_sentiment[0] if latest_sentiment and latest_sentiment[0] is not None else 'æœªèƒ½ç²å–'}

##  æŠ•è³‡æ©Ÿæœƒ (æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)
[åŸºæ–¼æ–°èã€åŸºæœ¬é¢ã€æŠ€è¡“é¢å’Œç­–ç•¥åˆ†æï¼Œåˆ—å‡º2-3é»ä¸»è¦æŠ•è³‡æ©Ÿæœƒã€‚](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)

 é¢¨éšªæé†’ (æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)
[åŸºæ–¼æ–°èã€åŸºæœ¬é¢ã€æŠ€è¡“é¢å’Œç­–ç•¥åˆ†æï¼Œåˆ—å‡º2-3é»ä¸»è¦æŠ•è³‡é¢¨éšªã€‚](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)

è«‹ç¢ºä¿åˆ†æå°ˆæ¥­ã€å®¢è§€ï¼Œä¸¦é‡é»é—œæ³¨æœ€æ–°æ–°èå°æŠ•è³‡æ±ºç­–çš„å½±éŸ¿ã€‚"""

        # ğŸ”¥ é—œéµï¼šé…ç½® Gemini ä½¿ç”¨ Google Search å·¥å…·
        config = genai_types.GenerateContentConfig(
            temperature=0.7,
            max_output_tokens=4500,
            tools=[genai_types.Tool(google_search=genai_types.GoogleSearch())],
            safety_settings=safety_settings_gemini
        )
        
        response = gemini_client.models.generate_content(
            model='models/gemini-2.5-flash',
            contents=prompt,
            config=config
        )
        
        # ğŸ”¥ ä¿®å¾©ï¼šæ·»åŠ ç©ºå€¼æª¢æŸ¥
        if response and hasattr(response, 'text') and response.text:
            return response.text.strip()
        else:
            logger.warning("Gemini API è¿”å›ç©ºéŸ¿æ‡‰")
            return "AIåˆ†ææš«æ™‚ç„¡æ³•ç”Ÿæˆï¼Œä½†è‚¡ç¥¨åŸºæœ¬è³‡æ–™å’ŒæŠ€è¡“æŒ‡æ¨™åˆ†ææ­£å¸¸é‹è¡Œ"
            
    except Exception as e:
        logger.error(f"Gemini æ–°èåˆ†æç”Ÿæˆå¤±æ•—: {e}")
        return f"AIæ–°èåˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼š{str(e)}"

# === å¾ stock_ga_web.py ç§»æ¤ï¼šSingleStockTrainer é¡åˆ¥ ===
class SingleStockTrainer:
    """å–®æ”¯è‚¡ç¥¨è¨“ç·´å™¨é¡åˆ¥ - Kç·šåœ–æ•´åˆç‰ˆ"""
    def __init__(self):
        # å›ºå®šçš„GAåƒæ•¸
        self.fixed_params = {
            'mutation_rate': 0.25,
            'crossover_rate': 0.7,
            'no_trade_penalty': 0.1,
            'nsga2_enabled': True
        }
        
        # é è¨­çš„è‡ªå®šç¾©æ¬Šé‡
        self.default_custom_weights = {
            'total_return_weight': 0.35,
            'avg_trade_return_weight': 0.30,
            'win_rate_weight': 0.30,
            'trade_count_weight': 0,
            'drawdown_weight': 0.05
        }
        
        self.system_a_config = GA_PARAMS_CONFIG.copy()
        self.system_b_config = GA_PARAMS_CONFIG_B.copy()

    def validate_inputs(self, ticker, start_date, end_date, system_type):
        """é©—è­‰è¼¸å…¥åƒæ•¸"""
        errors = []
        
        if not ticker or len(ticker.strip()) == 0:
            errors.append("è‚¡ç¥¨ä»£è™Ÿä¸èƒ½ç‚ºç©º")
        
        try:
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            end_dt = datetime.strptime(end_date, "%Y-%m-%d")
            
            if start_dt >= end_dt:
                errors.append("é–‹å§‹æ—¥æœŸå¿…é ˆæ—©æ–¼çµæŸæ—¥æœŸ")
            if end_dt > datetime.now():
                errors.append("çµæŸæ—¥æœŸä¸èƒ½è¶…éä»Šå¤©")
            if (end_dt - start_dt).days < 100:
                errors.append("è¨“ç·´æœŸé–“è‡³å°‘éœ€è¦100å¤©")
        except ValueError:
            errors.append("æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
        
        if system_type not in ['A', 'B']:
            errors.append("ç³»çµ±é¡å‹å¿…é ˆæ˜¯ A æˆ– B")
        
        return errors

    def validate_custom_weights(self, custom_weights):
        """é©—è­‰è‡ªå®šç¾©æ¬Šé‡"""
        errors = []
        required_weights = ['total_return_weight', 'avg_trade_return_weight',
                          'win_rate_weight', 'trade_count_weight', 'drawdown_weight']
        
        total_weight = 0
        for weight_name in required_weights:
            if weight_name not in custom_weights:
                errors.append(f"ç¼ºå°‘æ¬Šé‡åƒæ•¸: {weight_name}")
                continue
            
            try:
                value = float(custom_weights[weight_name])
                if value < 0 or value > 1:
                    errors.append(f"{weight_name} å¿…é ˆåœ¨ 0 åˆ° 1 ä¹‹é–“")
                total_weight += value
            except ValueError:
                errors.append(f"{weight_name} å¿…é ˆæ˜¯æœ‰æ•ˆçš„æ•¸å­—")
        
        if abs(total_weight - 1.0) > 0.01:
            errors.append(f"æ‰€æœ‰æ¬Šé‡ç¸½å’Œæ‡‰è©²ç­‰æ–¼1.0ï¼Œç›®å‰ç¸½å’Œç‚º: {total_weight:.3f}")
        
        return errors

    # æ‰¾åˆ° SingleStockTrainer é¡åˆ¥ä¸¦å®Œæ•´æ›¿æ› load_stock_data å‡½å¼
    def load_stock_data(self, ticker, start_date, end_date, system_type):
        """è¼‰å…¥è‚¡ç¥¨æ•¸æ“š - (æ•´åˆ.TW/.TWOè‡ªå‹•é‡è©¦)"""
        try:
            # <<<<<<< é€™è£¡æ˜¯æ–°çš„æ™ºæ…§é‡è©¦é‚è¼¯ >>>>>>>
            is_tw_stock_code = re.fullmatch(r'\d{4,6}[A-Z]?', ticker)
            loaded_data = None
            final_ticker = ticker
            
            load_func_a = lambda t: ga_load_data(
                t, start_date=start_date, end_date=end_date,
                sentiment_csv_path='2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv' if os.path.exists('2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv') else None,
                verbose=False
            )
            load_func_b = lambda t: load_stock_data_b(t, start_date=start_date, end_date=end_date, verbose=False)

            if is_tw_stock_code:
                logger.info(f"åµæ¸¬åˆ°å°è‚¡æ•¸å­—ä»£è™Ÿ {ticker}ï¼Œå°‡ä¾åºå˜—è©¦ .TW å’Œ .TWO å¾Œç¶´ã€‚")
                for suffix in ['.TW', '.TWO']:
                    potential_ticker = f"{ticker}{suffix}"
                    logger.info(f"æ­£åœ¨ç‚ºç³»çµ± {system_type} å˜—è©¦ä½¿ç”¨ {potential_ticker} è¼‰å…¥æ•¸æ“š...")
                    
                    prices = None
                    if system_type == 'A':
                        loaded_data = load_func_a(potential_ticker)
                        prices = loaded_data[0] # prices is the first element
                    else:
                        loaded_data = load_func_b(potential_ticker)
                        prices = loaded_data[0] # prices is the first element
                    
                    if prices and len(prices) > 0:
                        logger.info(f"æˆåŠŸä½¿ç”¨ {potential_ticker} è¼‰å…¥æ•¸æ“šã€‚")
                        final_ticker = potential_ticker
                        break # æˆåŠŸï¼Œè·³å‡ºè¿´åœˆ
                    else:
                        loaded_data = None # é‡ç½®ä»¥é€²è¡Œä¸‹ä¸€æ¬¡å˜—è©¦
            
            # å¦‚æœä¸æ˜¯å°è‚¡ä»£è™Ÿï¼Œæˆ–æ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—ï¼Œå‰‡åŸ·è¡ŒåŸå§‹é‚è¼¯
            if not loaded_data:
                logger.info(f"åŸ·è¡Œæ¨™æº–æŸ¥è©¢ï¼š{ticker}")
                if system_type == 'A':
                    loaded_data = load_func_a(ticker)
                else:
                    loaded_data = load_func_b(ticker)
            
            # æœ€çµ‚æª¢æŸ¥æ•¸æ“š
            prices = loaded_data[0]
            if not prices or len(prices) == 0:
                return None, f"æ•¸æ“šä¸è¶³ï¼Œè«‹æª¢æŸ¥è‚¡ç¥¨ä»£è™Ÿ {ticker} æˆ–èª¿æ•´æ—¥æœŸç¯„åœ (å·²å˜—è©¦ .TW å’Œ .TWO)ã€‚"
            # <<<<<<< æ™ºæ…§é‡è©¦é‚è¼¯çµæŸ >>>>>>>

            # æ ¹æ“šç³»çµ±é¡å‹è§£åŒ…ä¸¦é è¨ˆç®—æŒ‡æ¨™
            if system_type == 'A':
                prices, dates, stock_df, vix_series, sentiment_series = loaded_data
                precalculated, ready = ga_precompute_indicators(
                    stock_df, vix_series, STRATEGY_CONFIG_SHARED_GA,
                    sentiment_series=sentiment_series, verbose=False
                )
                if not ready: return None, "ç³»çµ±AæŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—"
                return {'prices': prices, 'dates': dates, 'stock_df': stock_df, 'vix_series': vix_series,
                        'sentiment_series': sentiment_series, 'precalculated': precalculated, 'data_points': len(prices)}, None
            else: # ç³»çµ±B
                prices, dates, stock_df, vix_series = loaded_data
                precalculated, ready = precompute_indicators_b(
                    stock_df, vix_series, STRATEGY_CONFIG_B, verbose=False
                )
                if not ready: return None, "ç³»çµ±BæŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—"
                return {'prices': prices, 'dates': dates, 'stock_df': stock_df, 'vix_series': vix_series,
                        'precalculated': precalculated, 'data_points': len(prices)}, None
                
        except Exception as e:
            logger.error(f"è¼‰å…¥æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None, f"è¼‰å…¥æ•¸æ“šå¤±æ•—: {str(e)}"

    def apply_fixed_and_custom_params(self, system_type, custom_weights, basic_params):
        """æ‡‰ç”¨å›ºå®šåƒæ•¸å’Œè‡ªå®šç¾©æ¬Šé‡åˆ°GAåƒæ•¸"""
        if system_type == 'A':
            config = self.system_a_config.copy()
        else:
            config = self.system_b_config.copy()
        
        config.update(self.fixed_params)
        
        if 'generations' in basic_params:
            config['generations'] = max(5, min(100, int(basic_params['generations'])))
        if 'population_size' in basic_params:
            config['population_size'] = max(20, min(200, int(basic_params['population_size'])))
        if 'min_trades' in basic_params:
            config['min_trades_for_full_score'] = max(1, min(20, int(basic_params['min_trades'])))
        
        config['nsga2_selection_method'] = 'custom_balance'
        config['custom_weights'] = custom_weights
        
        return config

    def generate_trading_signals(self, gene, data_result, ga_config, system_type):
        """ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿæ•¸æ“š"""
        try:
            logger.info(f"é–‹å§‹ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ - ç³»çµ±{system_type}")
            
            if system_type == 'A':
                def get_indicator_list(name, gene_indices, opt_keys):
                    params = [ga_config[k][gene[g_idx]] for g_idx, k in zip(gene_indices, opt_keys)]
                    key = tuple(params) if len(params) > 1 else params[0]
                    indicator_data = data_result['precalculated'].get(name, {}).get(key, [np.nan] * len(data_result['prices']))
                    return np.array(indicator_data, dtype=np.float64)
                
                result = run_strategy_numba_core(
                    np.array(gene, dtype=np.float64),
                    np.array(data_result['prices'], dtype=np.float64),
                    get_indicator_list('vix_ma', [GENE_MAP['vix_ma_p']], ['vix_ma_period_options']),
                    get_indicator_list('sentiment_ma', [GENE_MAP['sentiment_ma_p']], ['sentiment_ma_period_options']),
                    get_indicator_list('rsi', [GENE_MAP['rsi_p']], ['rsi_period_options']),
                    get_indicator_list('adx', [GENE_MAP['adx_p']], ['adx_period_options']),
                    get_indicator_list('bbl', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                    get_indicator_list('bbm', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                    get_indicator_list('bbu', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                    get_indicator_list('ma', [GENE_MAP['ma_s_p']], ['ma_period_options']),
                    get_indicator_list('ma', [GENE_MAP['ma_l_p']], ['ma_period_options']),
                    get_indicator_list('ema_s', [GENE_MAP['ema_s_p']], ['ema_s_period_options']),
                    get_indicator_list('ema_m', [GENE_MAP['ema_m_p']], ['ema_m_period_options']),
                    get_indicator_list('ema_l', [GENE_MAP['ema_l_p']], ['ema_l_period_options']),
                    get_indicator_list('atr', [GENE_MAP['atr_p']], ['atr_period_options']),
                    get_indicator_list('atr_ma', [GENE_MAP['atr_p']], ['atr_period_options']),
                    get_indicator_list('kd_k', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']],
                                     ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                    get_indicator_list('kd_d', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']],
                                     ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                    get_indicator_list('macd_line', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']],
                                     ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                    get_indicator_list('macd_signal', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']],
                                     ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                    ga_config.get('commission_rate', 0.003),
                    61
                )
                
                if result is None or len(result) < 6:
                    logger.warning("ç³»çµ±Aç­–ç•¥åŸ·è¡Œå¤±æ•—")
                    return None, None, None
                
                portfolio_values, buy_indices, buy_prices, sell_indices, sell_prices, _ = result
                
                buy_signals = []
                sell_signals = []
                
                if buy_indices is not None and len(buy_indices) > 0:
                    buy_signals = [{'date': data_result['dates'][i], 'price': buy_prices[idx] if buy_prices is not None and idx < len(buy_prices) else data_result['prices'][i]}
                                 for idx, i in enumerate(buy_indices) if i < len(data_result['dates'])]
                
                if sell_indices is not None and len(sell_indices) > 0:
                    sell_signals = [{'date': data_result['dates'][i], 'price': sell_prices[idx] if sell_prices is not None and idx < len(sell_prices) else data_result['prices'][i]}
                                  for idx, i in enumerate(sell_indices) if i < len(data_result['dates'])]
                
                logger.info(f"ç³»çµ±Aä¿¡è™Ÿç”Ÿæˆå®Œæˆ: {len(buy_signals)}è²·å…¥, {len(sell_signals)}è³£å‡º")
                return portfolio_values.tolist(), buy_signals, sell_signals
                
            else:  # ç³»çµ±B
                # è§£æåŸºå› åƒæ•¸
                rsi_buy_entry_threshold = float(gene[0])
                rsi_exit_threshold = float(gene[1])
                vix_threshold = float(gene[2])
                low_vol_exit_strategy = int(gene[3])
                rsi_p_choice = int(gene[4])
                vix_ma_p_choice = int(gene[5])
                bb_len_choice = int(gene[6])
                bb_std_choice = int(gene[7])
                adx_threshold = float(gene[8])
                high_vol_entry_choice = int(gene[9])
                
                # ç²å–æŒ‡æ¨™æ•¸æ“š
                rsi_period = STRATEGY_CONFIG_B['rsi_period_options'][rsi_p_choice]
                vix_ma_period = STRATEGY_CONFIG_B['vix_ma_period_options'][vix_ma_p_choice]
                bb_len = STRATEGY_CONFIG_B['bb_length_options'][bb_len_choice]
                bb_std = STRATEGY_CONFIG_B['bb_std_options'][bb_std_choice]
                
                rsi_list = data_result['precalculated']['rsi'][rsi_period]
                vix_ma_list = data_result['precalculated']['vix_ma'][vix_ma_period]
                bbl_list = data_result['precalculated']['bbl'][(bb_len, bb_std)]
                bbm_list = data_result['precalculated']['bbm'][(bb_len, bb_std)]
                adx_list = data_result['precalculated']['fixed']['adx_list']
                ma_short_list = data_result['precalculated']['fixed']['ma_short_list']
                ma_long_list = data_result['precalculated']['fixed']['ma_long_list']
                
                # åŸ·è¡Œç­–ç•¥
                portfolio_values, buy_signals, sell_signals = run_strategy_b(
                    rsi_buy_entry_threshold, rsi_exit_threshold, adx_threshold, vix_threshold,
                    low_vol_exit_strategy, high_vol_entry_choice,
                    ga_config['commission_rate'],
                    data_result['prices'], data_result['dates'],
                    rsi_list, bbl_list, bbm_list, adx_list,
                    vix_ma_list, ma_short_list, ma_long_list
                )
                
                # è½‰æ›ä¿¡è™Ÿæ ¼å¼
                buy_signals_formatted = [{'date': s[0], 'price': s[1]} for s in buy_signals]
                sell_signals_formatted = [{'date': s[0], 'price': s[1]} for s in sell_signals]
                
                logger.info(f"ç³»çµ±Bä¿¡è™Ÿç”Ÿæˆå®Œæˆ: {len(buy_signals_formatted)}è²·å…¥, {len(sell_signals_formatted)}è³£å‡º")
                return portfolio_values, buy_signals_formatted, sell_signals_formatted
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            logger.error(traceback.format_exc())
            return None, None, None

    def create_line_chart_with_signals(self, ticker, data_result, portfolio_values, buy_signals, sell_signals):
        """ç”¨æ”¶ç›¤åƒ¹ç·šåœ–å’Œäº¤æ˜“ä¿¡è™Ÿå‰µå»ºåœ–è¡¨"""
        try:
            df = data_result['stock_df'].copy()
            if df.index.name != 'Date':
                df = df.reset_index()
            
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
            else:
                df['Date'] = pd.to_datetime(df.index)
            df = df.reset_index(drop=True)
            
            fig = make_subplots(
                rows=2, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.1,
                row_heights=[0.7, 0.3],
                subplot_titles=(f'{ticker} åƒ¹æ ¼èµ°å‹¢èˆ‡äº¤æ˜“ä¿¡è™Ÿ', 'æŠ•è³‡çµ„åˆåƒ¹å€¼è®ŠåŒ–')
            )
            
            fig.add_trace(
                go.Scatter(
                    x=df['Date'],
                    y=data_result['prices'],
                    mode='lines',
                    name='æ”¶ç›¤åƒ¹',
                    line=dict(color='rgba(102, 126, 234, 0.7)', width=2)
                ),
                row=1, col=1
            )
            
            if buy_signals:
                buy_dates = [pd.to_datetime(signal['date']) for signal in buy_signals]
                buy_prices = [signal['price'] for signal in buy_signals]
                fig.add_trace(
                    go.Scatter(
                        x=buy_dates,
                        y=buy_prices,
                        mode='markers',
                        marker=dict(symbol='triangle-up', size=12, color='red', line=dict(width=2, color='darkred')),
                        name=f'è²·å…¥ ({len(buy_signals)}æ¬¡)',
                        hovertemplate='è²·å…¥ä¿¡è™Ÿ<br>æ—¥æœŸ: %{x}<br>åƒ¹æ ¼: %{y:.2f}<extra></extra>'
                    ),
                    row=1, col=1
                )
            
            if sell_signals:
                sell_dates = [pd.to_datetime(signal['date']) for signal in sell_signals]
                sell_prices = [signal['price'] for signal in sell_signals]
                fig.add_trace(
                    go.Scatter(
                        x=sell_dates,
                        y=sell_prices,
                        mode='markers',
                        marker=dict(symbol='triangle-down', size=12, color='blue', line=dict(width=2, color='darkblue')),
                        name=f'è³£å‡º ({len(sell_signals)}æ¬¡)',
                        hovertemplate='è³£å‡ºä¿¡è™Ÿ<br>æ—¥æœŸ: %{x}<br>åƒ¹æ ¼: %{y:.2f}<extra></extra>'
                    ),
                    row=1, col=1
                )
            
            if portfolio_values and len(portfolio_values) >= len(df):
                portfolio_data = portfolio_values[:len(df)]
                fig.add_trace(
                    go.Scatter(
                        x=df['Date'],
                        y=portfolio_data,
                        mode='lines',
                        line=dict(color='purple', width=2),
                        name='æŠ•è³‡çµ„åˆåƒ¹å€¼',
                        hovertemplate='çµ„åˆåƒ¹å€¼<br>æ—¥æœŸ: %{x}<br>åƒ¹å€¼: %{y:.4f}<extra></extra>'
                    ),
                    row=2, col=1
                )
            
            fig.update_layout(
                title={'text': f'{ticker} ç­–ç•¥å›æ¸¬çµæœ', 'x': 0.5, 'xanchor': 'center', 'font': {'size': 18}},
                xaxis_title='æ—¥æœŸ', yaxis_title='è‚¡åƒ¹',
                xaxis2_title='', yaxis2_title='çµ„åˆåƒ¹å€¼',
                height=600, showlegend=True,
                xaxis_rangeslider_visible=False,
                hovermode='x unified', template='plotly_white'
            )
            
            fig.update_xaxes(tickformat='%Y-%m-%d', tickangle=45)
            
            chart_json = fig.to_json()
            logger.info(f"æˆåŠŸç”Ÿæˆ {ticker} çš„Plotlyç·šåœ–JSON")
            return chart_json
            
        except Exception as e:
            logger.error(f"å‰µå»ºç·šåœ–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            logger.error(traceback.format_exc())
            return None

    def calculate_detailed_metrics(self, gene, data_result, ga_config, system_type):
        """è¨ˆç®—è©³ç´°ç¸¾æ•ˆæŒ‡æ¨™ (å·²é‡æ§‹ç‚ºä½¿ç”¨ utils)"""
        try:
            portfolio_values, buy_signals, sell_signals = self.generate_trading_signals(gene, data_result, ga_config, system_type)
            if not portfolio_values: 
                return {}
            
            # ğŸ”¥ ç›´æ¥å‘¼å« utils ä¸­çš„å‡½å¼
            metrics = calculate_performance_metrics(
                portfolio_values,
                data_result['dates'],
                buy_signals,
                sell_signals,
                data_result['prices']
            )
            
            return metrics
        except Exception as e:
            logger.error(f"è¨ˆç®—è©³ç´°æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return {}

    def analyze_signal_status(self, buy_signals, sell_signals):
        """åˆ†ææœ€æ–°çš„ä¿¡è™Ÿç‹€æ…‹ï¼Œè¿”å›ä¸€å€‹æç¤ºå­—ä¸²"""
        if not buy_signals and not sell_signals: 
            return "ç›®å‰ç„¡ä»»ä½•è¨Šè™Ÿ"
        
        today = datetime.now().date()
        seven_days_ago = today - timedelta(days=7)
        
        last_buy_date = pd.to_datetime(buy_signals[-1]['date']).date() if buy_signals else None
        last_sell_date = pd.to_datetime(sell_signals[-1]['date']).date() if sell_signals else None
        
        # 1. æª¢æŸ¥è¿‘æœŸä¿¡è™Ÿ
        recent_buy_signal = last_buy_date if last_buy_date and last_buy_date >= seven_days_ago else None
        recent_sell_signal = last_sell_date if last_sell_date and last_sell_date >= seven_days_ago else None
        
        if recent_buy_signal and (not recent_sell_signal or recent_buy_signal >= recent_sell_signal):
            return f"æ³¨æ„ï¼š{recent_buy_signal.strftime('%Y/%m/%d')} æœ‰è¿‘æœŸè²·å…¥è¨Šè™Ÿï¼"
        
        if recent_sell_signal and (not recent_buy_signal or recent_sell_signal > recent_buy_signal):
            return f"æ³¨æ„ï¼š{recent_sell_signal.strftime('%Y/%m/%d')} æœ‰è¿‘æœŸè³£å‡ºè¨Šè™Ÿï¼"
        
        # 2. å¦‚æœæ²’æœ‰è¿‘æœŸä¿¡è™Ÿï¼Œåˆ¤æ–·é•·æœŸæŒæœ‰ç‹€æ…‹
        if last_buy_date and (not last_sell_date or last_buy_date > last_sell_date):
            return "ç›®å‰ç­–ç•¥ç‹€æ…‹ç‚ºã€ŒæŒæœ‰ä¸­ã€"
        else:
            return "ç›®å‰ç­–ç•¥ç‹€æ…‹ç‚ºã€Œç„¡å€‰ä½ã€"

    # åœ¨ main_app.py ä¸­ï¼Œæ‰¾åˆ° SingleStockTrainer é¡åˆ¥ä¸¦æ›¿æ›ä»¥ä¸‹å…©å€‹å‡½å¼

# --- 1. å®Œæ•´æ›¿æ› run_training å‡½å¼ ---
    # åœ¨ main_app.py ä¸­ï¼Œæ‰¾åˆ° SingleStockTrainer é¡åˆ¥ä¸¦æ›¿æ› run_training å‡½å¼

    def run_training(self, ticker, start_date, end_date, system_type, custom_weights, basic_params, num_runs=10):
        """åŸ·è¡Œè¨“ç·´ - (æ•ˆèƒ½å„ªåŒ–ç‰ˆï¼šåªç‚ºTop 3ç”Ÿæˆåœ–è¡¨)"""
        try:
            
            
            errors = self.validate_inputs(ticker, start_date, end_date, system_type)
            if errors: 
                return {'success': False, 'errors': errors}
            
            weight_errors = self.validate_custom_weights(custom_weights)
            if weight_errors: 
                return {'success': False, 'errors': weight_errors}
            
            data_result, error_msg = self.load_stock_data(ticker, start_date, end_date, system_type)
            if error_msg: 
                return {'success': False, 'errors': [error_msg]}
            
            ga_config = self.apply_fixed_and_custom_params(system_type, custom_weights, basic_params)
            
            strategy_pool = []
            logger.info(f"é–‹å§‹ç‚º {ticker} åŸ·è¡Œ {num_runs} æ¬¡ç³»çµ±{system_type} NSGA-IIå„ªåŒ– (é«˜æ•ˆæ¨¡å¼)...")
            
            # <<<<<<< æ•ˆèƒ½å„ªåŒ–é» 1ï¼šè¿´åœˆå…§ä¸å†ç”Ÿæˆåœ–è¡¨ >>>>>>>
            for run_idx in range(num_runs):
                try:
                    runner_func = genetic_algorithm_unified if system_type == 'A' else genetic_algorithm_unified_b
                    result = runner_func(data_result['prices'], data_result['dates'], data_result['precalculated'], ga_config)
                    
                    if result and result[0] is not None:
                        gene, performance = result
                        metrics = self.calculate_detailed_metrics(gene, data_result, ga_config, system_type)
                        if not metrics: 
                            continue
                        
                        # åªå„²å­˜æ ¸å¿ƒæ•¸æ“šï¼Œä¸é€²è¡Œè€—æ™‚çš„åœ–è¡¨ç”Ÿæˆ
                        strategy_pool.append({
                            'gene': gene,
                            'fitness': metrics.get('total_return', 0),
                            'metrics': metrics,
                            'run': run_idx + 1,
                        })
                except Exception as e:
                    logger.warning(f"ç¬¬ {run_idx + 1} æ¬¡é‹è¡Œå¤±æ•—: {e}")
                    continue
            
            if not strategy_pool: 
                return {'success': False, 'errors': ['æ‰€æœ‰è¨“ç·´é‹è¡Œéƒ½å¤±æ•—äº†']}
            
            # æ’åºä¸¦é¸å‡ºæœ€ä½³ç­–ç•¥
            strategy_pool.sort(key=lambda x: x['fitness'], reverse=True)
            top_3 = strategy_pool[:3]
            
            results = []
            logger.info(f"è¨“ç·´å®Œæˆï¼Œé–‹å§‹ç‚º Top {len(top_3)} ç­–ç•¥ç”Ÿæˆåœ–è¡¨...")

            # <<<<<<< æ•ˆèƒ½å„ªåŒ–é» 2ï¼šåªç‚º Top 3 ç”Ÿæˆåœ–è¡¨ >>>>>>>
            for i, strategy in enumerate(top_3):
                # åœ¨é€™è£¡æ‰ç”Ÿæˆåœ–è¡¨ï¼Œå¤§å¤§æ¸›å°‘äº† I/O æ“ä½œ
                portfolio_values, buy_signals, sell_signals = self.generate_trading_signals(
                    strategy['gene'], data_result, ga_config, system_type
                )
                
                chart_image_url, chart_interactive_url = None, None
                if portfolio_values is not None:
                    chart_image_url, chart_interactive_url = create_backtest_chart_assets(
                        ticker, f"System{system_type}", strategy['run'],
                        portfolio_values, data_result['prices'], data_result['dates'],
                        buy_signals, sell_signals
                    )
                
                formatter_func = format_ga_gene_parameters_to_text if system_type == 'A' else format_gene_parameters_to_text_b
                description = formatter_func(strategy['gene'])
                
                results.append({
                    'rank': i + 1,
                    'gene': strategy['gene'],
                    'fitness': strategy['fitness'],
                    'metrics': strategy['metrics'],
                    'description': description,
                    'run_number': strategy['run'],
                    'chart_image_url': chart_image_url,
                    'chart_interactive_url': chart_interactive_url,
                    'buy_signals_count': len(buy_signals or []),
                    'sell_signals_count': len(sell_signals or [])
                })
            
            logger.info("Top 3 ç­–ç•¥åœ–è¡¨ç”Ÿæˆå®Œç•¢ã€‚")
            return {
                'success': True, 'ticker': ticker, 'system_type': system_type,
                'training_period': f"{start_date} ~ {end_date}",
                'data_points': data_result['data_points'], 'total_runs': num_runs,
                'successful_runs': len(strategy_pool), 'results': results,
                'config_used': {k: v for k, v in ga_config.items() if k not in ['custom_weights']},
                'custom_weights_used': custom_weights,
                'chart_engine': 'ImagePreview'
            }
            
        except Exception as e:
            logger.error(f"è¨“ç·´éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return {'success': False, 'errors': [f'è¨“ç·´å¤±æ•—: {str(e)}']}


    # --- 2. å®Œæ•´æ›¿æ› run_manual_backtest å‡½å¼ ---
    def run_manual_backtest(self, ticker, gene, duration_months):
        """åŸ·è¡Œæ‰‹å‹•å›æ¸¬ - (ä¿®æ”¹ç‰ˆï¼šç”Ÿæˆåœ–ç‰‡å’ŒHTML URL)"""
        try:
            
            
            system_type = 'A' if len(gene) in range(27, 29) else 'B' if len(gene) in range(9, 11) else None
            if not system_type: 
                return {'success': False, 'error': f"ç„¡æ³•è­˜åˆ¥çš„åŸºå› é•·åº¦: {len(gene)}"}
            
            end_date = datetime.now()
            start_date = end_date - timedelta(days=duration_months * 30.4)
            start_date_str, end_date_str = start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")
            
            errors = self.validate_inputs(ticker, start_date_str, end_date_str, system_type)
            if errors: 
                return {'success': False, 'error': ", ".join(errors)}
            
            data_result, error_msg = self.load_stock_data(ticker, start_date_str, end_date_str, system_type)
            if error_msg: 
                return {'success': False, 'error': error_msg}
            
            ga_config = self.system_a_config if system_type == 'A' else self.system_b_config
            
            metrics = self.calculate_detailed_metrics(gene, data_result, ga_config, system_type)
            if not metrics: 
                return {'success': False, 'error': 'ç„¡æ³•ç”Ÿæˆå›æ¸¬çµæœï¼Œå¯èƒ½æ˜¯æ­¤åŸºå› åœ¨æ­¤æœŸé–“ç„¡äº¤æ˜“ã€‚'}
            
            portfolio_values, buy_signals, sell_signals = self.generate_trading_signals(gene, data_result, ga_config, system_type)
            
            # <<<<<<< è®Šæ›´é»ï¼šå‘¼å«æ–°çš„åœ–è¡¨ç”Ÿæˆå‡½å¼ >>>>>>>
            chart_image_url, chart_interactive_url = create_backtest_chart_assets(
                ticker, f"System{system_type}", "Manual",
                portfolio_values, data_result['prices'], data_result['dates'],
                buy_signals, sell_signals
            )
            
            signal_status = self.analyze_signal_status(buy_signals, sell_signals)
            
            # <<<<<<< è®Šæ›´é»ï¼šåœ¨å›å‚³çš„å­—å…¸ä¸­åŒ…å« URL >>>>>>>
            return {
                'success': True, 'ticker': ticker, 'system_type_detected': f'ç³»çµ± {system_type}',
                'backtest_period': f"{start_date_str} ~ {end_date_str}",
                'metrics': metrics, 
                'chart_image_url': chart_image_url, 
                'chart_interactive_url': chart_interactive_url, 
                'signal_status': signal_status
            }
            
        except Exception as e:
            logger.error(f"æ‰‹å‹•å›æ¸¬éç¨‹ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
            return {'success': False, 'error': f'å›æ¸¬å¤±æ•—: {str(e)}'}

# å»ºç«‹è¨“ç·´å™¨å¯¦ä¾‹
trainer = SingleStockTrainer()

# ==============================================================================
# >>> ä»¥ä¸‹ç‚ºåŸå§‹ program.py çš„å…¶ä»–åŠŸèƒ½æ¨¡çµ„ (çœç•¥ä»¥ç¯€çœç¯‡å¹…ï¼Œä½†å¯¦éš›ä½¿ç”¨æ™‚éœ€è¦åŒ…å«) <<<
# ==============================================================================

# æ–°èæƒ…ç·’åˆ†æç›¸é—œå¸¸æ•¸å’Œå‡½å¼
MOCK_TODAY = None
MAX_TOTAL_HEADLINES = 100
MAX_HEADLINES_PER_TOPIC = 5
CSV_FILEPATH = '2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv'

TARGET_COMPANIES_AND_TOPICS = {
    "Apple": "AAPL", "Microsoft": "MSFT", "Nvidia": "NVDA", "Google": "GOOGL",
    "Amazon": "AMZN", "Meta": "META", "Tesla": "TSLA",
    "S&P 500": None, "Nasdaq": None, "Dow Jones": None, "Federal Reserve": "Fed",
    "inflation": "CPI", "jobs report": "nonfarm payrolls", "interest rates": None,
    "crude oil": "WTI", "US election": None, "trade war": "tariffs","war": "war",
    "Trump": "tariffs",
}

# FinBERT æ¨¡å‹ç›¸é—œ
finbert_tokenizer = None
finbert_model = None

if not FINBERT_AVAILABLE:
    logger.warning("PyTorch æˆ– Transformers æœªå®‰è£ï¼ŒFinBERT æƒ…ç·’åˆ†æåŠŸèƒ½å°‡è¢«è·³éã€‚")


# === ä¾†è‡ª program.py çš„åŸå§‹é¦–é è·¯ç”± ===
@app.route('/')
def home():
    """åŸå§‹å¸‚å ´åˆ†æå„€è¡¨æ¿é¦–é """
    return render_template('index.html')

# === å¾ stock_ga_web.py ç§»æ¤ï¼šç­–ç•¥è¨“ç·´å¹³å°è·¯ç”± ===
@app.route('/trainer')
@login_required
def trainer_page():
    """ç­–ç•¥è¨“ç·´å¹³å°ä¸»é é¢"""
    return render_template('index_page.html')

@app.route('/login')
def login_page():
    """æä¾›ç™»å…¥é é¢"""
    if current_user.is_authenticated:
        return redirect(url_for('trainer_page'))
    return render_template('login.html')

# === å¾ stock_ga_web.py ç§»æ¤ï¼šä½¿ç”¨è€…èªè­‰ API ===
@app.route('/api/register', methods=['POST'])
def api_register():
    data = request.get_json()
    username = data.get('username')
    email = data.get('email')
    password = data.get('password')
    password_confirm = data.get('password_confirm')
    
    if not all([username, email, password, password_confirm]):
        return jsonify({'success': False, 'message': 'æ‰€æœ‰æ¬„ä½éƒ½ä¸èƒ½ç‚ºç©º'}), 400
    
    if password != password_confirm:
        return jsonify({'success': False, 'message': 'å…©æ¬¡è¼¸å…¥çš„å¯†ç¢¼ä¸ä¸€è‡´'}), 400
    
    if execute_db_query("SELECT id FROM users WHERE email = %s", (email,), fetch_one=True):
        return jsonify({'success': False, 'message': 'æ­¤ Email å·²è¢«è¨»å†Š'}), 409
    
    password_hash = generate_password_hash(password)
    sql = "INSERT INTO users (username, email, password_hash) VALUES (%s, %s, %s)"
    execute_db_query(sql, (username, email, password_hash))
    
    return jsonify({'success': True, 'message': 'è¨»å†ŠæˆåŠŸï¼è«‹ä½¿ç”¨ Email ç™»å…¥ã€‚'}), 201

@app.route('/api/login', methods=['POST'])
def api_login():
    data = request.get_json()
    email = data.get('email')
    password = data.get('password')
    
    user_data = execute_db_query("SELECT * FROM users WHERE email = %s", (email,), fetch_one=True)
    
    if user_data and check_password_hash(user_data['password_hash'], password):
        user = User(user_data)
        login_user(user, remember=True)
        
        # é—œéµï¼šç²å– next åƒæ•¸ï¼Œå¦‚æœæ²’æœ‰ï¼Œå°±é è¨­è·³è½‰åˆ° /trainer
        next_url = request.args.get('next')
        # å¢åŠ å®‰å…¨æ€§æª¢æŸ¥ï¼Œé˜²æ­¢é–‹æ”¾é‡å°å‘æ¼æ´
        if not next_url or not next_url.startswith('/'):
            next_url = url_for('trainer_page')
            
        return jsonify({'success': True, 'message': 'ç™»å…¥æˆåŠŸ', 'redirect_url': next_url}) # <--- è¿”å›é‡å°å‘ URL
    
    return jsonify({'success': False, 'message': 'Email æˆ–å¯†ç¢¼éŒ¯èª¤'}), 401

@app.route('/api/logout')
@login_required
def api_logout():
    logout_user()
    return jsonify({'success': True, 'message': 'å·²æˆåŠŸç™»å‡º'})

@app.route('/api/user/status')
def user_status():
    if current_user.is_authenticated:
        return jsonify({'logged_in': True, 'username': current_user.username})
    return jsonify({'logged_in': False})

# === å¾ stock_ga_web.py ç§»æ¤ï¼šæ ¸å¿ƒåŠŸèƒ½ API (å·²å—ä¿è­·) ===
@app.route('/api/train', methods=['POST'])
@login_required
def api_train():
    """
    (æ–°ç‰ˆ) è¨“ç·´APIç«¯é» - è‡ªå‹•åŒ–è¨“ç·´ç³»çµ±Aå’Œç³»çµ±Bï¼Œä¸¦å›å‚³å„è‡ªçš„æœ€ä½³ç­–ç•¥
    """
    if not ENGINES_IMPORTED:
        return jsonify({'success': False, 'errors': ['éºå‚³ç®—æ³•å¼•æ“æœªæ­£ç¢ºè¼‰å…¥']}), 500
    
    try:
        data = request.json
        ticker = data.get('ticker', '').strip().upper()
        start_date = data.get('start_date')
        end_date = data.get('end_date')
        custom_weights = data.get('custom_weights', trainer.default_custom_weights)
        
        # <<<< ä¿®æ”¹é» 1: å¾Œç«¯å®šç¾©å›ºå®šçš„è¨“ç·´åƒæ•¸ >>>>
        # å¾å‰ç«¯ç²å–ç”¨æˆ¶å”¯ä¸€èƒ½è¨­å®šçš„ min_trades
        basic_params_from_user = data.get('basic_params', {})
        
        # å°‡å›ºå®šçš„åƒæ•¸èˆ‡ç”¨æˆ¶è¨­å®šçš„åƒæ•¸åˆä½µ
        fixed_basic_params = {
            'generations': 15,       # å›ºå®šä¸–ä»£æ•¸
            'population_size': 50,   # å›ºå®šæ—ç¾¤å¤§å°
            'min_trades': int(basic_params_from_user.get('min_trades', 4)) # ä¿ç•™ç”¨æˆ¶è¨­å®š
        }
        fixed_num_runs = 15 # å›ºå®šè¨“ç·´æ¬¡æ•¸

        logger.info(f"æ”¶åˆ°ç°¡åŒ–ç‰ˆè¨“ç·´è«‹æ±‚: {ticker} ({start_date} to {end_date})")
        logger.info(f"å°‡ä½¿ç”¨å›ºå®šåƒæ•¸: {fixed_basic_params}ï¼Œè¨“ç·´ {fixed_num_runs} æ¬¡")

        # <<<< ä¿®æ”¹é» 2: ä¾åºåŸ·è¡Œç³»çµ± A å’Œ B çš„è¨“ç·´ >>>>
        # è¨“ç·´ç³»çµ± A
        logger.info("--- é–‹å§‹è¨“ç·´ç³»çµ± A ---")
        result_A = trainer.run_training(
            ticker=ticker, start_date=start_date, end_date=end_date,
            system_type='A',
            custom_weights=custom_weights,
            basic_params=fixed_basic_params,
            num_runs=fixed_num_runs
        )
        
        # è¨“ç·´ç³»çµ± B
        logger.info("--- é–‹å§‹è¨“ç·´ç³»çµ± B ---")
        result_B = trainer.run_training(
            ticker=ticker, start_date=start_date, end_date=end_date,
            system_type='B',
            custom_weights=custom_weights,
            basic_params=fixed_basic_params,
            num_runs=fixed_num_runs
        )

        # <<<< ä¿®æ”¹é» 3: åˆä½µå…©å€‹ç³»çµ±çš„æœ€ä½³çµæœ >>>>
        combined_results = []
        
        # æå–ç³»çµ± A çš„æœ€ä½³ç­–ç•¥ (Rank 1)
        if result_A.get('success') and result_A.get('results'):
            strategy_A = result_A['results'][0]
            strategy_A['rank'] = 1 # é‡æ–°æ’åç‚º 1
            # æ–°å¢ä¸€å€‹æ¬„ä½ä¾†æ¨™ç¤ºç­–ç•¥é¡å‹ï¼Œæ–¹ä¾¿å‰ç«¯æœªä¾†å®¢è£½åŒ–é¡¯ç¤º
            strategy_A['strategy_type_name'] = 'ç­–ç•¥ 1 ' 
            combined_results.append(strategy_A)
            logger.info("ç³»çµ± A è¨“ç·´æˆåŠŸï¼Œå·²æå–æœ€ä½³ç­–ç•¥ã€‚")
        else:
            logger.warning("ç³»çµ± A è¨“ç·´å¤±æ•—æˆ–ç„¡çµæœã€‚")

        # æå–ç³»çµ± B çš„æœ€ä½³ç­–ç•¥ (Rank 1)
        if result_B.get('success') and result_B.get('results'):
            strategy_B = result_B['results'][0]
            strategy_B['rank'] = 2 # é‡æ–°æ’åç‚º 2
            strategy_B['strategy_type_name'] = 'ç­–ç•¥ 2 '
            combined_results.append(strategy_B)
            logger.info("ç³»çµ± B è¨“ç·´æˆåŠŸï¼Œå·²æå–æœ€ä½³ç­–ç•¥ã€‚")
        else:
            logger.warning("ç³»çµ± B è¨“ç·´å¤±æ•—æˆ–ç„¡çµæœã€‚")
            
        # <<<< ä¿®æ”¹é» 4: è™•ç†è¨“ç·´å¤±æ•—çš„æƒ…æ³ä¸¦å›å‚³åˆä½µå¾Œçš„çµæœ >>>>
        if not combined_results:
            # å¦‚æœå…©å€‹ç³»çµ±éƒ½å¤±æ•—ï¼Œå›å‚³ä¸€å€‹ç¶œåˆçš„éŒ¯èª¤è¨Šæ¯
            error_A = result_A.get('errors', ['æœªçŸ¥éŒ¯èª¤'])[0] if not result_A.get('success') else 'ç„¡æœ‰æ•ˆç­–ç•¥'
            error_B = result_B.get('errors', ['æœªçŸ¥éŒ¯èª¤'])[0] if not result_B.get('success') else 'ç„¡æœ‰æ•ˆç­–ç•¥'
            return jsonify({'success': False, 'errors': [f"æ‰€æœ‰è¨“ç·´å‡å¤±æ•—ã€‚ç³»çµ±A: {error_A} | ç³»çµ±B: {error_B}"]})

        # ä½¿ç”¨ä»»ä¸€æˆåŠŸçµæœçš„å…ƒæ•¸æ“šä¾†å»ºç«‹æœ€çµ‚çš„å›å‚³ç‰©ä»¶
        base_result = result_A if result_A.get('success') else result_B
        
        final_response = {
            'success': True,
            'ticker': base_result.get('ticker'),
            'training_period': base_result.get('training_period'),
            'results': combined_results
        }
        
        logger.info(f"è¨“ç·´å®Œæˆï¼Œå°‡å›å‚³ {len(combined_results)} å€‹æœ€ä½³ç­–ç•¥ã€‚")
        return jsonify(final_response)

    except Exception as e:
        logger.error(f"APIéŒ¯èª¤ /api/train: {e}", exc_info=True)
        return jsonify({'success': False, 'errors': [f'APIä¼ºæœå™¨éŒ¯èª¤: {str(e)}']}), 500

@app.route('/api/manual-backtest', methods=['POST'])
@login_required
def api_manual_backtest():
    if not ENGINES_IMPORTED:
        return jsonify({'success': False, 'error': 'éºå‚³ç®—æ³•å¼•æ“æœªæ­£ç¢ºè¼‰å…¥'}), 500
    
    try:
        data = request.json
        ticker = data.get('ticker', '').strip().upper()
        gene = data.get('gene')
        duration_months = data.get('duration_months', 36)
        
        if not ticker or not gene or not isinstance(gene, list):
            return jsonify({'success': False, 'error': 'ç„¡æ•ˆçš„è¼¸å…¥åƒæ•¸'}), 400
        
        result = trainer.run_manual_backtest(ticker, gene, duration_months)
        return jsonify(result)
    except Exception as e:
        logger.error(f"æ‰‹å‹•å›æ¸¬APIéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'error': f'API ä¼ºæœå™¨éŒ¯èª¤: {str(e)}'}), 500

# === å¾ stock_ga_web.py ç§»æ¤ï¼šç­–ç•¥ç®¡ç† API ===
@app.route('/api/strategies', methods=['POST'])
@login_required
def save_strategy():
    """å„²å­˜ä¸€å€‹æ–°ç­–ç•¥åˆ°ä½¿ç”¨è€…çš„æ¸…å–®ä¸­"""
    try:
        data = request.get_json()
        required_fields = ['ticker', 'train_start_date', 'train_end_date', 'gene', 'metrics', 'strategy_details']
        if not all(field in data for field in required_fields):
            return jsonify({'success': False, 'message': 'ç¼ºå°‘å¿…è¦åƒæ•¸'}), 400
        
        metrics = data['metrics']
        
        sql = """
        INSERT INTO saved_strategies (
            user_id, ticker, train_start_date, train_end_date, gene,
            win_rate, total_return, trade_count, avg_trade_return, max_drawdown,
            max_trade_extremes, strategy_details
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        args = (
            current_user.id,
            data['ticker'],
            data['train_start_date'],
            data['train_end_date'],
            json.dumps(data.get('gene', [])),
            metrics.get('win_rate_pct', 0.0),
            metrics.get('total_return', 0.0),
            metrics.get('trade_count', 0),
            metrics.get('average_trade_return', 0.0),
            metrics.get('max_drawdown', 0.0),
            f"{metrics.get('max_trade_drop_pct', 0.0):.2f}% / {metrics.get('max_trade_gain_pct', 0.0):.2f}%",
            data.get('strategy_details', '')
        )
        
        execute_db_query(sql, args)
        return jsonify({'success': True, 'message': 'ç­–ç•¥å·²æˆåŠŸå„²å­˜ï¼'}), 201
    except Exception as e:
        logger.error(f"å„²å­˜ç­–ç•¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨éŒ¯èª¤: {str(e)}'}), 500

@app.route('/api/strategies', methods=['GET'])
@login_required
def get_strategies():
    """ç²å–ç›®å‰ä½¿ç”¨è€…å„²å­˜çš„æ‰€æœ‰ç­–ç•¥"""
    try:
        sql = "SELECT * FROM saved_strategies WHERE user_id = %s ORDER BY saved_at DESC"
        strategies_from_db = execute_db_query(sql, (current_user.id,), fetch_all=True)
        
        strategies_serializable = []
        if strategies_from_db:
            for s in strategies_from_db:
                for key in ['win_rate', 'total_return', 'avg_trade_return', 'max_drawdown']:
                    if s.get(key) is not None:
                        s[key] = float(s[key])
                
                if isinstance(s.get('gene'), str):
                    try:
                        s['gene'] = json.loads(s['gene'])
                    except json.JSONDecodeError:
                        s['gene'] = []
                
                for dt_key in ['saved_at', 'train_start_date', 'train_end_date']:
                    if isinstance(s.get(dt_key), (datetime, date)):
                        s[dt_key] = s[dt_key].isoformat().split('T')[0]
                
                strategies_serializable.append(s)
        
        return jsonify({'success': True, 'strategies': strategies_serializable})
    except Exception as e:
        logger.error(f"ç²å–ç­–ç•¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨éŒ¯èª¤: {str(e)}'}), 500

@app.route('/api/strategies/<int:strategy_id>', methods=['DELETE'])
@login_required
def delete_strategy(strategy_id):
    """åˆªé™¤ä¸€å€‹æŒ‡å®šçš„ç­–ç•¥"""
    try:
        sql = "DELETE FROM saved_strategies WHERE id = %s AND user_id = %s"
        rowcount = execute_db_query(sql, (strategy_id, current_user.id))
        
        if rowcount > 0:
            return jsonify({'success': True, 'message': 'ç­–ç•¥å·²åˆªé™¤'})
        else:
            return jsonify({'success': False, 'message': 'æ‰¾ä¸åˆ°ç­–ç•¥æˆ–æ¬Šé™ä¸è¶³'}), 404
            
    except Exception as e:
        logger.error(f"åˆªé™¤ç­–ç•¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨éŒ¯èª¤: {e}'}), 500
# ==============================================================================
# >>> æ–°å¢ï¼šè³‡é‡‘é…ç½® API ç«¯é» <<<
# ==============================================================================

def _build_allocation_prompt(risk_profile, strategies_data):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼å‹•æ…‹ç”Ÿæˆçµ¦ Gemini çš„ Prompt - åŠ å¼·ç‰ˆ"""
    
    # 1. æ§‹å»ºç­–ç•¥è³‡ç”¢çš„æ–‡å­—æè¿°
    assets_description = ""
    search_queries = []
    
    for i, strategy in enumerate(strategies_data, 1):
        # --- START: ä¿®æ­£å¾Œçš„ç¨‹å¼ç¢¼å€å¡Š ---
        # è™•ç†æœ€å¤§æ¼²è·Œå¹…ï¼Œä½¿å…¶æ›´ç©©å¥
        extremes_str = strategy.get('max_trade_extremes', '0% / 0%')
        parts = extremes_str.split('/')

        if len(parts) == 2:
            # é€™æ˜¯é æœŸçš„æ ¼å¼ï¼Œä¾‹å¦‚: "-12.3% / +25.4%"
            max_drop = parts[0].strip()
            max_gain = parts[1].strip()
        else:
            # è™•ç†é‚Šç•Œæƒ…æ³ï¼Œä¾‹å¦‚ "N/A" æˆ–å…¶ä»–æ²’æœ‰ '/' çš„æ ¼å¼
            max_drop = parts[0].strip() if parts else 'N/A'
            max_gain = 'N/A' # çµ¦ä¸€å€‹å®‰å…¨çš„é è¨­å€¼
        # --- END: ä¿®æ­£å¾Œçš„ç¨‹å¼ç¢¼å€å¡Š ---
        
        # ç‚ºæ¯å€‹è‚¡ç¥¨æº–å‚™æœå°‹é—œéµå­—
        ticker = strategy['ticker']
        search_queries.append(f"{ticker} stock news today")
        search_queries.append(f"{ticker} earnings financial results")
        
        assets_description += f"""
è³‡ç”¢ {i}: {ticker}
- ç¸½å ±é…¬ç‡: {float(strategy['total_return'])*100:+.2f}%
- å¹³å‡äº¤æ˜“å ±é…¬ç‡: {float(strategy['avg_trade_return'])*100:+.3f}%
- å‹ç‡: {float(strategy['win_rate']):.1f}%
- æœ€å¤§å›æ’¤: -{float(strategy['max_drawdown'])*100:.2f}%
- æœ€å¤§æ¼²è·Œå¹…: {max_gain} / {max_drop}
"""

    # 2. æ§‹å»ºå®Œæ•´çš„ Promptï¼ˆå„ªåŒ–ç‰ˆï¼‰
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æŠ•è³‡çµ„åˆç¶“ç†ï¼Œéœ€è¦ç‚ºå®¢æˆ¶åˆ†é…æŠ•è³‡è³‡é‡‘ã€‚

**ç¬¬ä¸€æ­¥ï¼šæœå°‹æœ€æ–°è³‡è¨Š**
è«‹ä½¿ç”¨ Google Search å·¥å…·æœå°‹ä»¥ä¸‹æ¯å€‹è‚¡ç¥¨çš„æœ€æ–°è³‡è¨Šï¼š

{chr(10).join([f"- {query}" for query in search_queries])}

é‡é»æœå°‹å…§å®¹ï¼š
- æœ€æ–°è²¡å ±å’Œæ¥­ç¸¾è¡¨ç¾
- é‡å¤§æ–°èäº‹ä»¶å’Œå…¬å¸å‹•æ…‹
- åˆ†æå¸«è©•ç´šå’Œç›®æ¨™åƒ¹
- è¡Œæ¥­è¶¨å‹¢å’Œå¸‚å ´æƒ…ç·’

**ç¬¬äºŒæ­¥ï¼šæŠ•è³‡çµ„åˆåˆ†æ**

å®¢æˆ¶é¢¨éšªåå¥½: {risk_profile}
- ä¿å®ˆå‹ï¼šé‡è¦–ç©©å®šæ€§ï¼Œå„ªå…ˆä½å›æ’¤ã€é«˜å‹ç‡çš„ç­–ç•¥
- å‡è¡¡å‹ï¼šå¹³è¡¡æ”¶ç›Šèˆ‡é¢¨éšªï¼Œå°‹æ±‚æœ€ä½³é¢¨éšªèª¿æ•´å¾Œå ±é…¬
- ç©æ¥µå‹ï¼šè¿½æ±‚é«˜å ±é…¬ï¼Œå¯æ‰¿å—è¼ƒé«˜æ³¢å‹•ï¼Œä½†ä»éœ€ç¨å¾®å›æ’¤é¢¨éšªåŠå‹ç‡

ç­–ç•¥è³‡ç”¢ç¸¾æ•ˆæ•¸æ“š:
{assets_description}

**æ­¥é©Ÿ 3ï¼šè¼¸å‡ºçµæœ**
åŸºæ–¼ä»¥ä¸Šæ‰€æœ‰è³‡è¨Šï¼Œ**åš´æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›æ‡‰**ï¼Œä¸è¦æœ‰ä»»ä½•é¡å¤–æ–‡å­—æˆ–markdownã€‚ç†ç”±(justification)å¿…é ˆéå¸¸ç°¡æ½”ï¼Œé™æ–¼30-50å­—ã€‚

{{
  "allocations": [
    {{"ticker": "è‚¡ç¥¨ä»£è™Ÿ", "percentage": æ•¸å­—}},
    {{"ticker": "è‚¡ç¥¨ä»£è™Ÿ", "percentage": æ•¸å­—}}
  ],
  "reasoning": {{
    "overall_summary": "å°æ•´é«”é…ç½®ç­–ç•¥çš„ç°¡çŸ­ç¸½çµ(50-70å­—)ã€‚",
    "per_stock_analysis": [
      {{
        "ticker": "è‚¡ç¥¨ä»£è™Ÿ",
        "role_in_portfolio": "ç”¨ 'æ ¸å¿ƒå¢é•·'ã€'è¡›æ˜Ÿé…ç½®' æˆ– 'ç©©å®šåŸºçŸ³' ä¾†å®šç¾©å…¶è§’è‰²ã€‚",
        "justification": "ä¸€å¥è©±è§£é‡‹ç‚ºä½•å¦‚æ­¤é…ç½®ï¼Œä»¥åŠå®ƒåœ¨çµ„åˆä¸­çš„ä½œç”¨ã€‚"
      }}
    ]
  }}
}}

**è¼¸å‡ºè¦æ±‚ï¼š**
- æ‰€æœ‰ç™¾åˆ†æ¯”ç¸½å’Œå¿…é ˆæ˜¯100ã€‚
- åˆ†æç†ç”±å¿…é ˆç²¾ç…‰ã€å°ˆæ¥­ã€ç›´æŒ‡æ ¸å¿ƒã€‚
- **æœ€çµ‚çš„è¼¸å‡ºå…§å®¹ä¸­ï¼Œçµ•å°ä¸èƒ½åŒ…å«ä»»ä½•æ–¹æ‹¬è™Ÿ `[]` åŠ ä¸Šæ•¸å­—çš„å¼•æ–‡æ¨™è¨˜ã€åŸºå› åºåˆ—ã€‚**
"""
    
    return prompt


@app.route('/api/capital-allocation', methods=['POST'])
@login_required
def api_capital_allocation():
    """è™•ç†è³‡é‡‘é…ç½®è«‹æ±‚çš„ API ç«¯é» - ç¶“éå…©è¼ªé™¤éŒ¯çš„ç©©å¥ç‰ˆæœ¬"""
    try:
        # 1. æ¥æ”¶ä¸¦é©—è­‰å‰ç«¯å‚³ä¾†çš„æ•¸æ“š
        data = request.get_json()
        strategy_ids = data.get('strategy_ids')
        risk_profile = data.get('risk_profile')

        if not isinstance(strategy_ids, list) or not strategy_ids or not risk_profile:
            return jsonify({'success': False, 'message': 'ç„¡æ•ˆçš„è«‹æ±‚åƒæ•¸'}), 400
        
        if not gemini_client:
            return jsonify({'success': False, 'message': 'Gemini AI æœå‹™æœªé…ç½®'}), 503

        # 2. å¾è³‡æ–™åº«æŸ¥è©¢è¢«é¸ä¸­ç­–ç•¥çš„è©³ç´°æ•¸æ“š
        placeholders = ', '.join(['%s'] * len(strategy_ids))
        sql = f"""
            SELECT id, ticker, total_return, avg_trade_return, win_rate, max_drawdown, max_trade_extremes 
            FROM saved_strategies 
            WHERE id IN ({placeholders}) AND user_id = %s
        """
        params = tuple(strategy_ids) + (current_user.id,)
        strategies_from_db = execute_db_query(sql, params, fetch_all=True)

        if not strategies_from_db or len(strategies_from_db) != len(strategy_ids):
             return jsonify({'success': False, 'message': 'æ‰¾ä¸åˆ°éƒ¨åˆ†æˆ–å…¨éƒ¨ç­–ç•¥ï¼Œè«‹åˆ·æ–°å¾Œå†è©¦'}), 404

        # 3. æ§‹å»ºçµ¦ Gemini çš„ Prompt (ä¾è³´å·²ä¿®æ­£çš„ _build_allocation_prompt)
        prompt_text = _build_allocation_prompt(risk_profile, strategies_from_db)
        logger.info(f"ç‚ºä½¿ç”¨è€… {current_user.id} ç”Ÿæˆçš„è³‡é‡‘é…ç½® Prompt å·²å»ºç«‹ã€‚")

        # 4. èª¿ç”¨ Gemini API
        config = genai_types.GenerateContentConfig(
            temperature=0.3,
            max_output_tokens=20000,
            tools=[genai_types.Tool(google_search=genai_types.GoogleSearch())],
            safety_settings=safety_settings_gemini
        )
        
        response = gemini_client.models.generate_content(
            model='models/gemini-2.5-flash',
            contents=prompt_text,
            config=config
        )

        # 5. å¼·åŒ–çš„å›æ‡‰è™•ç† (æ ¸å¿ƒä¿®æ­£)
        logger.info(f"Gemini API å›æ‡‰é¡å‹: {type(response)}")
        response_text = None

        # æª¢æŸ¥æ˜¯å¦æœ‰å›  Prompt æœ¬èº«çš„å•é¡Œè€Œè¢«é˜»æ“‹
        if response.prompt_feedback and response.prompt_feedback.block_reason:
            block_reason_str = str(response.prompt_feedback.block_reason)
            logger.error(f"âŒ è«‹æ±‚è¢«é˜»æ“‹ï¼åŸå› : {block_reason_str}")
            return jsonify({
                'success': False,
                'message': f'AI åˆ†æè«‹æ±‚è¢«å®‰å…¨ç­–ç•¥é˜»æ“‹ï¼ŒåŸå› : {block_reason_str}ã€‚è«‹å˜—è©¦èª¿æ•´ç­–ç•¥æè¿°æˆ–é¢¨éšªåå¥½ã€‚'
            }), 400

        # å˜—è©¦å¾ response.text ç›´æ¥ç²å– (æœ€ç°¡å–®çš„æƒ…æ³)
        if hasattr(response, 'text') and response.text:
            response_text = response.text.strip()
            logger.info("âœ… ä½¿ç”¨ response.text æˆåŠŸç²å–å›æ‡‰")
        # å¦‚æœä¸è¡Œï¼Œæ·±å…¥æŒ–æ˜ candidates
        elif hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0] # é€šå¸¸åªé—œå¿ƒç¬¬ä¸€å€‹å€™é¸é …
            
            # æª¢æŸ¥å®ŒæˆåŸå› ï¼Œé€™æ˜¯åˆ¤æ–·æ˜¯å¦è¢«å®‰å…¨æ””æˆªçš„é—œéµ
            finish_reason_str = str(candidate.finish_reason) if hasattr(candidate, 'finish_reason') else 'UNKNOWN'
            if finish_reason_str.upper() != 'STOP':
                 logger.warning(f"âš ï¸ Gemini å›æ‡‰çš„å®ŒæˆåŸå› ä¸¦é 'STOP', è€Œæ˜¯ '{finish_reason_str}'ã€‚é€™é€šå¸¸è¡¨ç¤ºå…§å®¹å› å®‰å…¨æˆ–å…¶ä»–åŸå› è¢«æ””æˆªã€‚")
                 if finish_reason_str.upper() == 'SAFETY':
                     return jsonify({
                         'success': False, 
                         'message': 'AI ç”Ÿæˆçš„å…§å®¹å› è§¸ç™¼å®‰å…¨ç­–ç•¥è€Œè¢«æ””æˆªã€‚è«‹ç¨å¾Œé‡è©¦æˆ–èª¿æ•´è«‹æ±‚ã€‚'
                     }), 500

            # å¦‚æœå®ŒæˆåŸå› æ˜¯æ­£å¸¸çš„ï¼Œå†å˜—è©¦è§£æå…§å®¹
            if hasattr(candidate, 'content') and candidate.content.parts:
                response_text = "".join(part.text for part in candidate.content.parts if hasattr(part, 'text')).strip()
                if response_text:
                    logger.info("âœ… å¾ candidate.content.parts æˆåŠŸçµ„åˆå›æ‡‰")

        if not response_text:
            logger.error("âŒ ç„¡æ³•å¾ Gemini API ç²å–ä»»ä½•æ–‡æœ¬å…§å®¹ã€‚å¯èƒ½æ˜¯å› ç‚ºå®‰å…¨æ””æˆªæˆ–ç©ºå›æ‡‰ã€‚")
            logger.error(f"åŸå§‹å›æ‡‰ç‰©ä»¶è©³æƒ…: {response}") # è¨˜éŒ„ä¸‹æ•´å€‹ç‰©ä»¶ä»¥ä¾›åˆ†æ
            return jsonify({
                'success': False, 
                'message': 'AI æœå‹™è¿”å›äº†ç©ºçš„å›æ‡‰ï¼Œå¯èƒ½å› å…§å®¹å¯©æ ¸è¢«æ””æˆªï¼Œè«‹ç¨å¾Œå†è©¦ã€‚'
            }), 500

        logger.info(f"ç²å–åˆ°çš„å›æ‡‰é•·åº¦: {len(response_text)}")
        logger.info(f"å›æ‡‰å‰200å­—ç¬¦: {response_text[:200]}...")

        # 6. æ™ºèƒ½ JSON è§£æ
        try:
            cleaned_text = response_text.replace('```json', '').replace('```', '').strip()
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_text = cleaned_text[json_start:json_end]
                parsed_response = json.loads(json_text)
                
                # é©—è­‰å¿…è¦æ¬„ä½
                if 'allocations' not in parsed_response or not isinstance(parsed_response['allocations'], list):
                    raise ValueError("å›æ‡‰ä¸­ç¼ºå°‘ 'allocations' é™£åˆ—")
                
                total_percentage = sum(item.get('percentage', 0) for item in parsed_response['allocations'])
                if not (95 <= total_percentage <= 105):
                    logger.warning(f"AI é…ç½®ç¸½å’Œç‚º {total_percentage}%ï¼Œåé›¢100%è¼ƒå¤š")
                
                if 'reasoning' not in parsed_response:
                    parsed_response['reasoning'] = "AIå·²å®Œæˆåˆ†æï¼Œä½†æœªæä¾›è©³ç´°èªªæ˜"
                
                logger.info("âœ… JSON è§£ææˆåŠŸ")
                return jsonify({'success': True, 'data': parsed_response})
            else:
                raise ValueError("åœ¨å›æ‡‰ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„JSONçµæ§‹")

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"JSON è§£æå¤±æ•—: {e}")
            logger.error(f"åŸå§‹å›æ‡‰: {response_text}")
            return jsonify({
                'success': False, 
                'message': f'AI å›æ‡‰æ ¼å¼ç•°å¸¸ï¼ŒåŸå§‹å›æ‡‰: {response_text[:300]}...',
                'raw_response': response_text
            }), 500

    except Exception as e:
        logger.error(f"è³‡é‡‘é…ç½® API ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤: {str(e)}'}), 500


    
# === ä¾†è‡ª program.py çš„åŸå§‹ API ç«¯é» ===
# é€™æ˜¯ main_app.py ä¸­çš„ä¸€å€‹å‡½å¼ï¼Œè«‹å®Œæ•´æ›¿æ›
@app.route('/api/enhanced-analyze', methods=['POST'])
def enhanced_analyze_stock():
    """å¢å¼·ç‰ˆè‚¡ç¥¨åˆ†æAPI - åŒ…å«å®Œæ•´æŒ‡æ¨™ã€å›æ¸¬æ™‚é–“ï¼Œä¸¦åŒæ™‚ç”Ÿæˆéœæ…‹åœ–ç‰‡èˆ‡äº’å‹•HTMLåœ–è¡¨"""
    try:
        data = request.get_json()
        ticker = data.get('ticker', '').strip()
        if not ticker: 
            return jsonify({"success": False, "message": "è«‹æä¾›è‚¡ç¥¨ä»£è™Ÿ"})
        
        logger.info(f"é–‹å§‹å¢å¼·åˆ†æï¼š{ticker}")
        analyzer = EnhancedStockAnalyzer(ticker)
        
        stock_data = analyzer.get_basic_stock_data()
        if not stock_data["success"]: 
            return jsonify({"success": False, "message": f"ç„¡æ³•ç²å–è‚¡ç¥¨è³‡æ–™ï¼š{stock_data.get('error', 'æœªçŸ¥éŒ¯èª¤')}"})
        
         # ==================== åœ¨é€™è£¡åŠ å…¥æ–°çš„ç¨‹å¼ç¢¼ ====================
        # æˆåŠŸç²å–è‚¡ç¥¨è³‡æ–™å¾Œï¼Œå‘¼å«å‡½å¼è¨˜éŒ„æ–°çš„ä»£è™Ÿ
        log_new_ticker_to_csv(stock_data['ticker'], stock_data['market'])
        # ============================================================
        tech_indicators = analyzer.get_technical_indicators(stock_data['historical_data'])
        strategies_data = analyzer.get_ai_strategies_data()
        
        # <<<<<<< é€™æ˜¯ä¿®æ”¹å¾Œçš„åœ–è¡¨ç”Ÿæˆå‘¼å« >>>>>>>
        chart_image_url, chart_interactive_url = create_enhanced_stock_chart(
            stock_data['ticker'], stock_data['company_name'], 
            stock_data['historical_data']
        )
        # <<<<<<< ä¿®æ”¹çµæŸ >>>>>>>
        
        logger.info("æ­£åœ¨ç²å–æœ€æ–°çš„VIXæŒ‡æ•¸å’Œå¸‚å ´æƒ…ç·’åˆ†æ•¸...")
        latest_vix = get_latest_vix()
        latest_sentiment = get_latest_sentiment_from_csv()
        
        ai_analysis = generate_enhanced_news_analysis(
            stock_data, tech_indicators, strategies_data, latest_vix, latest_sentiment
        )
        
        if stock_data.get('market_cap'):
            stock_data['market_cap_formatted'] = format_market_cap(
                stock_data['market_cap'], stock_data['currency']
            )
        
        # æ ¼å¼åŒ–ç­–ç•¥æ•¸æ“š
        if strategies_data.get('system_a'):
            for s in strategies_data['system_a']:
                s['formatted_metrics'] = {
                    'average_trade_return_formatted': f"{s.get('average_trade_return_pct',0):.3f}%",
                    'max_drawdown_formatted': f"{s.get('max_drawdown_pct',0):.2f}%",
                    'max_drop_formatted': f"{s.get('max_trade_drop_pct',0):.2f}%",
                    'max_gain_formatted': f"{s.get('max_trade_gain_pct',0):.2f}%"
                }
        
        if strategies_data.get('system_b'):
            for s in strategies_data['system_b']:
                s['formatted_metrics'] = {
                    'average_trade_return_formatted': f"{s.get('average_trade_return_pct',0):.3f}%",
                    'max_drawdown_formatted': f"{s.get('max_drawdown_pct',0):.2f}%",
                    'max_drop_formatted': f"{s.get('max_trade_drop_pct',0):.2f}%",
                    'max_gain_formatted': f"{s.get('max_trade_gain_pct',0):.2f}%"
                }
        
        del stock_data['historical_data']
        
        logger.info(f"å¢å¼·åˆ†æå®Œæˆï¼š{ticker}")
        
        # <<<<<<< é€™æ˜¯ä¿®æ”¹å¾Œçš„APIå›å‚³å…§å®¹ >>>>>>>
        return jsonify({
            "success": True,
            "data": {
                **stock_data,
                "technical_indicators": tech_indicators,
                "ai_strategies": strategies_data,
                "gemini_analysis": ai_analysis,
                "chart_image_url": chart_image_url,           # éœæ…‹åœ–ç‰‡URL
                "chart_interactive_url": chart_interactive_url # äº’å‹•HTMLçš„URL
            }
        })
        # <<<<<<< ä¿®æ”¹çµæŸ >>>>>>>
        
    except Exception as e:
        logger.error(f"å¢å¼·è‚¡ç¥¨åˆ†æAPIéŒ¯èª¤ï¼š{e}")
        return jsonify({"success": False, "message": f"åˆ†æå¤±æ•—ï¼š{str(e)}"})

@app.route('/api/news/search', methods=['POST'])
def api_news_search():
    """ä½¿ç”¨ Gemini Tools æœå°‹æœ€æ–°æ–°è"""
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query: 
            return jsonify({"success": False, "message": "è«‹æä¾›æœå°‹é—œéµå­—"})
        
        if not gemini_client: 
            return jsonify({"success": False, "message": "Gemini AI æœå‹™ä¸å¯ç”¨"})
        
        news_prompt = f"""è«‹æœå°‹é—œæ–¼ "{query}" çš„æœ€æ–°æ–°èå’Œäº‹ä»¶ï¼Œä¸¦æä¾›ä»¥ä¸‹è³‡è¨Šï¼š

1. æœå°‹æœ€è¿‘7å¤©å…§çš„ç›¸é—œæ–°è
2. é‡é»é—œæ³¨è²¡ç¶“ã€ç§‘æŠ€ã€æ”¿ç­–ç­‰å½±éŸ¿æŠ•è³‡çš„æ–°è
3. æ•´ç†æˆçµæ§‹åŒ–å ±å‘Š

è«‹æŒ‰ä»¥ä¸‹æ ¼å¼å›æ‡‰ï¼š

##  æœ€æ–°æ–°èæ‘˜è¦
[åˆ—å‡º3-5å‰‡æœ€é‡è¦çš„æ–°èï¼Œæ¯å‰‡åŒ…å«æ¨™é¡Œã€æ™‚é–“ã€é‡é»å…§å®¹](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)(150-200å­—)

##  å¸‚å ´å½±éŸ¿åˆ†æ
[åˆ†æé€™äº›æ–°èå°ç›¸é—œè‚¡ç¥¨æˆ–å¸‚å ´çš„æ½›åœ¨å½±éŸ¿](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)(100-150å­—)

##  æ©Ÿæœƒèˆ‡é¢¨éšª(æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)
[åŸºæ–¼æ–°èå…§å®¹æŒ‡å‡ºå¯èƒ½çš„æŠ•è³‡æ©Ÿæœƒå’Œé¢¨éšªé»](100-150å­—)

è«‹ç¢ºä¿è³‡è¨Šæº–ç¢ºä¸”å…·æœ‰æ™‚æ•ˆæ€§ã€‚"""

        config = genai_types.GenerateContentConfig(
            temperature=0.6,
            max_output_tokens=4000,
            tools=[genai_types.Tool(google_search=genai_types.GoogleSearch())],
            safety_settings=safety_settings_gemini
        )
        
        response = gemini_client.models.generate_content(
            model='models/gemini-2.5-flash',
            contents=news_prompt,
            config=config
        )
        
        if response and hasattr(response, 'text') and response.text:
            return jsonify({
                "success": True,
                "data": {
                    "query": query,
                    "news_analysis": response.text.strip(),
                    "search_time": datetime.now().isoformat()
                }
            })
        else:
            return jsonify({"success": False, "message": "ç„¡æ³•ç²å–æ–°èæœå°‹çµæœ"})
            
    except Exception as e:
        logger.error(f"æ–°èæœå°‹APIéŒ¯èª¤: {e}")
        return jsonify({"success": False, "message": f"æ–°èæœå°‹å¤±æ•—ï¼š{str(e)}"})

@app.route('/api/strategy-signals', methods=['GET'])
def api_strategy_signals():
    """
    (ä¿®æ­£ç‰ˆ) AIç­–ç•¥ä¿¡è™Ÿ API - ä¿®æ­£äº† Collation éŒ¯èª¤ä¸¦ JOIN ai_vs_user_games è¡¨ä»¥åŒ…å«å®Œæ•´ç­–ç•¥åŸºå› ä¾›å„²å­˜
    """
    try:
        market = request.args.get('market', 'TW')
        signal_type_filter = request.args.get('type', 'buy')
        
        signal_conditions = "('BUY', 'BUY_SELL')" if signal_type_filter == 'buy' else "('SELL', 'BUY_SELL')"
        
        # <<<< ä¿®æ­£é»ï¼šåœ¨ JOIN ON æ¢ä»¶ä¸­åŠ å…¥ COLLATE utf8mb4_unicode_ci ä¾†çµ±ä¸€æ¯”è¼ƒè¦å‰‡ >>>>
        query = f"""
        WITH RankedSignals AS (
            SELECT 
                bs.stock_ticker, bs.system_type, bs.strategy_rank, bs.signal_type, 
                bs.signal_reason, bs.buy_price, bs.sell_price, bs.return_pct, 
                bs.win_rate, bs.chart_path, bs.processed_at,
                a.ai_strategy_gene,
                a.strategy_details,
                a.game_start_date,
                a.game_end_date,
                a.total_trades,
                a.average_trade_return_pct,
                a.max_drawdown_pct,
                a.max_trade_drop_pct,
                a.max_trade_gain_pct,
                ROW_NUMBER() OVER(PARTITION BY bs.stock_ticker, bs.system_type ORDER BY bs.win_rate DESC, bs.return_pct DESC) as rn
            FROM 
                backtest_signals bs
            JOIN 
                ai_vs_user_games a ON bs.stock_ticker = a.stock_ticker COLLATE utf8mb4_unicode_ci
                                   AND bs.strategy_rank = a.strategy_rank
                                   AND bs.system_type = (CASE WHEN a.user_id = 2 THEN 'SystemA' ELSE 'SystemB' END) COLLATE utf8mb4_unicode_ci
            WHERE 
                bs.market_type = %s AND bs.signal_type IN {signal_conditions}
        )
        SELECT * FROM RankedSignals WHERE rn = 1 ORDER BY stock_ticker ASC, system_type ASC;
        """
        
        signals = execute_db_query(query, (market,), fetch_all=True)
        
        if signals:
            for signal in signals:
                if isinstance(signal.get('processed_at'), datetime):
                    signal['processed_at_str'] = signal['processed_at'].strftime('%Y-%m-%d %H:%M')
                if isinstance(signal.get('game_start_date'), date):
                    signal['game_start_date'] = signal['game_start_date'].isoformat()
                if isinstance(signal.get('game_end_date'), date):
                    signal['game_end_date'] = signal['game_end_date'].isoformat()
                
                if signal.get('win_rate') is not None: 
                    signal['win_rate'] = round(signal['win_rate'], 2)
                if signal.get('return_pct') is not None: 
                    signal['return_pct'] = round(signal['return_pct'], 2)

        return jsonify({"success": True, "data": signals or []})
        
    except Exception as e:
        logger.error(f"AIç­–ç•¥ä¿¡è™ŸAPIéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({"success": False, "message": "å…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤ï¼Œç­–ç•¥ä¿¡è™ŸæŸ¥è©¢å¤±æ•—"})

@app.route('/charts/<filename>')
def serve_chart(filename):
    """æä¾›åœ–è¡¨æª”æ¡ˆ"""
    try:
        return send_from_directory('charts', filename)
    except:
        return jsonify({"error": "Chart not found"}), 404

# ==============================================================================
# >>> ä»¥ä¸‹ç‚ºåŸå§‹ program.py çš„æ–°èæƒ…ç·’åˆ†æåŠŸèƒ½ (å®Œæ•´ä¿ç•™) <<<
# ==============================================================================
# ==============================================================================
#      >>> (æ–°æ•´åˆ) ä»¥ä¸‹ç‚ºæ–°èæƒ…ç·’åˆ†æåŠŸèƒ½ (å¾ update_news.py ç§»æ¤) <<<
# ==============================================================================

# --- å…¨å±€è¨­å®šèˆ‡é–‹é—œ ---
MOCK_TODAY = None # æ­£å¸¸åŸ·è¡Œæ™‚ç‚º None, å¯è¨­å®šç‚º datetime(YYYY, M, D).date() é€²è¡Œæ¸¬è©¦
MAX_TOTAL_HEADLINES = 100
MAX_HEADLINES_PER_TOPIC = 5
CSV_FILEPATH = '2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv'
TARGET_COMPANIES_AND_TOPICS = {
    "Apple": "AAPL", "Microsoft": "MSFT", "Nvidia": "NVDA", "Google": "GOOGL",
    "Amazon": "AMZN", "Meta": "META", "Tesla": "TSLA",
    "S&P 500": None, "Nasdaq": None, "Dow Jones": None, "Federal Reserve": "Fed",
    "inflation": "CPI", "jobs report": "nonfarm payrolls", "interest rates": None,
    "crude oil": "WTI", "US election": None, "trade war": "tariffs","war": "war",
    "Trump": "tariffs",
}

# FinBERT æ¨¡å‹å¿«å–
finbert_tokenizer = None
finbert_model = None

if not FINBERT_AVAILABLE:
    logger.warning("PyTorch æˆ– Transformers æœªå®‰è£ï¼ŒFinBERT æƒ…ç·’åˆ†æåŠŸèƒ½å°‡è¢«è·³éã€‚")

def load_finbert_model():
    """è¼‰å…¥ FinBERT æ¨¡å‹å’Œ Tokenizerï¼Œä¸¦é€²è¡Œå¿«å–ã€‚"""
    global finbert_tokenizer, finbert_model
    if finbert_model is None and FINBERT_AVAILABLE:
        try:
            logger.info("  [æ–°èåˆ†æ] é¦–æ¬¡è¼‰å…¥ FinBERT æ¨¡å‹ (ProsusAI/finbert)...")
            model_name = "ProsusAI/finbert"
            finbert_tokenizer = AutoTokenizer.from_pretrained(model_name)
            finbert_model = AutoModelForSequenceClassification.from_pretrained(model_name)
            logger.info("  [æ–°èåˆ†æ] FinBERT æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        except Exception as e:
            logger.error(f"  [æ–°èåˆ†æ] è¼‰å…¥ FinBERT æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    return finbert_model is not None

def analyze_titles_with_finbert(titles: list):
    """ä½¿ç”¨ FinBERT åˆ†ææ–°èæ¨™é¡Œçš„æƒ…ç·’ã€‚"""
    if not load_finbert_model():
        logger.warning("  [æ–°èåˆ†æ] FinBERT æ¨¡å‹ä¸å¯ç”¨ï¼Œè·³éæƒ…ç·’åˆ†æã€‚")
        return [f"[ANALYSIS_SKIPPED] {title}" for title in titles]
    
    logger.info(f"  [æ–°èåˆ†æ] æ­£åœ¨ä½¿ç”¨ FinBERT åˆ†æ {len(titles)} æ¢è‹±æ–‡æ–°èæ¨™é¡Œ...")
    analyzed_titles = []
    
    for title in titles:
        try:
            inputs = finbert_tokenizer(title, padding=True, truncation=True, return_tensors='pt')
            outputs = finbert_model(**inputs)
            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
            prediction_idx = torch.argmax(probabilities).item()
            label = finbert_model.config.id2label[prediction_idx]
            score = probabilities[0][0].item() - probabilities[0][1].item() # Positive - Negative
            analyzed_titles.append(f"[{label.upper()}, Score: {score:+.2f}] {title}")
        except Exception as e:
            logger.error(f"  [æ–°èåˆ†æ] FinBERT åˆ†ææ¨™é¡Œ '{title}' æ™‚å‡ºéŒ¯: {e}")
            analyzed_titles.append(f"[ANALYSIS_FAILED] {title}")
    
    logger.info("  [æ–°èåˆ†æ] FinBERT åˆ†æå®Œæˆã€‚")
    return analyzed_titles

def get_this_weeks_english_news(target_topics: dict):
    """æŠ“å–æ–°èä¸¦è¿”å›æ¨™é¡Œåˆ—è¡¨åŠçœŸå¯¦æ–°èçš„æ—¥æœŸç¯„åœã€‚"""
    real_today = datetime.now(pytz.utc)
    real_start_date = real_today - timedelta(days=7)
    real_date_range_str = f"{real_start_date.strftime('%Y-%m-%d')} to {real_today.strftime('%Y-%m-%d')}"
    
    if MOCK_TODAY:
        logger.info(f"\n--- [æ–°èåˆ†æ] æ¨¡æ“¬æ¸¬è©¦æ¨¡å¼å·²å•Ÿå‹• (æ¨¡æ“¬æ—¥æœŸ: {MOCK_TODAY.strftime('%Y-%m-%d')}) ---")
        logger.info(f"  [æ–°èåˆ†æ] å°‡æŠ“å–çœŸå¯¦ä¸–ç•Œè¿‘æœŸ ({real_date_range_str}) çš„æ–°èä½œç‚ºåˆ†æææ–™ã€‚")
    else:
        logger.info(f"\n--- [æ–°èåˆ†æ] æ­£å¸¸æ¨¡å¼å·²å•Ÿå‹• ---")
        logger.info(f"  [æ–°èåˆ†æ] å°‡æŠ“å–çœŸå¯¦ä¸–ç•Œè¿‘æœŸ ({real_date_range_str}) çš„æ–°èä½œç‚ºåˆ†æææ–™ã€‚")
    
    seen_titles = set()
    topic_items = list(target_topics.items())
    total_headlines_collected = 0
    
    for i, (company_or_topic, ticker_or_keyword) in enumerate(topic_items):
        if total_headlines_collected >= MAX_TOTAL_HEADLINES:
            logger.info(f"\n  [æ–°èåˆ†æ] å·²é”åˆ°å…¨å±€æ–°èä¸Šé™ ({MAX_TOTAL_HEADLINES}æ¢)ï¼Œåœæ­¢æŠ“å–ã€‚")
            break
        
        logger.info(f"  [æ–°èåˆ†æ] [é€²åº¦ {i+1}/{len(topic_items)}] æŸ¥è©¢: '{company_or_topic}' (å·²æ”¶é›†: {total_headlines_collected}æ¢)...")
        
        primary_query = f'"{company_or_topic}" {ticker_or_keyword} stock' if ticker_or_keyword else f'"{company_or_topic}" stock market'
        url = f"https://news.google.com/rss/search?q={urllib.parse.quote_plus(primary_query)}&hl=en-US&gl=US&ceid=US:en"
        
        try:
            feed = feedparser.parse(url)
            if feed.entries:
                headlines_from_this_topic = 0
                for entry in feed.entries:
                    if headlines_from_this_topic >= MAX_HEADLINES_PER_TOPIC or total_headlines_collected >= MAX_TOTAL_HEADLINES:
                        break
                    
                    try:
                        published_dt = datetime(*entry.published_parsed[:6])
                        published_dt_utc = pytz.utc.localize(published_dt)
                        if real_start_date <= published_dt_utc <= real_today:
                            title = entry.title.strip()
                            if title not in seen_titles:
                                seen_titles.add(title)
                                headlines_from_this_topic += 1
                                total_headlines_collected += 1
                    except Exception:
                        continue
                
                if headlines_from_this_topic > 0:
                    logger.info(f"  âœ”ï¸ [æ–°èåˆ†æ] æŸ¥è©¢æˆåŠŸï¼Œç‚ºæ­¤ä¸»é¡Œæ–°å¢ {headlines_from_this_topic} æ¢æ–°èã€‚")
        except Exception as e:
            logger.error(f"  -> [æ–°èåˆ†æ] æŠ“å–æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        if i < len(topic_items) - 1:
            time.sleep(random.uniform(0.5, 1.2))
    
    if seen_titles:
        logger.info(f"\nã€æ–°èåˆ†ææŠ“å–å®Œæˆã€‘ç¸½å…±æ”¶é›†åˆ° {len(seen_titles)} æ¢ä¸é‡è¤‡çš„ç›¸é—œè‹±æ–‡æ–°èæ¨™é¡Œã€‚")
    else:
        logger.warning("\nã€æ–°èåˆ†ææŠ“å–å®Œæˆã€‘æœªèƒ½æ‰¾åˆ°ä»»ä½•ç¬¦åˆæ¢ä»¶çš„æ–°èã€‚")
    
    return list(seen_titles), real_date_range_str

def get_sentiment_and_translate_summary(analyzed_titles: list, simulated_week_key: str, real_news_date_range: str, few_shot_examples=None):
    """ä½¿ç”¨"æ™‚ç©ºæ©‹æ¥æç¤º"è®“ Gemini é€²è¡Œæ¨¡æ“¬åˆ†æã€‚"""
    if not gemini_client:
        return None, "Gemini clientæœªé…ç½®"
    
    if not analyzed_titles:
        return None, "åˆ†æå¾Œçš„æ–°èæ¨™é¡Œåˆ—è¡¨ç‚ºç©º"
    
    example_prompt_part = ""
    if few_shot_examples:
        example_prompt_part = "Here are some historical rating examples for your reference (in Traditional Chinese):\n"
        for ex_date, ex_score, ex_summary in few_shot_examples:
            example_prompt_part += f"- Week: {ex_date}; Sentiment Score: {ex_score}; Summary: {ex_summary}\n"
        example_prompt_part += "\n"
    
    news_titles_str = "\n".join([f"- {title}" for title in analyzed_titles])
    
    prompt = f"""
You are an expert financial analyst participating in a market simulation.
**CONTEXT:**
- The **simulated week** you are analyzing is: **{simulated_week_key}**
- To perform your analysis, you have been provided with **real-world news headlines** from the recent period of: **{real_news_date_range}**
**YOUR TASK:**
You must **interpret these real-world events as if they were happening during the simulated week**. Synthesize the key themes (e.g., inflation, Fed policy, tech trends, geopolitical events) and generate a market analysis *for the simulated week*.
The headlines below are pre-analyzed by FinBERT. The format is [SENTIMENT_LABEL, FinBERT_Score] Original Headline. Use this as a key reference for sentiment.
**REQUIRED OUTPUT FORMAT:**
1. **Sentiment Score**: A single integer from 0 to 100 representing the market sentiment for the **simulated week**. (0=fear, 50=neutral, 100=greed).
2. **News Summary (Traditional Chinese)**: A translated summary of the key events, written *as if* they occurred in the simulated week. Separate items with a semicolon.
---
**Provided Real-World News Headlines:**
{news_titles_str}
---
**Now, provide the analysis in the required format for the simulated week of {simulated_week_key}:**
Sentiment Score: [A single integer between 0 and 100]
News Summary (Traditional Chinese): [Your translated summary for the simulated week]
"""
    
    try:
        logger.info(f"\n  [æ–°èåˆ†æ] ç™¼é€ {len(analyzed_titles)} æ¢æ–°èåˆ° Gemini (æ¨¡æ“¬é€±: {simulated_week_key}, çœŸå¯¦æ–°èæº: {real_news_date_range})...")
        
        response = gemini_client.models.generate_content(
            model="models/gemini-2.5-flash",
            contents=prompt,
            config=genai_types.GenerateContentConfig(temperature=0.3, max_output_tokens=1000)
        )
        
        content = response.text
        
        score_match = re.search(r"Sentiment Score:\s*(\d+)", content, re.IGNORECASE)
        summary_match = re.search(r"News Summary \(Traditional Chinese\):\s*(.+)", content, re.IGNORECASE | re.DOTALL)
        
        sentiment_score_val = int(score_match.group(1)) if score_match else None
        
        if summary_match:
            news_summary_val = summary_match.group(1).strip()
            news_summary_val = re.sub(r'^\s*-\s*', '', news_summary_val)
            news_summary_val = news_summary_val.replace('\n', ' ').replace(';', 'ï¼›').strip()
            news_summary_val = re.sub(r'\s*ï¼›\s*', 'ï¼›', news_summary_val)
            news_summary_val = re.sub(r'ï¼›$', '', news_summary_val)
        else:
            news_summary_val = "æœªèƒ½ç”Ÿæˆæ‘˜è¦"
        
        logger.info(f"  [æ–°èåˆ†æ] å·²è§£æ ({simulated_week_key}): åˆ†æ•¸={sentiment_score_val}, æ‘˜è¦='{news_summary_val[:100]}...'")
        
        return sentiment_score_val, news_summary_val
        
    except Exception as e:
        logger.error(f"  [æ–°èåˆ†æ] Gemini API èª¿ç”¨æˆ–è§£ææ™‚å‡ºéŒ¯: {e}")
        return None, f"Gemini APIèª¿ç”¨æˆ–è§£æéŒ¯èª¤: {str(e)}"

def get_few_shot_examples(csv_filepath, num_examples=5):
    """å¾ CSV è®€å– few-shot å­¸ç¿’çš„ç¯„ä¾‹ã€‚"""
    try:
        df = pd.read_csv(csv_filepath, encoding='utf-8-sig')
        if df.empty: return []
        df_valid = df.dropna(subset=['æƒ…ç·’åˆ†æ•¸', 'é‡å¤§æ–°èæ‘˜è¦']).tail(num_examples)
        return [(str(r['å¹´/é€±']), r['æƒ…ç·’åˆ†æ•¸'], str(r['é‡å¤§æ–°èæ‘˜è¦'])) for _, r in df_valid.iterrows()]
    except Exception as e:
        logger.warning(f"[æ–°èåˆ†æ] è®€å– few-shot ç¯„ä¾‹æ™‚å‡ºéŒ¯: {e}")
        return []

def get_current_week_key():
    """æ ¹æ“šæ˜¯å¦åœ¨æ¨¡æ“¬æ¨¡å¼ï¼Œç²å–æœ¬é€±çš„æ—¥æœŸéµå€¼ã€‚"""
    today = MOCK_TODAY if MOCK_TODAY else datetime.now().date()
    start_of_week = today - timedelta(days=today.weekday())
    end_of_week = start_of_week + timedelta(days=6)
    return f"{start_of_week.strftime('%Y/%m/%d')}-{end_of_week.strftime('%Y/%m/%d')}"

def update_sentiment_csv(csv_filepath, target_topics):
    """ä¸»æµç¨‹å‡½å¼ï¼šæ•´åˆæ‰€æœ‰æ­¥é©Ÿä¾†æ›´æ–° CSVã€‚"""
    if not gemini_client:
        logger.error("[æ–°èåˆ†æ] Gemini client æœªè¼‰å…¥ï¼Œä»»å‹™çµ‚æ­¢ã€‚")
        return
    
    simulated_week_key = get_current_week_key()
    logger.info(f"[æ–°èåˆ†æ] ç›®æ¨™æ¨¡æ“¬é€±çš„éµå€¼ç‚º: {simulated_week_key}")
    
    raw_english_titles, real_date_range = get_this_weeks_english_news(target_topics)
    if not raw_english_titles:
        logger.warning(f"[æ–°èåˆ†æ] ç„¡æ³•ç²å–è¿‘æœŸçœŸå¯¦æ–°èï¼Œæµç¨‹çµ‚æ­¢ã€‚")
        return
    
    analyzed_titles = analyze_titles_with_finbert(raw_english_titles)
    few_shot_examples = get_few_shot_examples(csv_filepath, num_examples=5)
    
    score, summary_chinese = get_sentiment_and_translate_summary(analyzed_titles, simulated_week_key, real_date_range, few_shot_examples)
    
    if score is not None and summary_chinese and "æœªèƒ½ç”Ÿæˆæ‘˜è¦" not in summary_chinese:
        try:
            df = pd.read_csv(csv_filepath, encoding='utf-8-sig') if os.path.exists(csv_filepath) else pd.DataFrame(columns=['å¹´/é€±', 'æƒ…ç·’åˆ†æ•¸', 'é‡å¤§æ–°èæ‘˜è¦'])
            df['å¹´/é€±'] = df['å¹´/é€±'].astype(str).str.strip()
            week_key_stripped = simulated_week_key.strip()
            
            week_exists_mask = df['å¹´/é€±'] == week_key_stripped
            
            if week_exists_mask.any():
                logger.info(f"\n[æ–°èåˆ†æ] æ›´æ–°æ¨¡æ“¬é€± ({week_key_stripped}) çš„æƒ…ç·’åˆ†æ•¸èˆ‡æ‘˜è¦...")
                df.loc[week_exists_mask, 'æƒ…ç·’åˆ†æ•¸'] = score
                df.loc[week_exists_mask, 'é‡å¤§æ–°èæ‘˜è¦'] = summary_chinese
            else:
                logger.info(f"\n[æ–°èåˆ†æ] æ–°å¢æ¨¡æ“¬é€± ({week_key_stripped}) çš„æƒ…ç·’åˆ†æ•¸èˆ‡æ‘˜è¦...")
                new_row = pd.DataFrame([{'å¹´/é€±': week_key_stripped, 'æƒ…ç·’åˆ†æ•¸': score, 'é‡å¤§æ–°èæ‘˜è¦': summary_chinese}])
                df = pd.concat([df, new_row], ignore_index=True)
            
            df.drop_duplicates(subset=['å¹´/é€±'], keep='last', inplace=True)
            df.to_csv(csv_filepath, index=False, encoding='utf-8-sig')
            logger.info(f"[æ–°èåˆ†æ] å·²æˆåŠŸå°‡ {week_key_stripped} çš„è³‡æ–™å¯«å…¥/æ›´æ–°åˆ° CSVï¼")
            
        except Exception as e:
            logger.error(f"[æ–°èåˆ†æ] å¯«å…¥ CSV æ™‚å‡ºéŒ¯: {e}")
    else:
        logger.error(f"\n[æ–°èåˆ†æ] æœªèƒ½å¾ Gemini å–å¾—æœ‰æ•ˆçš„æ¨¡æ“¬åˆ†æçµæœï¼š{summary_chinese}")


# ==============================================================================
#           >>> ä»¥ä¸‹ç‚ºæ–°åŠ å…¥çš„æ’ç¨‹å›æ¸¬åŠŸèƒ½ (ç¨ç«‹å€å¡Š) <<<
# ==============================================================================

class StrategyBacktesterWithSignals:
    """ç­–ç•¥å›æ¸¬å™¨ - (å¾ backtest.py é·ç§»ä¸¦æ•´åˆï¼Œä½¿ç”¨ logger)"""
    
    def __init__(self):
        self.backtest_months = 36
        self.signal_check_days = 5
        self.start_date, self.end_date = self._get_date_range()
        self.charts_dir = "charts"
        self.data_cache_a = {}
        self.data_cache_b = {}
        os.makedirs(self.charts_dir, exist_ok=True)
        logger.info(f"ğŸ¯ [æ’ç¨‹å›æ¸¬] å›æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“… [æ’ç¨‹å›æ¸¬] å›æ¸¬æœŸé–“: {self.start_date} ~ {self.end_date}")
        logger.info(f"ğŸ“ [æ’ç¨‹å›æ¸¬] åœ–è¡¨ç›®éŒ„: {self.charts_dir}")
    
    def _get_date_range(self):
        end_date = datetime.now(pytz.timezone('Asia/Taipei')).date()
        start_date = end_date - timedelta(days=self.backtest_months * 30)
        return start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")
    
    def create_signals_table(self):
        """æª¢æŸ¥ä¸¦å‰µå»º backtest_signals è³‡æ–™åº«è¡¨"""
        query = """
        CREATE TABLE IF NOT EXISTS `backtest_signals` (
          `id` INT AUTO_INCREMENT PRIMARY KEY, `stock_ticker` VARCHAR(20) NOT NULL,
          `stock_name` VARCHAR(100), `market_type` VARCHAR(10) NOT NULL,
          `system_type` VARCHAR(20) NOT NULL, `strategy_rank` INT NOT NULL,
          `signal_type` ENUM('BUY', 'SELL', 'BUY_SELL') NOT NULL, `signal_reason` TEXT,
          `buy_price` FLOAT NULL, `sell_price` FLOAT NULL, `return_pct` FLOAT,
          `win_rate` FLOAT NULL, `chart_path` VARCHAR(255), `processed_at` DATETIME NOT NULL,
          INDEX `idx_market_signal` (`market_type`, `signal_type`)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;"""
        try:
            execute_db_query(query)
            logger.info("âœ… [æ’ç¨‹å›æ¸¬] `backtest_signals` è¡¨å·²ç¢ºèªå­˜åœ¨")
        except Exception as e:
            logger.error(f"âŒ [æ’ç¨‹å›æ¸¬] å‰µå»º `backtest_signals` è¡¨å¤±æ•—: {e}")

    def save_results_to_db(self, results):
        """å°‡æœ‰ä¿¡è™Ÿçš„çµæœå„²å­˜åˆ°è³‡æ–™åº«"""
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cursor:
                cursor.execute("TRUNCATE TABLE backtest_signals")
                logger.info("ğŸ—‘ï¸ [æ’ç¨‹å›æ¸¬] å·²æ¸…ç©ºèˆŠçš„ä¿¡è™Ÿè³‡æ–™")
                query = """INSERT INTO backtest_signals (stock_ticker, stock_name, market_type, system_type, strategy_rank, 
                    signal_type, signal_reason, buy_price, sell_price, return_pct, win_rate, chart_path, processed_at) 
                    VALUES (%(ticker)s, NULL, %(market_type)s, %(system)s, %(rank)s, %(signal_type)s, %(signal_reason)s, 
                    %(buy_price)s, %(sell_price)s, %(return_pct)s, %(win_rate)s, %(chart_path)s, %(processed_at)s)"""
                
                to_save = []
                for res in results:
                    if res.get('has_recent_signal'):
                        signal_type = 'BUY_SELL' if res['has_buy_signal'] and res['has_sell_signal'] else 'BUY' if res['has_buy_signal'] else 'SELL'
                        res_copy = res.copy()
                        res_copy['signal_type'] = signal_type
                        res_copy['chart_path'] = res_copy.get('chart_path', None)
                        to_save.append(res_copy)
                
                if to_save:
                    cursor.executemany(query, to_save)
                    conn.commit()
                    logger.info(f"ğŸ’¾ [æ’ç¨‹å›æ¸¬] æˆåŠŸå°‡ {len(to_save)} ç­†æ–°ä¿¡è™Ÿå„²å­˜åˆ°è³‡æ–™åº«")
                else:
                    logger.info("â„¹ï¸ [æ’ç¨‹å›æ¸¬] æœ¬æ¬¡é‹è¡Œæ²’æœ‰ç™¼ç¾ä»»ä½•æ–°ä¿¡è™Ÿå¯å„²å­˜")
        except Exception as e:
            if conn: conn.rollback()
            logger.error(f"âŒ [æ’ç¨‹å›æ¸¬] å„²å­˜ä¿¡è™Ÿåˆ°è³‡æ–™åº«å¤±æ•—: {e}\n{traceback.format_exc()}")
        finally:
            if conn: conn.close()

    def get_all_strategies(self):
        """å¾è³‡æ–™åº«ç²å–æ‰€æœ‰å¾…å›æ¸¬çš„ç­–ç•¥"""
        query = """SELECT user_id, market_type, stock_ticker, ai_strategy_gene, strategy_details, strategy_rank
                   FROM ai_vs_user_games WHERE strategy_rank > 0 AND ai_strategy_gene IS NOT NULL 
                   AND (user_id = 2 OR user_id = 3) ORDER BY stock_ticker, user_id, strategy_rank"""
        strategies = execute_db_query(query, fetch_all=True)
        if strategies:
            logger.info(f"ğŸ“Š [æ’ç¨‹å›æ¸¬] å¾è³‡æ–™åº«ç²å–åˆ° {len(strategies)} å€‹ç­–ç•¥")
            return strategies
        logger.warning("âŒ [æ’ç¨‹å›æ¸¬] è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç­–ç•¥")
        return []
    
    def parse_strategy_gene(self, gene_json_str):
        try:
            return json.loads(gene_json_str) if isinstance(gene_json_str, str) else None
        except (json.JSONDecodeError, TypeError):
            return None
    
    def backtest_system_a_with_signals(self, gene, ticker):
        try:
            if ticker in self.data_cache_a:
                prices, dates, stock_df, vix_series, sentiment_series = self.data_cache_a[ticker]
            else:
                prices, dates, stock_df, vix_series, sentiment_series = ga_load_data(ticker, start_date=self.start_date, end_date=self.end_date, verbose=False)
                if prices is not None and len(prices) > 0: self.data_cache_a[ticker] = (prices, dates, stock_df, vix_series, sentiment_series)
            if not prices or len(prices) < 30: return None, None, None, None, None
            precalculated, ready = ga_precompute_indicators(stock_df, vix_series, STRATEGY_CONFIG_SHARED_GA, sentiment_series=sentiment_series, verbose=False)
            if not ready: return None, None, None, None, None
            def get_ind(name, g_indices, opt_keys):
                params = [GA_PARAMS_CONFIG[k][gene[g_idx]] for g_idx, k in zip(g_indices, opt_keys)]
                key = tuple(params) if len(params) > 1 else params[0]
                return np.array(precalculated.get(name, {}).get(key, [np.nan]*len(prices)), dtype=np.float64)
            result = run_strategy_numba_core(np.array(gene, dtype=np.float64), np.array(prices, dtype=np.float64),
                get_ind('vix_ma', [GENE_MAP['vix_ma_p']], ['vix_ma_period_options']), get_ind('sentiment_ma', [GENE_MAP['sentiment_ma_p']], ['sentiment_ma_period_options']),
                get_ind('rsi', [GENE_MAP['rsi_p']], ['rsi_period_options']), get_ind('adx', [GENE_MAP['adx_p']], ['adx_period_options']),
                get_ind('bbl', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']), get_ind('bbm', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                get_ind('bbu', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']), get_ind('ma', [GENE_MAP['ma_s_p']], ['ma_period_options']),
                get_ind('ma', [GENE_MAP['ma_l_p']], ['ma_period_options']), get_ind('ema_s', [GENE_MAP['ema_s_p']], ['ema_s_period_options']),
                get_ind('ema_m', [GENE_MAP['ema_m_p']], ['ema_m_period_options']), get_ind('ema_l', [GENE_MAP['ema_l_p']], ['ema_l_period_options']),
                get_ind('atr', [GENE_MAP['atr_p']], ['atr_period_options']), get_ind('atr_ma', [GENE_MAP['atr_p']], ['atr_period_options']),
                get_ind('kd_k', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']], ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                get_ind('kd_d', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']], ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                get_ind('macd_line', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']], ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                get_ind('macd_signal', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']], ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                GA_PARAMS_CONFIG.get('commission_rate', 0.003), 61)
            if result is None or len(result) < 6: return None, None, None, None, None
            portfolio_values, buy_indices, buy_prices, sell_indices, sell_prices, _ = result
            buy_signals = [{'date': dates[i], 'price': buy_prices[idx], 'index': i} for idx, i in enumerate(buy_indices) if i < len(dates) and idx < len(buy_prices)]
            sell_signals = [{'date': dates[i], 'price': sell_prices[idx], 'index': i} for idx, i in enumerate(sell_indices) if i < len(dates) and idx < len(sell_prices)]
            return portfolio_values, dates, prices, buy_signals, sell_signals
        except Exception: return None, None, None, None, None

    def backtest_system_b_with_signals(self, gene, ticker):
        try:
            if ticker in self.data_cache_b: prices, dates, stock_df, vix_series = self.data_cache_b[ticker]
            else:
                prices, dates, stock_df, vix_series = load_stock_data_b(ticker, start_date=self.start_date, end_date=self.end_date, verbose=False)
                if prices is not None and len(prices) > 0: self.data_cache_b[ticker] = (prices, dates, stock_df, vix_series)
            if not prices or len(prices) < 30: return None, None, None, None, None
            precalculated, ready = precompute_indicators_b(stock_df, vix_series, STRATEGY_CONFIG_B, verbose=False)
            if not ready: return None, None, None, None, None
            rsi_buy_entry, rsi_exit, vix_threshold = gene[0], gene[1], gene[2]
            low_vol_exit, rsi_period_choice, vix_ma_choice = int(gene[3]), int(gene[4]), int(gene[5])
            bb_len_choice, bb_std_choice, adx_thresh, high_vol_entry_choice = int(gene[6]), int(gene[7]), gene[8], int(gene[9])
            rsi_p, vix_ma_p = STRATEGY_CONFIG_B['rsi_period_options'][rsi_period_choice], STRATEGY_CONFIG_B['vix_ma_period_options'][vix_ma_choice]
            bb_l, bb_s = STRATEGY_CONFIG_B['bb_length_options'][bb_len_choice], STRATEGY_CONFIG_B['bb_std_options'][bb_std_choice]
            rsi_arr, vix_ma_arr = np.array(precalculated['rsi'][rsi_p], dtype=np.float64), np.array(precalculated['vix_ma'][vix_ma_p], dtype=np.float64)
            bbl_arr, bbm_arr = np.array(precalculated['bbl'][(bb_l, bb_s)], dtype=np.float64), np.array(precalculated['bbm'][(bb_l, bb_s)], dtype=np.float64)
            adx_arr, ma_s_arr, ma_l_arr = np.array(precalculated['fixed']['adx_list'], dtype=np.float64), np.array(precalculated['fixed']['ma_short_list'], dtype=np.float64), np.array(precalculated['fixed']['ma_long_list'], dtype=np.float64)
            def get_valid_iloc(arr):
                valid_indices = np.where(np.isfinite(arr))[0]
                return valid_indices[0] if len(valid_indices) > 0 else len(prices)
            start_iloc = max(get_valid_iloc(arr) for arr in [rsi_arr, vix_ma_arr, bbl_arr, bbm_arr, adx_arr, ma_s_arr, ma_l_arr]) + 1
            if start_iloc >= len(prices): return None, None, None, None, None
            result = run_strategy_numba_core_b(float(rsi_buy_entry), float(rsi_exit), float(adx_thresh), float(vix_threshold), low_vol_exit, high_vol_entry_choice,
                float(STRATEGY_CONFIG_B['commission_pct']), np.array(prices, dtype=np.float64), rsi_arr, bbl_arr, bbm_arr, adx_arr, vix_ma_arr, ma_s_arr, ma_l_arr, start_iloc)
            if result is None or len(result) < 7: return None, None, None, None, None
            portfolio_values, buy_indices, _, _, sell_indices, _, _ = result
            buy_signals = [{'date': dates[i], 'price': prices[i], 'index': i} for i in buy_indices if i < len(dates)]
            sell_signals = [{'date': dates[i], 'price': prices[i], 'index': i} for i in sell_indices if i < len(dates)]
            return portfolio_values, dates, prices, buy_signals, sell_signals
        except Exception: return None, None, None, None, None
    
    def check_recent_signals(self, signals, signal_type_text):
        if not signals: return False, f"ç„¡{signal_type_text}ä¿¡è™Ÿ", None
        recent, latest_price, today = [], None, datetime.now().date()
        for signal in signals[-self.signal_check_days:]:
            s_date = pd.to_datetime(signal['date']).date()
            days_diff = (today - s_date).days
            if 0 <= days_diff < self.signal_check_days:
                day_str = {0: "ä»Šå¤©", 1: "æ˜¨å¤©"}.get(days_diff, f"{days_diff}å¤©å‰")
                recent.append(f"{day_str}({s_date})")
                latest_price = signal['price']
        return (True, f"åœ¨ {', '.join(recent)} æª¢æ¸¬åˆ°{signal_type_text}ä¿¡è™Ÿ", latest_price) if recent else (False, f"è¿‘æœŸç„¡{signal_type_text}ä¿¡è™Ÿ", None)

    def create_strategy_backtest_chart(self, ticker, system_type, rank, portfolio, prices, dates, buys, sells, details, final_return):
        try:
            fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, row_heights=[0.7, 0.3],
                                subplot_titles=[f'{ticker} {system_type} Rank{rank} - è‚¡åƒ¹èˆ‡è²·è³£é»', 'æŠ•è³‡çµ„åˆåƒ¹å€¼æ›²ç·š'])
            if prices is not None and len(prices) > 0 and dates is not None: fig.add_trace(go.Scatter(x=dates, y=prices, mode='lines', name='è‚¡åƒ¹', line=dict(color='white', width=1)), row=1, col=1)
            if buys: fig.add_trace(go.Scatter(x=[s['date'] for s in buys], y=[s['price'] for s in buys], mode='markers', name='è²·å…¥é»', marker=dict(symbol='triangle-up', size=12, color='lime')), row=1, col=1)
            if sells: fig.add_trace(go.Scatter(x=[s['date'] for s in sells], y=[s['price'] for s in sells], mode='markers', name='è³£å‡ºé»', marker=dict(symbol='triangle-down', size=12, color='red')), row=1, col=1)
            if portfolio is not None and portfolio.size > 0 and dates is not None:
                ret_pct = (portfolio - 1.0) * 100
                line_color = 'lime' if final_return >= 0 else 'red'
                fig.add_trace(go.Scatter(x=dates, y=ret_pct, mode='lines', name=f'å ±é…¬ç‡ ({final_return:.2f}%)', line=dict(color=line_color, width=2), fill='tozeroy' if final_return >= 0 else None), row=2, col=1)
            fig.update_layout(title=f"{ticker} {system_type} Rank{rank} (å ±é…¬ç‡: {final_return:.2f}%)", template='plotly_dark', height=800)
            filename = f"{ticker.replace('.', '_')}_{system_type}_Rank{rank}_backtest.html"
            path = os.path.join(self.charts_dir, filename)
            fig.write_html(path)
            return path
        except Exception as e:
            logger.error(f"    âŒ [æ’ç¨‹å›æ¸¬] ç‚º {ticker} å‰µå»ºåœ–è¡¨å¤±æ•—: {e}")
            return None

    def _calculate_win_rate(self, buy_signals, sell_signals):
        if not buy_signals or not sell_signals: return 0.0
        buys, sells = sorted(buy_signals, key=lambda x: x['index']), sorted(sell_signals, key=lambda x: x['index'])
        total, wins = 0, 0
        num_trades = min(len(buys), len(sells))
        for i in range(num_trades):
            if sells[i]['index'] > buys[i]['index']:
                total += 1
                if sells[i]['price'] > buys[i]['price']: wins += 1
        return (wins / total) * 100 if total > 0 else 0.0

    def process_single_strategy(self, strategy):
        try:
            ticker, sys_type, rank = strategy['stock_ticker'], "SystemA" if strategy['user_id'] == 2 else "SystemB", strategy['strategy_rank']
            logger.info(f"\n[{self.current_strategy_index}/{self.total_strategies}] ğŸ“Š [æ’ç¨‹å›æ¸¬] æ­£åœ¨å›æ¸¬ {ticker} {sys_type} rank{rank}...")
            gene = self.parse_strategy_gene(strategy['ai_strategy_gene'])
            if not gene:
                logger.warning(f"    âš ï¸ ç„¡æ³•è§£æ {ticker} çš„ç­–ç•¥åŸºå› ï¼Œå·²è·³éã€‚")
                return None
            
            portfolio, dates, prices, buys, sells = (None,)*5
            if sys_type == "SystemA": portfolio, dates, prices, buys, sells = self.backtest_system_a_with_signals(gene, ticker)
            else: portfolio, dates, prices, buys, sells = self.backtest_system_b_with_signals(gene, ticker)
            
            if portfolio is None or buys is None or sells is None:
                logger.warning(f"    âš ï¸ {ticker} å›æ¸¬æ•¸æ“šä¸è¶³æˆ–å¤±æ•—ï¼Œå·²è·³éã€‚")
                return None
            
            final_return = (portfolio[-1] - 1.0) * 100 if portfolio.size > 0 else 0.0
            win_rate = self._calculate_win_rate(buys, sells)
            has_buy, buy_reason, buy_price = self.check_recent_signals(buys, 'è²·å…¥')
            has_sell, sell_reason, sell_price = self.check_recent_signals(sells, 'è³£å‡º')
            has_signal = has_buy or has_sell
            signal_reason = " | ".join(filter(None, [buy_reason if has_buy else None, sell_reason if has_sell else None]))
            
            result = {'ticker': ticker, 'system': sys_type, 'rank': rank, 'market_type': strategy['market_type'], 'return_pct': final_return, 'win_rate': win_rate,
                      'has_recent_signal': has_signal, 'signal_reason': signal_reason, 'has_buy_signal': has_buy, 'buy_reason': buy_reason,
                      'has_sell_signal': has_sell, 'sell_reason': sell_reason, 'buy_price': buy_price, 'sell_price': sell_price,
                      'processed_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
            
            if has_signal:
                chart_path = self.create_strategy_backtest_chart(ticker, sys_type, rank, portfolio, prices, dates, buys, sells, strategy.get('strategy_details', ''), final_return)
                if chart_path: result['chart_path'] = os.path.basename(chart_path)
            
            return result
        except Exception as e:
            logger.error(f"    âŒ [æ’ç¨‹å›æ¸¬] è™•ç†ç­–ç•¥ {strategy.get('stock_ticker')} å¤±æ•—: {e}\n{traceback.format_exc()}")
            return None

    def run_full_backtest_with_signals(self):
        logger.info("ğŸš€ [æ’ç¨‹å›æ¸¬] é–‹å§‹åŸ·è¡Œç­–ç•¥æ‰¹é‡å›æ¸¬...")
        start_time = time.time()
        strategies = self.get_all_strategies()
        if not strategies: return []
        
        self.total_strategies = len(strategies)
        logger.info(f"ğŸ“‹ [æ’ç¨‹å›æ¸¬] æ‰¾åˆ° {self.total_strategies} å€‹ç­–ç•¥å¾…å›æ¸¬")
        
        results = []
        for i, strategy in enumerate(strategies, 1):
            self.current_strategy_index = i
            result = self.process_single_strategy(strategy)
            if result: results.append(result)
        
        elapsed = time.time() - start_time
        logger.info("\n" + "=" * 70 + "\nğŸ“Š [æ’ç¨‹å›æ¸¬] å›æ¸¬ç¸½çµ\n" + "=" * 70)
        signals_found = [res for res in results if res['has_recent_signal']]
        logger.info(f"â±ï¸ [æ’ç¨‹å›æ¸¬] ç¸½è€—æ™‚: {elapsed:.2f} ç§’")
        logger.info(f"ğŸ¯ [æ’ç¨‹å›æ¸¬] ç™¼ç¾ä¿¡è™Ÿ: {len(signals_found)}")
        
        if signals_found:
            logger.info("\nğŸ¯ [æ’ç¨‹å›æ¸¬] ã€è¿‘æœŸæœ‰è²·è³£ä¿¡è™Ÿçš„ç­–ç•¥ã€‘")
            for res in signals_found:
                buy_info = f" @ {res['buy_price']:.2f}" if res['has_buy_signal'] and res['buy_price'] is not None else ""
                sell_info = f" @ {res['sell_price']:.2f}" if res['has_sell_signal'] and res['sell_price'] is not None else ""
                logger.info(f"  - {res['ticker']} | {res['system']} R{res['rank']} | å‹ç‡: {res['win_rate']:.2f}% | ğŸŸ¢:{res['has_buy_signal']}{buy_info} | ğŸ”´:{res['has_sell_signal']}{sell_info}")
        
        return results

def run_scheduled_backtest():
    """æ¯æ—¥è‡ªå‹•åŸ·è¡Œçš„ä¸»ä»»å‹™ (åœ¨ App Context ä¸­é‹è¡Œ)"""
    with app.app_context():
        logger.info("="*50 + f"\nâ° [æ’ç¨‹ä»»å‹™] å•Ÿå‹•æ¯æ—¥è‡ªå‹•å›æ¸¬... (å°ç£æ™‚é–“: {datetime.now(pytz.timezone('Asia/Taipei'))})\n" + "="*50)
        try:
            if not os.getenv("DB_PASSWORD"):
                logger.error("âŒ [æ’ç¨‹ä»»å‹™] éŒ¯èª¤: DB_PASSWORD ç’°å¢ƒè®Šæ•¸æœªè¨­å®šã€‚ä»»å‹™ä¸­æ­¢ã€‚")
                return
            if not ENGINES_IMPORTED:
                logger.error("âŒ [æ’ç¨‹ä»»å‹™] å›æ¸¬å¼•æ“æ¨¡çµ„æœªæˆåŠŸå°å…¥ã€‚ä»»å‹™ä¸­æ­¢ã€‚")
                return
            
            backtester = StrategyBacktesterWithSignals()
            backtester.create_signals_table()
            results = backtester.run_full_backtest_with_signals()
            if results:
                backtester.save_results_to_db(results)
            
            logger.info("âœ… [æ’ç¨‹ä»»å‹™] æ¯æ—¥è‡ªå‹•å›æ¸¬ä»»å‹™åŸ·è¡Œå®Œç•¢ã€‚")
        except Exception as e:
            logger.error(f"\nâŒ [æ’ç¨‹ä»»å‹™] åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}\n{traceback.format_exc()}")
        finally:
            logger.info("=" * 50)

def run_scheduled_news_update():
    """(æ–°æ•´åˆ) æ¯æ—¥è‡ªå‹•åŸ·è¡Œçš„å¸‚å ´æƒ…ç·’åˆ†æä»»å‹™"""
    with app.app_context():
        logger.info("="*50 + f"\nâ° [æ’ç¨‹ä»»å‹™] å•Ÿå‹•æ¯æ—¥å¸‚å ´æƒ…ç·’åˆ†æ... (å°ç£æ™‚é–“: {datetime.now(pytz.timezone('Asia/Taipei'))})\n" + "="*50)
        try:
            if not GEMINI_API_KEY:
                logger.error("âŒ [æ’ç¨‹ä»»å‹™] éŒ¯èª¤: GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®šã€‚å¸‚å ´æƒ…ç·’åˆ†æä»»å‹™ä¸­æ­¢ã€‚")
                return

            # ç¢ºä¿ CSV æª”æ¡ˆå­˜åœ¨
            if not os.path.exists(CSV_FILEPATH):
                logger.warning(f"'{CSV_FILEPATH}' ä¸å­˜åœ¨ï¼Œå‰µå»ºä¸€å€‹ç©ºçš„ç¯„ä¾‹æª”æ¡ˆ...")
                pd.DataFrame(columns=['å¹´/é€±', 'æƒ…ç·’åˆ†æ•¸', 'é‡å¤§æ–°èæ‘˜è¦']).to_csv(CSV_FILEPATH, index=False, encoding='utf-8-sig')

            # åŸ·è¡Œä¸»æµç¨‹
            update_sentiment_csv(CSV_FILEPATH, target_topics=TARGET_COMPANIES_AND_TOPICS)

            logger.info("âœ… [æ’ç¨‹ä»»å‹™] æ¯æ—¥å¸‚å ´æƒ…ç·’åˆ†æä»»å‹™åŸ·è¡Œå®Œç•¢ã€‚")
        except Exception as e:
            logger.error(f"\nâŒ [æ’ç¨‹ä»»å‹™] å¸‚å ´æƒ…ç·’åˆ†æåŸ·è¡ŒæœŸé–“ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}\n{traceback.format_exc()}")
        finally:
            logger.info("=" * 50)


# ==============================================================================
# >>> Flask App å•Ÿå‹•å€å¡Š (æ•´åˆç‰ˆ) <<<
# ==============================================================================

if __name__ == '__main__':
    # ç¢ºä¿å¿…è¦ç›®éŒ„å­˜åœ¨
    os.makedirs('templates', exist_ok=True)
    os.makedirs('charts', exist_ok=True)
    os.makedirs('static/charts', exist_ok=True)
    
    # å»ºç«‹ç°¡å–®çš„æ¨¡æ¿æ–‡ä»¶ä»¥å… Flask å ±éŒ¯
    if not os.path.exists('templates/index.html'):
        with open('templates/index.html', 'w', encoding='utf-8') as f:
            f.write("""<!DOCTYPE html>
<html>
<head><title>Market Analysis Platform</title></head>
<body><h1>å¸‚å ´åˆ†æå¹³å°é‹è¡Œä¸­</h1></body>
</html>""")
    
    # è¨­å®šä¸¦å•Ÿå‹•æ’ç¨‹å™¨
    logger.info("âš™ï¸ æ­£åœ¨è¨­å®šæ’ç¨‹å™¨...")
    scheduler = BackgroundScheduler(timezone=pytz.timezone('Asia/Taipei'))
    
    # æ–°å¢ä»»å‹™ï¼šæ¯æ—¥å¸‚å ´æƒ…ç·’åˆ†æ
    scheduler.add_job(
        func=run_scheduled_news_update,
        trigger='cron',
        hour=8,
        minute=30,
        id='daily_news_update_job',
        name='æ¯æ—¥å°ç£æ™‚é–“ 8:30 åŸ·è¡Œå¸‚å ´æƒ…ç·’åˆ†æ',
        replace_existing=True
    )
    logger.info("âœ… å·²è¨­å®šæ¯æ—¥å¸‚å ´æƒ…ç·’åˆ†ææ’ç¨‹ (08:30)ã€‚")
    
    if ENGINES_IMPORTED:
        # æ–°å¢ä»»å‹™ï¼šæ¯æ—¥å›æ¸¬
        scheduler.add_job(
            func=run_scheduled_backtest,
            trigger='cron',
            hour=17,
            minute=30,
            id='daily_backtest_job',
            name='æ¯æ—¥å°ç£æ™‚é–“ 17:30 åŸ·è¡Œç­–ç•¥å›æ¸¬',
            replace_existing=True
        )
        logger.info("âœ… å·²è¨­å®šæ¯æ—¥ç­–ç•¥å›æ¸¬æ’ç¨‹ (17:30)ã€‚")
    else:
        logger.warning("âš ï¸ ç”±æ–¼æ¨¡çµ„å°å…¥å¤±æ•—ï¼Œæ¯æ—¥è‡ªå‹•å›æ¸¬åŠŸèƒ½å·²åœç”¨ã€‚")
    
    # å•Ÿå‹•æ’ç¨‹å™¨
    scheduler.start()
    logger.info("ğŸš€ æ’ç¨‹å™¨å·²å•Ÿå‹•ã€‚")
    
    # æ‡‰ç”¨ç¨‹å¼çµæŸæ™‚å„ªé›…åœ°é—œé–‰æ’ç¨‹å™¨
    atexit.register(lambda: scheduler.shutdown())
    
    logger.info("ğŸš€ å•Ÿå‹•æ•´åˆç‰ˆ AI ç­–ç•¥åˆ†æèˆ‡å¸‚å ´åˆ†æå¹³å°...")
    logger.info("ğŸ“Š ç­–ç•¥è¨“ç·´å¹³å°è¨ªå•: http://localhost:5001/trainer")
    logger.info("ğŸ“ˆ å¸‚å ´åˆ†æå¹³å°è¨ªå•: http://localhost:5001/")
    
    # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰ä½¿ç”¨ WSGI ä¼ºæœå™¨å¦‚ Gunicorn
    # debug è¨­ç‚º False æ˜¯å¾ˆé‡è¦çš„ï¼Œå› ç‚º Flask çš„è‡ªå‹•é‡è¼‰å™¨æœƒå°è‡´æ’ç¨‹ä»»å‹™è¢«åˆå§‹åŒ–å…©æ¬¡
    app.run(debug=False, host='0.0.0.0', port=5001)
