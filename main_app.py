# program_merged.py - æ•´åˆç‰ˆ AI ç­–ç•¥åˆ†æèˆ‡å¸‚å ´åˆ†æå¹³å°
# æ•´åˆäº†ï¼š
# 1. ä¾†è‡ª program.py çš„å¸‚å ´åˆ†æå„€è¡¨æ¿ã€Gemini AI æ–°èåˆ†æã€å€‹è‚¡æ·±åº¦å ±å‘Šå’Œè‡ªå‹•åŒ–æ’ç¨‹ä»»å‹™
# 2. ä¾†è‡ª stock_ga_web.py çš„ä½¿ç”¨è€…èªè­‰ç³»çµ±ã€ç­–ç•¥è¨“ç·´å™¨ã€æ‰‹å‹•å›æ¸¬å’Œç­–ç•¥æ¸…å–®åŠŸèƒ½

import os
import logging
import re
import json
from datetime import datetime, timedelta, date
from flask import Flask, request, jsonify, render_template, send_from_directory, redirect, url_for
from flask_cors import CORS
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import csv
# === å¾ stock_ga_web.py ç§»æ¤ï¼šä½¿ç”¨è€…èªè­‰èˆ‡è³‡æ–™åº«ç›¸é—œæ¨¡çµ„ ===
from flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user
from werkzeug.security import generate_password_hash, check_password_hash
import traceback

# Google Gemini AI
try:
    from google import genai
    from google.genai import types as genai_types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# è³‡æ–™åº«é€£æ¥
import pymysql

# ğŸ†• æ–°å¢ï¼šæ’ç¨‹ã€æ™‚å€ã€æ™‚é–“èˆ‡è¿½è¹¤æ¨¡çµ„
from apscheduler.schedulers.background import BackgroundScheduler
import pytz
import atexit
import time
import traceback

# ==============================================================================
# >>> (æ–°æ•´åˆ) æ–°èæƒ…ç·’åˆ†ææ‰€éœ€æ¨¡çµ„ <<<
# ==============================================================================
import feedparser
import urllib.parse
import random
import queue
import threading
import uuid

# FinBERT ç›¸é—œå‡½å¼åº« (è»Ÿæ€§ä¾è³´)
try:
    import torch
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    FINBERT_AVAILABLE = True
except ImportError:
    FINBERT_AVAILABLE = False

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å»ºç«‹Flaskæ‡‰ç”¨
app = Flask(__name__)
CORS(app)

# ã€æ–°å¢ç¨‹å¼ç¢¼ STARTã€‘
# --- ç°¡å–®çš„å…§å»ºä»»å‹™ä½‡åˆ—ç³»çµ± ---
# 1. ä»»å‹™ä½‡åˆ—: å­˜æ”¾å¾…è™•ç†çš„è¨“ç·´ä»»å‹™
task_queue = queue.Queue()

# 2. çµæœå­—å…¸: ç”¨æ–¼å„²å­˜ä»»å‹™çš„ç‹€æ…‹å’Œæœ€çµ‚çµæœ
#    éµæ˜¯ task_idï¼Œå€¼æ˜¯åŒ…å« status å’Œ result çš„å­—å…¸
task_results = {}

# 3. åŸ·è¡Œç·’é–: ä¿è­· task_results åœ¨å¤šåŸ·è¡Œç·’ç’°å¢ƒä¸‹çš„è®€å¯«å®‰å…¨
results_lock = threading.Lock()
# ã€æ–°å¢ç¨‹å¼ç¢¼ ENDã€‘

# === å¾ stock_ga_web.py ç§»æ¤ï¼šFlask-Login è¨­å®š ===
app.secret_key = os.getenv('SECRET_KEY', os.urandom(24))
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login_page'
login_manager.login_message = "è«‹å…ˆç™»å…¥ä»¥è¨ªå•æ­¤é é¢ã€‚"
login_manager.login_message_category = "info"

# ğŸ†• æ–°å¢ï¼šå°å…¥å›æ¸¬å¼•æ“æ¨¡çµ„ (å®‰å…¨æª¢æŸ¥)
try:
    from ga_engine import (
        ga_load_data, ga_precompute_indicators, run_strategy_numba_core,
        format_ga_gene_parameters_to_text, STRATEGY_CONFIG_SHARED_GA,
        GA_PARAMS_CONFIG, GENE_MAP, check_ga_buy_signal_at_latest_point
    )
    from ga_engine_b import (
        load_stock_data_b, precompute_indicators_b, run_strategy_numba_core_b,
        format_gene_parameters_to_text_b, STRATEGY_CONFIG_B,GA_PARAMS_CONFIG_B
    )
    # === å¾ stock_ga_web.py ç§»æ¤ï¼šGA å¼•æ“é¡å¤–åŠŸèƒ½ ===
    from ga_engine import genetic_algorithm_unified
    from ga_engine_b import genetic_algorithm_unified_b, run_strategy_b
    from utils import execute_db_query, calculate_performance_metrics, calc_trade_extremes
    
    ENGINES_IMPORTED = True
    logger.info("âœ… æˆåŠŸå°å…¥æ‰€æœ‰å¿…è¦çš„å›æ¸¬å¼•æ“æ¨¡çµ„ã€‚")
except ImportError as e:
    logger.error(f"âŒ å°å…¥å›æ¸¬å¼•æ“æ¨¡çµ„å¤±æ•—: {e}ã€‚æ’ç¨‹å›æ¸¬åŠŸèƒ½å°‡è¢«ç¦ç”¨ã€‚")
    ENGINES_IMPORTED = False

TARGET_SCAN_DATE = None


# è³‡æ–™åº«è¨­å®š
DB_CONFIG = {
    'host': os.getenv("DB_HOST", "localhost"),
    'user': os.getenv("DB_USER", "root"),
    'password': os.getenv("DB_PASSWORD"),
    'database': os.getenv("DB_NAME", "finsimu_db"),
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor,
    'connect_timeout': 15
}

# Gemini AI è¨­å®š
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
gemini_client = None

# å®‰å…¨è¨­å®š
safety_settings_gemini = []
if GEMINI_API_KEY and GEMINI_AVAILABLE:
    try:
        gemini_client = genai.Client(api_key=GEMINI_API_KEY)
        safety_settings_gemini = [
            genai_types.SafetySetting(
                category="HARM_CATEGORY_HARASSMENT",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_HATE_SPEECH",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_DANGEROUS_CONTENT",
                threshold="BLOCK_MEDIUM_AND_ABOVE"
            )
        ]
        logger.info("Gemini AI å®¢æˆ¶ç«¯å·²æˆåŠŸé…ç½®")
    except Exception as e:
        logger.error(f"é…ç½® Gemini AI å¤±æ•—: {e}")

WEIGHTS = {
    'ç©æ¥µå‹': {'annualized_return': 0.55, 'sharpe_ratio': 0.25, 'max_drawdown': 0.10, 'win_rate': 0.10},
    'å‡è¡¡å‹': {'annualized_return': 0.20, 'sharpe_ratio': 0.50, 'max_drawdown': 0.20, 'win_rate': 0.10},
    'ä¿å®ˆå‹': {'annualized_return': 0.10, 'sharpe_ratio': 0.40, 'max_drawdown': 0.40, 'win_rate': 0.10}
}

AI_ADJUSTMENT_FACTORS = {
    'Bullish': 1.10,
    'Neutral': 1.0,
    'Bearish': 0.90
}

# ã€æ–°å¢ç¨‹å¼ç¢¼ STARTã€‘
def training_worker_function():
    """
    é€™æ˜¯åœ¨èƒŒæ™¯åŸ·è¡Œçš„åŸ·è¡Œç·’å‡½å¼ï¼Œå®ƒæœƒæ°¸é å¾ªç’°ï¼Œ
    å¾ task_queue ä¸­ä¾åºå–å‡ºä»»å‹™ä¸¦åŸ·è¡Œã€‚
    """
    logger.info("âœ… [Worker Thread] èƒŒæ™¯è¨“ç·´å·¥äººå·²å•Ÿå‹•ï¼Œç­‰å¾…ä»»å‹™...")
    while True:
        task_id, task_data = task_queue.get()
        
        logger.info(f"ğŸšš [Worker Thread] æ¥æ”¶åˆ°æ–°ä»»å‹™: {task_id} ({task_data['ticker']})")

        try:
            with results_lock:
                task_results[task_id] = {'status': 'STARTED', 'start_time': time.time()}

            local_trainer = SingleStockTrainer()

            ticker = task_data['ticker']
            start_date = task_data['start_date']
            end_date = task_data['end_date']
            custom_weights = task_data['custom_weights']
            basic_params = task_data['basic_params']
            fixed_num_runs = 3

            logger.info(f"--- [Worker Thread] é–‹å§‹è¨“ç·´ç³»çµ± A for {ticker} ---")
            result_A = local_trainer.run_training(
                ticker=ticker, start_date=start_date, end_date=end_date, system_type='A',
                custom_weights=custom_weights, basic_params=basic_params, num_runs=fixed_num_runs
            )
            
            logger.info(f"--- [Worker Thread] é–‹å§‹è¨“ç·´ç³»çµ± B for {ticker} ---")
            result_B = local_trainer.run_training(
                ticker=ticker, start_date=start_date, end_date=end_date, system_type='B',
                custom_weights=custom_weights, basic_params=basic_params, num_runs=fixed_num_runs
            )
            
            # â–¼â–¼â–¼â–¼â–¼ã€éœ€æ±‚ä¿®æ”¹ã€‘å°èª¿ç­–ç•¥ 1 å’Œç­–ç•¥ 2 çš„é †åº â–¼â–¼â–¼â–¼â–¼
            combined_results = []
            
            # å°‡ç³»çµ± B (åŸç­–ç•¥2) ä½œç‚ºç­–ç•¥ 1
            if result_B.get('success') and result_B.get('results'):
                strategy_B = result_B['results'][0]
                strategy_B['rank'] = 1
                strategy_B['strategy_type_name'] = 'ç­–ç•¥ 1 '
                combined_results.append(strategy_B)
            
            # å°‡ç³»çµ± A (åŸç­–ç•¥1) ä½œç‚ºç­–ç•¥ 2
            if result_A.get('success') and result_A.get('results'):
                strategy_A = result_A['results'][0]
                strategy_A['rank'] = 2
                strategy_A['strategy_type_name'] = 'ç­–ç•¥ 2 '
                combined_results.append(strategy_A)
            # â–²â–²â–²â–²â–² ä¿®æ”¹çµæŸ â–²â–²â–²â–²â–²

            if not combined_results:
                raise Exception("è¨“ç·´æˆåŠŸï¼Œä½†æœªèƒ½ç”¢ç”Ÿä»»ä½•æœ‰æ•ˆç­–ç•¥ã€‚")
            
            base_result = result_A if result_A.get('success') else result_B
            final_response = {
                'success': True, 'ticker': ticker,
                'training_period': base_result.get('training_period'),
                'results': combined_results
            }

            with results_lock:
                task_results[task_id].update({
                    'status': 'SUCCESS',
                    'result': final_response,
                    'end_time': time.time()
                })
            logger.info(f"âœ… [Worker Thread] ä»»å‹™ {task_id} æˆåŠŸå®Œæˆã€‚")

        except Exception as e:
            logger.error(f"âŒ [Worker Thread] ä»»å‹™ {task_id} åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
            with results_lock:
                task_results[task_id].update({
                    'status': 'FAILURE',
                    'result': f'èƒŒæ™¯ä»»å‹™åŸ·è¡Œå¤±æ•—: {str(e)}',
                    'end_time': time.time()
                })
        finally:
            task_queue.task_done()

def log_new_ticker_to_csv(ticker: str, market: str):
    """
    æª¢æŸ¥ä¸¦è¨˜éŒ„æ–°çš„è‚¡ç¥¨ä»£è™Ÿåˆ°å°æ‡‰çš„ CSV æª”æ¡ˆä¸­ã€‚(ç©©å¥ç‰ˆ)
    - ticker: ç¶“éé©—è­‰çš„å®Œæ•´è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚ 'AAPL', '2330.TW')
    - market: 'US' æˆ– 'TW'
    """
    try:
        if market == 'TW':
            filepath = 'tw_stock.csv'
            header_name = 'è‚¡ç¥¨ä»£è™Ÿ'
        elif market == 'US':
            filepath = 'usa_stock.csv'
            header_name = 'Symbol'
        else:
            logger.warning(f"[Ticker Logging] æœªçŸ¥çš„å¸‚å ´é¡å‹ '{market}'ï¼Œè·³éè¨˜éŒ„ '{ticker}'ã€‚")
            return

        file_exists = os.path.exists(filepath)
        existing_tickers = set()

        # è®€å–ç¾æœ‰ä»£è™Ÿä»¥é¿å…é‡è¤‡
        if file_exists and os.path.getsize(filepath) > 0:
            try:
                # ä½¿ç”¨ utf-8-sig ä¾†è™•ç†å¯èƒ½å­˜åœ¨çš„ BOM
                df = pd.read_csv(filepath, encoding='utf-8-sig')
                if header_name in df.columns:
                    # æ¸…ç†å¯èƒ½çš„å‰å¾Œç©ºç™½
                    existing_tickers = set(df[header_name].astype(str).str.strip())
            except pd.errors.EmptyDataError:
                logger.warning(f"[Ticker Logging] CSV æª”æ¡ˆ '{filepath}' ç‚ºç©ºã€‚")
            except Exception as e:
                logger.error(f"[Ticker Logging] è®€å– CSV '{filepath}' å¤±æ•—: {e}")
                return

        # å¦‚æœä»£è™Ÿä¸å­˜åœ¨ï¼Œå‰‡ä½¿ç”¨ pandas å°‡å…¶é™„åŠ åˆ°æª”æ¡ˆä¸­
        if ticker not in existing_tickers:
            logger.info(f"[Ticker Logging] ç™¼ç¾æ–°ä»£è™Ÿ '{ticker}'ï¼Œå¯«å…¥ '{filepath}'...")
            try:
                # å‰µå»ºä¸€å€‹åªåŒ…å«æ–°ä»£è™Ÿçš„ DataFrame
                new_ticker_df = pd.DataFrame([{header_name: ticker}])
                
                # ä½¿ç”¨ to_csv çš„é™„åŠ æ¨¡å¼ ('a') é€²è¡Œå¯«å…¥
                # header=not file_exists: åªæœ‰åœ¨æª”æ¡ˆä¸å­˜åœ¨æ™‚æ‰å¯«å…¥æ¨™é ­
                # index=False: ä¸å¯«å…¥ DataFrame çš„ç´¢å¼•
                new_ticker_df.to_csv(
                    filepath, 
                    mode='a', 
                    header=not file_exists or os.path.getsize(filepath) == 0,
                    index=False, 
                    encoding='utf-8-sig'
                )
                logger.info(f"âœ… [Ticker Logging] å·²æˆåŠŸå°‡ '{ticker}' æ·»åŠ åˆ° '{filepath}'ã€‚")
            except Exception as e:
                logger.error(f"âŒ [Ticker Logging] å¯«å…¥æª”æ¡ˆ '{filepath}' å¤±æ•—: {e}")

    except Exception as e:
        logger.error(f"âŒ [Ticker Logging] è¨˜éŒ„æ–°è‚¡ç¥¨ä»£è™Ÿæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")

# === å¾ stock_ga_web.py ç§»æ¤ï¼šUser é¡åˆ¥å’Œèªè­‰ç³»çµ± ===
class User(UserMixin):
    """ä¸€å€‹ç¬¦åˆ Flask-Login è¦æ±‚çš„ä½¿ç”¨è€…é¡åˆ¥"""
    def __init__(self, user_data):
        self.id = user_data['id']
        self.username = user_data['username']
        self.email = user_data['email']
        self.password_hash = user_data['password_hash']

@login_manager.user_loader
def load_user(user_id):
    """Flask-Login éœ€è¦é€™å€‹å‡½å¼ä¾†å¾ session ä¸­é‡æ–°è¼‰å…¥ä½¿ç”¨è€…ç‰©ä»¶"""
    user_data = execute_db_query("SELECT * FROM users WHERE id = %s", (user_id,), fetch_one=True)
    if user_data:
        return User(user_data)
    return None

# ==============================================================================
# >>> ä»¥ä¸‹ç‚ºåŸå§‹ program.py çš„å‡½å¼ (å®Œå…¨æœªä¿®æ”¹) <<<
# ==============================================================================

def format_market_cap(market_cap, currency='USD'):
    """æ ¼å¼åŒ–å¸‚å€¼é¡¯ç¤º"""
    if not market_cap:
        return 'æœªæä¾›'
    currency_symbol = {'USD': '$', 'TWD': 'NT$', 'EUR': 'â‚¬', 'JPY': 'Â¥'}.get(currency, currency)
    if market_cap >= 1e12:
        return f"{currency_symbol}{market_cap/1e12:.1f}å…†"
    elif market_cap >= 1e9:
        return f"{currency_symbol}{market_cap/1e9:.1f}B"
    elif market_cap >= 1e6:
        return f"{currency_symbol}{market_cap/1e6:.0f}M"
    else:
        return f"{currency_symbol}{market_cap:,.0f}"

def get_latest_vix():
    """ä½¿ç”¨ yfinance ç²å–æœ€æ–°çš„ VIX æŒ‡æ•¸"""
    try:
        vix_ticker = yf.Ticker("^VIX")
        hist = vix_ticker.history(period="5d")
        if not hist.empty:
            latest_vix = hist['Close'].iloc[-1]
            logger.info(f"æˆåŠŸç²å–æœ€æ–°VIXæŒ‡æ•¸: {latest_vix:.2f}")
            return round(latest_vix, 2)
        else:
            logger.warning("ç„¡æ³•ç²å–VIXæ­·å²æ•¸æ“šã€‚")
            return None
    except Exception as e:
        logger.error(f"ç²å–VIXæŒ‡æ•¸å¤±æ•—: {e}")
        return None

def get_latest_sentiment_from_csv(csv_path='2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv'):
    """å¾CSVæª”æ¡ˆè®€å–æœ€æ–°çš„å¸‚å ´æƒ…ç·’åˆ†æ•¸å’Œæ‘˜è¦"""
    try:
        if not os.path.exists(csv_path):
            logger.warning(f"æƒ…ç·’åˆ†æCSVæª”æ¡ˆä¸å­˜åœ¨: {csv_path}")
            return None, None
        df = pd.read_csv(csv_path)
        if not df.empty:
            if 'æƒ…ç·’åˆ†æ•¸' in df.columns and 'é‡å¤§æ–°èæ‘˜è¦' in df.columns:
                latest_sentiment = df.iloc[-1]
                score = latest_sentiment['æƒ…ç·’åˆ†æ•¸']
                summary = latest_sentiment['é‡å¤§æ–°èæ‘˜è¦']
                logger.info(f"æˆåŠŸå¾CSVç²å–æœ€æ–°æƒ…ç·’åˆ†æ•¸: {score}")
                return score, summary
            else:
                logger.warning("CSVæª”æ¡ˆä¸­ç¼ºå°‘ 'æƒ…ç·’åˆ†æ•¸' æˆ– 'é‡å¤§æ–°èæ‘˜è¦' æ¬„ä½ã€‚")
                return None, None
        else:
            logger.warning("æƒ…ç·’åˆ†æCSVæª”æ¡ˆç‚ºç©ºã€‚")
            return None, None
    except Exception as e:
        logger.error(f"è®€å–æƒ…ç·’åˆ†æCSVå¤±æ•—: {e}")
        return None, None

class EnhancedStockAnalyzer:
    """å¢å¼·ç‰ˆè‚¡ç¥¨åˆ†æå™¨ - æ•´åˆåŸºæœ¬é¢ã€æŠ€è¡“é¢èˆ‡AIç­–ç•¥"""
    def __init__(self, ticker: str):
        self.ticker_input = ticker.strip().upper()
        # æˆ‘å€‘ä¸å†å¼·åˆ¶é è¨­å¾Œç¶´ï¼Œè®“ get_basic_stock_data å‡½å¼å»æ™ºæ…§åˆ¤æ–·
        self.ticker = self.ticker_input 
        self.market = "US" # é è¨­ç‚ºç¾è‚¡
        
        # åƒ…åšåˆæ­¥çš„å¸‚å ´é¡å‹åˆ¤æ–·ï¼Œå¯¦éš›æœ‰æ•ˆçš„ ticker å°‡åœ¨ç²å–æ•¸æ“šæ™‚ç¢ºèª
        if self.ticker.endswith(".TW") or self.ticker.endswith(".TWO"):
            self.market = "TW"
        elif re.fullmatch(r'\d{4,6}', self.ticker):
            # å¦‚æœæ˜¯æ•¸å­—ä»£ç¢¼ï¼Œæš«æ™‚æ¨™è¨˜ç‚ºå°è‚¡ï¼Œç­‰å¾…å¾ŒçºŒç¢ºèª
            self.market = "TW"
        
        logger.info(f"åˆå§‹åŒ–å¢å¼·åˆ†æå™¨ï¼š{self.ticker_input} (å¸‚å ´ï¼š{self.market})")

    # æ‰¾åˆ°ä¸¦æ›¿æ› EnhancedStockAnalyzer çš„ get_basic_stock_data å‡½å¼
    def get_basic_stock_data(self):
        """ç²å–åŸºæœ¬è‚¡ç¥¨æ•¸æ“š - å¢å¼·ç‰ˆ (æ•´åˆ.TW/.TWOè‡ªå‹•é‡è©¦)"""
        try:
            # <<<<<<< é€™è£¡æ˜¯æ–°çš„æ™ºæ…§é‡è©¦é‚è¼¯ >>>>>>>
            is_tw_stock_code = re.fullmatch(r'\d{4,6}[A-Z]?', self.ticker_input)
            stock = None
            hist_data = pd.DataFrame() # åˆå§‹åŒ–ä¸€å€‹ç©ºçš„ DataFrame

            if is_tw_stock_code:
                logger.info(f"åµæ¸¬åˆ°å°è‚¡æ•¸å­—ä»£è™Ÿ {self.ticker_input}ï¼Œå°‡ä¾åºå˜—è©¦ .TW å’Œ .TWO å¾Œç¶´ã€‚")
                for suffix in ['.TW', '.TWO']:
                    potential_ticker = f"{self.ticker_input}{suffix}"
                    logger.info(f"æ­£åœ¨å˜—è©¦ä½¿ç”¨ {potential_ticker}...")
                    try:
                        temp_stock = yf.Ticker(potential_ticker)
                        temp_hist = temp_stock.history(period="1y")
                        if not temp_hist.empty:
                            logger.info(f"æˆåŠŸä½¿ç”¨ {potential_ticker} ç²å–æ•¸æ“šã€‚")
                            self.ticker = potential_ticker  # é‡è¦ï¼šæ›´æ–°é¡åˆ¥å¯¦ä¾‹ä¸­æœ‰æ•ˆçš„ ticker
                            self.market = "TW"
                            stock = temp_stock
                            hist_data = temp_hist
                            break  # æˆåŠŸæ‰¾åˆ°æ•¸æ“šï¼Œè·³å‡ºè¿´åœˆ
                    except Exception:
                        logger.warning(f"å˜—è©¦ {potential_ticker} å¤±æ•—ï¼Œç¹¼çºŒä¸‹ä¸€å€‹ã€‚")
                        continue
            
            # å¦‚æœä¸æ˜¯å°è‚¡ä»£è™Ÿï¼Œæˆ–æ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—ï¼Œå‰‡åŸ·è¡ŒåŸå§‹é‚è¼¯
            if stock is None:
                logger.info(f"åŸ·è¡Œæ¨™æº–æŸ¥è©¢ï¼š{self.ticker}")
                stock = yf.Ticker(self.ticker)
                hist_data = stock.history(period="1y")

            # åœ¨æ‰€æœ‰å˜—è©¦å¾Œï¼Œæœ€çµ‚æª¢æŸ¥æ•¸æ“šæ˜¯å¦ç‚ºç©º
            if hist_data.empty:
                raise ValueError(f"ç„¡æ³•ç²å– {self.ticker_input} çš„æ­·å²æ•¸æ“š (å·²å˜—è©¦ .TW å’Œ .TWO)")
            # <<<<<<< æ™ºæ…§é‡è©¦é‚è¼¯çµæŸ >>>>>>>

            info = stock.info
            current_price = hist_data['Close'].iloc[-1]
            prev_close = hist_data['Close'].iloc[-2] if len(hist_data) >= 2 else current_price
            change = current_price - prev_close
            change_pct = (change / prev_close * 100) if prev_close != 0 else 0
            
            change_str = f"{change:+.2f}"
            change_pct_str = f"{change_pct:+.2f}%"
            price_change_str = f"{change_str} ({change_pct_str})"
            
            return {
                "success": True, "ticker": self.ticker, 
                "company_name": info.get('longName', info.get('shortName', self.ticker)),
                "market": self.market, "current_price": round(float(current_price), 2), 
                "price_change": round(float(change), 2),
                "price_change_pct": round(float(change_pct), 2), 
                "price_change_str": price_change_str,
                "currency": info.get('currency', 'TWD' if self.market == 'TW' else 'USD'), 
                "market_cap": info.get('marketCap'),
                "pe_ratio": round(info.get('trailingPE'), 2) if info.get('trailingPE') else None,
                "forward_pe": round(info.get('forwardPE'), 2) if info.get('forwardPE') else None,
                "eps": round(info.get('trailingEps'), 2) if info.get('trailingEps') else None,
                "roe": round(info.get('returnOnEquity'), 4) if info.get('returnOnEquity') else None,
                "dividend_yield": round(info.get('dividendYield'), 4) if info.get('dividendYield') else None,
                "beta": round(info.get('beta'), 2) if info.get('beta') else None,
                "price_to_book": round(info.get('priceToBook'), 2) if info.get('priceToBook') else None,
                "debt_to_equity": round(info.get('debtToEquity'), 2) if info.get('debtToEquity') else None,
                "volume": int(hist_data['Volume'].iloc[-1]) if not pd.isna(hist_data['Volume'].iloc[-1]) else 0,
                "day_high": round(float(hist_data['High'].iloc[-1]), 2), 
                "day_low": round(float(hist_data['Low'].iloc[-1]), 2),
                "year_high": round(float(hist_data['High'].max()), 2), 
                "year_low": round(float(hist_data['Low'].min()), 2),
                "historical_data": hist_data, 
                "analysis_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        except Exception as e:
            logger.error(f"ç²å–åŸºæœ¬è‚¡ç¥¨æ•¸æ“šå¤±æ•—ï¼š{e}")
            # æä¾›æ›´æ˜ç¢ºçš„éŒ¯èª¤è¨Šæ¯
            error_message = f"ç„¡æ³•ç²å–è‚¡ç¥¨ {self.ticker_input} çš„æ•¸æ“šã€‚è«‹æª¢æŸ¥ä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚å°æ–¼å°è‚¡ï¼Œæˆ‘å€‘å·²è‡ªå‹•å˜—è©¦ .TW å’Œ .TWO å¾Œç¶´ã€‚éŒ¯èª¤è©³æƒ…: {e}"
            return {"success": False, "error": error_message}

    def get_technical_indicators(self, hist_data):
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
        try:
            close_prices = hist_data['Close']
            ma_5 = close_prices.rolling(window=5).mean().iloc[-1] if len(close_prices) >= 5 else None
            ma_10 = close_prices.rolling(window=10).mean().iloc[-1] if len(close_prices) >= 10 else None
            ma_20 = close_prices.rolling(window=20).mean().iloc[-1] if len(close_prices) >= 20 else None
            ma_60 = close_prices.rolling(window=60).mean().iloc[-1] if len(close_prices) >= 60 else None
            ma_120 = close_prices.rolling(window=120).mean().iloc[-1] if len(close_prices) >= 120 else None
            
            delta = close_prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            current_rsi = rsi.iloc[-1] if len(rsi) >= 14 else None
            
            bb_period = 20
            bb_std = 2
            if len(close_prices) >= bb_period:
                bb_middle = close_prices.rolling(window=bb_period).mean()
                bb_std_dev = close_prices.rolling(window=bb_period).std()
                bb_upper = bb_middle + (bb_std_dev * bb_std)
                bb_lower = bb_middle - (bb_std_dev * bb_std)
                bb_upper_val = bb_upper.iloc[-1]
                bb_lower_val = bb_lower.iloc[-1]
                bb_middle_val = bb_middle.iloc[-1]
            else:
                bb_upper_val = bb_lower_val = bb_middle_val = None
                
            def format_to_2_decimal(value):
                return round(float(value), 2) if value and not pd.isna(value) else None
                
            return {
                "ma_5": format_to_2_decimal(ma_5), "ma_10": format_to_2_decimal(ma_10), 
                "ma_20": format_to_2_decimal(ma_20),
                "ma_60": format_to_2_decimal(ma_60), "ma_120": format_to_2_decimal(ma_120), 
                "rsi": format_to_2_decimal(current_rsi),
                "bb_upper": format_to_2_decimal(bb_upper_val), 
                "bb_middle": format_to_2_decimal(bb_middle_val), 
                "bb_lower": format_to_2_decimal(bb_lower_val)
            }
        except Exception as e:
            logger.error(f"è¨ˆç®—æŠ€è¡“æŒ‡æ¨™å¤±æ•—: {e}")
            return {}

    def get_ai_strategies_data(self):
        """ç²å–AIç­–ç•¥æ•¸æ“šï¼ˆå¾è³‡æ–™åº«è®€å–çœŸå¯¦å›æ¸¬æ—¥æœŸï¼‰- (ä¿®æ”¹ç‰ˆï¼šåªç²å– Rank 1)"""
        try:
            market_type = "TW" if self.market == "TW" else "US"
            common_fields = "ai_strategy_gene, strategy_rank, strategy_details, period_return_pct, max_drawdown_pct, win_rate_pct, total_trades, average_trade_return_pct, max_trade_drop_pct, max_trade_gain_pct, game_start_date, game_end_date"
            
            # <<<< ä¿®æ”¹é»ï¼šå°‡ LIMIT 3 æ”¹ç‚º LIMIT 1ï¼ŒåªæŠ“å–æ¯å€‹ç³»çµ±çš„æœ€ä½³ç­–ç•¥ >>>>
            system_a_query = f"SELECT {common_fields} FROM ai_vs_user_games WHERE user_id = 2 AND market_type = %s AND stock_ticker = %s ORDER BY strategy_rank ASC LIMIT 1"
            system_b_query = f"SELECT {common_fields} FROM ai_vs_user_games WHERE user_id = 3 AND market_type = %s AND stock_ticker = %s ORDER BY strategy_rank ASC LIMIT 1"
            
            system_a_strategies = execute_db_query(system_a_query, (market_type, self.ticker), fetch_all=True)
            system_b_strategies = execute_db_query(system_b_query, (market_type, self.ticker), fetch_all=True)
            
            start_date_str, end_date_str = "N/A", "N/A"
            first_strategy = (system_a_strategies or system_b_strategies or [None])[0]
            if first_strategy and first_strategy.get('game_start_date'):
                start_date_obj, end_date_obj = first_strategy['game_start_date'], first_strategy['game_end_date']
                if isinstance(start_date_obj, date): start_date_str = start_date_obj.strftime('%Y-%m-%d')
                if isinstance(end_date_obj, date): end_date_str = end_date_obj.strftime('%Y-%m-%d')
                
            return { 
                "system_a": system_a_strategies or [], "system_b": system_b_strategies or [], 
                "market_type": market_type,
                "backtest_start_date": start_date_str, "backtest_end_date": end_date_str,
                "backtest_period_description": f"å›æ¸¬æœŸé–“ï¼š{start_date_str} è‡³ {end_date_str}"
            }
        except Exception as e:
            logger.error(f"ç²å–AIç­–ç•¥æ•¸æ“šå¤±æ•—ï¼š{e}")
            return { 
                "system_a": [], "system_b": [], "market_type": "", 
                "backtest_start_date": "N/A", "backtest_end_date": "N/A", 
                "backtest_period_description": "å›æ¸¬æœŸé–“ï¼šç„¡æ³•ç²å–" 
            }
# åœ¨ main_app.py ä¸­æ–°å¢é€™å€‹å‡½å¼

# åœ¨ main_app.py ä¸­ï¼Œæ‰¾åˆ°ä¸¦ç”¨æ­¤ã€æœ€çµ‚å®Œç¾ç‰ˆã€‘å‡½å¼å®Œæ•´æ›¿æ›

def create_backtest_chart_assets(ticker, system_type, rank, portfolio, prices, dates, buys, sells):
    """ç‚ºå›æ¸¬çµæœå‰µå»ºéœæ…‹PNGå’Œäº’å‹•HTMLï¼Œä¸¦è¿”å›URL - (åŸç‰ˆ + éš±è—å·¥å…·åˆ— + æ‡¸åœ/åº§æ¨™è»¸æ—¥æœŸæ ¼å¼åŒ–)"""
    try:
        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, 
                          row_heights=[0.7, 0.3],
                          subplot_titles=(f'{ticker} åƒ¹æ ¼èµ°å‹¢èˆ‡äº¤æ˜“ä¿¡è™Ÿ', 'åƒ¹å€¼è®ŠåŒ–'))
        
        # è‚¡åƒ¹èˆ‡è²·è³£é» (å·²åŠ å…¥æ‡¸åœæ ¼å¼)
        fig.add_trace(go.Scatter(
            x=dates, y=prices, mode='lines', name='æ”¶ç›¤åƒ¹', 
            line=dict(color='rgba(102, 126, 234, 0.7)'),
            hovertemplate='æ—¥æœŸ: %{x:%Y/%m/%d}<br>æ”¶ç›¤åƒ¹: %{y:.2f}<extra></extra>'
        ), row=1, col=1)
        
        if buys:
            fig.add_trace(go.Scatter(
                x=[s['date'] for s in buys], y=[s['price'] for s in buys], 
                mode='markers', name='è²·å…¥ä¿¡è™Ÿ', 
                marker=dict(symbol='triangle-up', size=10, color='#27AE60', line=dict(width=1, color='white')),
                hovertemplate='è²·å…¥ä¿¡è™Ÿ<br>æ—¥æœŸ: %{x:%Y/%m/%d}<br>åƒ¹æ ¼: %{y:.2f}<extra></extra>'
            ), row=1, col=1)
        
        if sells:
            fig.add_trace(go.Scatter(
                x=[s['date'] for s in sells], y=[s['price'] for s in sells], 
                mode='markers', name='è³£å‡ºä¿¡è™Ÿ', 
                marker=dict(symbol='triangle-down', size=10, color='#E74C3C', line=dict(width=1, color='white')),
                hovertemplate='è³£å‡ºä¿¡è™Ÿ<br>æ—¥æœŸ: %{x:%Y/%m/%d}<br>åƒ¹æ ¼: %{y:.2f}<extra></extra>'
            ), row=1, col=1)

        # æŠ•è³‡çµ„åˆåƒ¹å€¼ (å·²åŠ å…¥æ‡¸åœæ ¼å¼)
        if portfolio is not None and len(portfolio) > 0:
             fig.add_trace(go.Scatter(
                x=dates, y=portfolio, mode='lines', name='çµ„åˆåƒ¹å€¼', 
                line=dict(color='purple'),
                hovertemplate='æ—¥æœŸ: %{x:%Y/%m/%d}<br>çµ„åˆåƒ¹å€¼: %{y:.4f}<extra></extra>'
            ), row=2, col=1)

        # æ•´é«”æ’ç‰ˆ
        fig.update_layout(
            template='plotly_white', 
            height=500, 
            margin=dict(l=40, r=20, t=50, b=30), 
            showlegend=True,
            legend=dict(
                orientation="h", yanchor="bottom", y=1.03, xanchor="right", x=1
            ),
            hovermode='x unified'
        )

        fig.update_xaxes(tickformat='%Y/%m/%d')

        
        base_filename = f"{ticker.replace('.', '_')}_{system_type}_Rank{rank}_backtest"
        
        # å„²å­˜éœæ…‹åœ–ç‰‡
        img_filename = f"{base_filename}.png"
        img_path = os.path.join('static/charts', img_filename)
        fig.write_image(img_path, scale=2)
        
        # å„²å­˜äº’å‹•HTML (å·²éš±è—å·¥å…·åˆ—)
        html_filename = f"{base_filename}.html"
        html_path = os.path.join('charts', html_filename)
        fig.write_html(
            html_path, 
            include_plotlyjs='cdn', 
            config={'displayModeBar': False}
        )
        
        logger.info(f"âœ… (æœ€çµ‚å®Œç¾ç‰ˆ) å›æ¸¬åœ–è¡¨å·²ç”Ÿæˆï¼š{img_filename} å’Œ {html_filename}")
        return f"/static/charts/{img_filename}", f"/charts/{html_filename}"
        
    except Exception as e:
        logger.error(f"å‰µå»ºå›æ¸¬åœ–è¡¨(æœ€çµ‚å®Œç¾ç‰ˆ)å¤±æ•—: {e}", exc_info=True)
        return None, None
    
def create_enhanced_stock_chart(ticker, company_name, hist_data):
    """å‰µå»ºè‚¡åƒ¹åœ–è¡¨ï¼ŒåŒæ™‚ç”Ÿæˆéœæ…‹PNGå’Œäº’å‹•HTML"""
    try:
        fig = make_subplots(rows=1, cols=1, shared_xaxes=True, vertical_spacing=0.06)
        
        fig.add_trace(go.Candlestick(
            x=hist_data.index, open=hist_data['Open'], high=hist_data['High'], 
            low=hist_data['Low'], close=hist_data['Close'], name=f'{ticker} è‚¡åƒ¹', 
            increasing_line_color='#26C6DA', decreasing_line_color='#EF5350'
        ), row=1, col=1)
        
        fig.update_layout(
            # ç§»é™¤åœ–è¡¨å…§çš„å¤§æ¨™é¡Œï¼Œè®“åœ–æ›´ä¹¾æ·¨
            template='plotly_white', height=500, 
            font=dict(family="Arial", size=12),
            margin=dict(l=40, r=20, t=20, b=30), # ç¸®å°é‚Šè·
            xaxis_rangeslider_visible=False,
            showlegend=False # æ‰‹æ©Ÿä¸Šé€šå¸¸ä¸é¡¯ç¤ºåœ–ä¾‹
        )
        
        base_filename = f"{ticker.replace('.', '_')}_stock_chart"
        
        # å„²å­˜éœæ…‹åœ–ç‰‡
        img_filename = f"{base_filename}.png"
        img_path = os.path.join('static/charts', img_filename)
        fig.write_image(img_path, scale=2) # scale=2 è®“åœ–ç‰‡æ›´æ¸…æ™°
        
        # å„²å­˜äº’å‹•HTML (ç§»é™¤Plotlyæ§åˆ¶æ¬„)
        html_filename = f"{base_filename}.html"
        html_path = os.path.join('charts', html_filename)
        fig.write_html(html_path, include_plotlyjs='cdn', config={'displayModeBar': True}) # åœ¨å…¨è¢å¹•æ¨¡å¼é¡¯ç¤ºæ§åˆ¶æ¬„
        
        logger.info(f"åœ–è¡¨å·²ç”Ÿæˆï¼š{img_filename} å’Œ {html_filename}")
        return f"/static/charts/{img_filename}", f"/charts/{html_filename}"
    
    except Exception as e:
        logger.error(f"å‰µå»ºåœ–è¡¨å¤±æ•—ï¼š{e}")
        return None, None

def generate_enhanced_news_analysis(stock_data, tech_indicators, strategies_data, latest_vix, latest_sentiment):
    """ä½¿ç”¨ Gemini AI ç”ŸæˆåŒ…å«æœ€æ–°æ–°èçš„æ·±åº¦åˆ†æå ±å‘Š - ğŸ”¥ å®Œæ•´æŒ‡æ¨™ç‰ˆæœ¬"""
    if not gemini_client:
        return "Gemini AI æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨"
    
    try:
        # ğŸ”¥ ä¿®æ”¹ï¼šæº–å‚™å®Œæ•´ç­–ç•¥æ•¸æ“šæ‘˜è¦
        system_a_summary = ""
        if strategies_data.get('system_a'):
            system_a_summary = "System A (28åŸºå› å¤šç­–ç•¥):\n"
            for strategy in strategies_data['system_a'][:3]:
                system_a_summary += f" Rank {strategy['strategy_rank']}:\n"
                system_a_summary += f" ğŸ“ˆ ç¸½å ±é…¬ç‡: {strategy.get('period_return_pct', 0):.2f}%\n"
                system_a_summary += f" ğŸ’° å¹³å‡äº¤æ˜“å ±é…¬: {strategy.get('average_trade_return_pct', 0):.3f}%\n"
                system_a_summary += f" ğŸ¯ å‹ç‡: {strategy.get('win_rate_pct', 0):.1f}%\n"
                system_a_summary += f" ğŸ”¢ äº¤æ˜“æ¬¡æ•¸: {strategy.get('total_trades', 0)}\n"
                system_a_summary += f" ğŸ“‰ æœ€å¤§å›æ’¤: {strategy.get('max_drawdown_pct', 0):.2f}%\n"
                system_a_summary += f" ğŸ“‰ æœ€å¤§è·Œå¹…: {strategy.get('max_trade_drop_pct', 0):.2f}%\n"
                system_a_summary += f" ğŸ“ˆ æœ€å¤§æ¼²å¹…: {strategy.get('max_trade_gain_pct', 0):.2f}%\n"
        
        system_b_summary = ""
        if strategies_data.get('system_b'):
            system_b_summary = "System B (10åŸºå› RSIç­–ç•¥):\n"
            for strategy in strategies_data['system_b'][:3]:
                system_b_summary += f" Rank {strategy['strategy_rank']}:\n"
                system_b_summary += f" ğŸ“ˆ ç¸½å ±é…¬ç‡: {strategy.get('period_return_pct', 0):.2f}%\n"
                system_b_summary += f" ğŸ’° å¹³å‡äº¤æ˜“å ±é…¬: {strategy.get('average_trade_return_pct', 0):.3f}%\n"
                system_b_summary += f" ğŸ¯ å‹ç‡: {strategy.get('win_rate_pct', 0):.1f}%\n"
                system_b_summary += f" ğŸ”¢ äº¤æ˜“æ¬¡æ•¸: {strategy.get('total_trades', 0)}\n"
                system_b_summary += f" ğŸ“‰ æœ€å¤§å›æ’¤: {strategy.get('max_drawdown_pct', 0):.2f}%\n"
                system_b_summary += f" ğŸ“‰ æœ€å¤§è·Œå¹…: {strategy.get('max_trade_drop_pct', 0):.2f}%\n"
                system_b_summary += f" ğŸ“ˆ æœ€å¤§æ¼²å¹…: {strategy.get('max_trade_gain_pct', 0):.2f}%\n"
        
        system_a_details = ""
        if strategies_data.get('system_a'):
            system_a_details = "System A (28åŸºå› å¤šç­–ç•¥):\n"
            for strategy in strategies_data['system_a'][:1]:
                system_a_details += f" Rank {strategy['strategy_rank']}:\n"
                system_a_details += f" ç­–ç•¥è©³æƒ…: {strategy.get('strategy_details')}\n"
        
        system_b_details = ""
        if strategies_data.get('system_b'):
            system_b_details = "System B (10åŸºå› RSIç­–ç•¥):\n"
            for strategy in strategies_data['system_b'][:1]:
                system_b_details += f" Rank {strategy['strategy_rank']}:\n"
                system_b_details += f" ç­–ç•¥è©³æƒ…: {strategy.get('strategy_details')}\n"
        
        # ğŸ†• æ–°å¢ï¼šå›æ¸¬æ™‚é–“è³‡è¨Š
        backtest_info = f"å›æ¸¬æœŸé–“: {strategies_data.get('backtest_start_date', 'N/A')} è‡³ {strategies_data.get('backtest_end_date', 'N/A')}"
        
        # æ§‹å»ºåŒ…å«æ–°èæŸ¥è©¢çš„æç¤ºè©
        prompt = f"""ä½ æ˜¯é ‚å°–çš„é‡åŒ–æŠ•è³‡åˆ†æå¸«ï¼Œè«‹ç‚ºè‚¡ç¥¨ {stock_data['company_name']} ({stock_data['ticker']}) æ’°å¯«ä¸€ä»½åŒ…å«æœ€æ–°æ–°èçš„æŠ•è³‡åˆ†æå ±å‘Šã€‚(ä¸è¦åŠ å…¥è‡ªæˆ‘ä»‹ç´¹åŠå•å€™)

è«‹å…ˆæœå°‹ä»¥ä¸‹é—œéµå­—çš„æœ€æ–°æ–°èï¼š
- "{stock_data['company_name']} stock news"
- "{stock_data['ticker']} adxã€ macdã€kdjä»Šæ—¥æŠ€è¡“æŒ‡æ¨™"
- "{stock_data['ticker']} earnings"
- "{stock_data['company_name']} financial results"
- "market news today"
- "{stock_data['ticker']} åŒæ¥­ç«¶çˆ­"

åŸºæœ¬é¢æ•¸æ“šï¼š
- ç•¶å‰è‚¡åƒ¹: {stock_data['current_price']:.2f} {stock_data['currency']}
- å¸‚å€¼: {format_market_cap(stock_data.get('market_cap'), stock_data['currency'])}
- æœ¬ç›Šæ¯”: {stock_data.get('pe_ratio', 'æœªæä¾›')}
- æ¯è‚¡ç›ˆé¤˜: {stock_data.get('eps', 'æœªæä¾›')}
- ROE: {f"{stock_data.get('roe', 0)*100:.2f}%" if stock_data.get('roe') else 'æœªæä¾›'}
- Betaå€¼: {stock_data.get('beta', 'æœªæä¾›')}

æŠ€è¡“æŒ‡æ¨™ï¼š
- RSI: {tech_indicators.get('rsi', 'æœªæä¾›')}
- 5æ—¥å‡ç·š: {tech_indicators.get('ma_5', 'æœªæä¾›')}
- 10æ—¥å‡ç·š: {tech_indicators.get('ma_10', 'æœªæä¾›')}
- 20æ—¥å‡ç·š: {tech_indicators.get('ma_20', 'æœªæä¾›')}
- 60æ—¥å‡ç·š: {tech_indicators.get('ma_60', 'æœªæä¾›')}
- 120æ—¥å‡ç·š: {tech_indicators.get('ma_120', 'æœªæä¾›')}
- å¸ƒæ—å¸¶ä¸Šè»Œ: {tech_indicators.get('bb_upper', 'æœªæä¾›')}
- å¸ƒæ—å¸¶ä¸‹è»Œ: {tech_indicators.get('bb_lower', 'æœªæä¾›')}

é‡åŒ–ç­–ç•¥å›æ¸¬çµæœï¼ˆ{backtest_info}ï¼‰ï¼š

ç­–ç•¥1è©³æƒ…:
{system_a_summary}
{system_a_details}

ç­–ç•¥2è©³æƒ…:
{system_b_summary}
{system_b_details}

è«‹åš´æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼æ’°å¯«åˆ†æå ±å‘Šï¼Œæ¯å€‹éƒ¨åˆ†éƒ½ä½¿ç”¨ç¨ç«‹çš„ `##` æ¨™é¡Œï¼š

##  æœ€æ–°æ–°èåˆ†æ
[æ ¹æ“šæœå°‹åˆ°çš„æœ€æ–°æ–°èåˆ†æå°è‚¡åƒ¹çš„å½±éŸ¿ï¼Œ100-120å­—]

##  åŸºæœ¬é¢åˆ†æ
[æœå°‹ä¸¦åˆ†æå…¬å¸è²¡å‹™é«”è³ªã€ç²åˆ©èƒ½åŠ›ã€ä¼°å€¼æ°´æº–ç­‰é‚„æœ‰åŒæ¥­æ¯”è¼ƒï¼Œ120-150å­—]

##  è¿‘æœŸè¶¨å‹¢
[æœå°‹ç¶²è·¯åŠåŸºæ–¼æŠ€è¡“æŒ‡æ¨™åˆ†æè‚¡åƒ¹è¶¨å‹¢ç­‰ï¼Œ60-100å­—]

##  ç­–ç•¥è§£è®€ (æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)(!!å¦‚æœè©²è‚¡ç¥¨æ²’æœ‰æä¾›ç­–ç•¥ï¼Œè«‹ç›´æ¥å›è¦†"æ­¤è‚¡ç¥¨ç›®å‰å°šç„¡è¨“ç·´å¥½ç­–ç•¥ï¼Œç³»çµ±å°‡è‡ªå‹•å°‡å…¶ç´å…¥ä¸‹ä¸€æ‰¹æ¬¡çš„è¨“ç·´æ¸…å–®ä¸­ã€‚"!!)
[è«‹åŸºæ–¼ä¸Šæ–¹æä¾›çš„ **ç­–ç•¥ 1** å’Œ **ç­–ç•¥ 2** çš„æ•¸æ“šï¼Œæ’°å¯«ä¸€ä»½å°ˆæ¥­åˆ†æ (100-200å­—)ã€‚è«‹å‹™å¿…éµå¾ªä»¥ä¸‹è¦é»ï¼š
- **ç¦æ­¢ä½¿ç”¨ 'System A' æˆ– 'System B' ç­‰å…§éƒ¨è¡“èª**ï¼Œåªèƒ½ç›´æ¥ä½¿ç”¨ "ç­–ç•¥ 1" å’Œ "ç­–ç•¥ 2 " ä¾†ç¨±å‘¼å®ƒå€‘ï¼Œä¸éœ€åŠ å…¥(28åŸºå› å¤šç­–ç•¥æˆ–10åŸºå› RSIç­–ç•¥ä½œè§£é‡‹)ã€‚
- **æ¯”è¼ƒè¡¨ç¾å·®ç•°**: åˆ†æå…©å¥—ç­–ç•¥çš„é¢¨éšªæ”¶ç›Šç‰¹å¾µã€‚å“ªä¸€å€‹çœ‹èµ·ä¾†æ›´ç©©å¥ï¼Ÿå“ªå€‹æ¯”è¼ƒå¥½ï¼Ÿç‚ºä»€éº¼ï¼Ÿ
- **è§£è®€é—œéµæŒ‡æ¨™**: æ ¹æ“šæä¾›çš„ã€Œç­–ç•¥è©³æƒ…ã€ï¼Œè§£è®€å®ƒå€‘åˆ†åˆ¥ä¾è³´å“ªäº›æ ¸å¿ƒæŠ€è¡“æŒ‡æ¨™ã€‚
- **é æ¸¬è¿‘æœŸä¿¡è™Ÿ**: çµåˆç•¶å‰æŠ€è¡“æŒ‡æ¨™ï¼Œæé†’è¿‘æœŸæ˜¯å¦å¯èƒ½å‡ºç¾è²·å…¥æˆ–è³£å‡ºä¿¡è™Ÿã€‚(ä¸è¦æåˆ°æœ‰æ•¸æ“šç¼ºå¤±çš„éƒ¨åˆ†ï¼Œè¬¹èªªæ˜æœ‰æ•¸æ“šæ”¯æŒçš„éƒ¨åˆ†å³å¯)]

VIX ææ…ŒæŒ‡æ•¸:{latest_vix if latest_vix is not None else 'æœªèƒ½ç²å–'} (è¨»ï¼šæŒ‡æ•¸è¶Šé«˜ï¼Œå¸‚å ´ææ…Œç¨‹åº¦è¶Šé«˜)
å¸‚å ´æƒ…ç·’åˆ†æ•¸:{latest_sentiment[0] if latest_sentiment and latest_sentiment[0] is not None else 'æœªèƒ½ç²å–'}

##  æŠ•è³‡æ©Ÿæœƒ (æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)
[åŸºæ–¼æ–°èã€åŸºæœ¬é¢ã€æŠ€è¡“é¢å’Œç­–ç•¥åˆ†æï¼Œåˆ—å‡º2-3é»ä¸»è¦æŠ•è³‡æ©Ÿæœƒã€‚](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)

 é¢¨éšªæé†’ (æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)
[åŸºæ–¼æ–°èã€åŸºæœ¬é¢ã€æŠ€è¡“é¢å’Œç­–ç•¥åˆ†æï¼Œåˆ—å‡º2-3é»ä¸»è¦æŠ•è³‡é¢¨éšªã€‚](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)

è«‹ç¢ºä¿åˆ†æå°ˆæ¥­ã€å®¢è§€ï¼Œä¸¦é‡é»é—œæ³¨æœ€æ–°æ–°èå°æŠ•è³‡æ±ºç­–çš„å½±éŸ¿ã€‚"""

        # ğŸ”¥ é—œéµï¼šé…ç½® Gemini ä½¿ç”¨ Google Search å·¥å…·
        config = genai_types.GenerateContentConfig(
            temperature=0.7,
            max_output_tokens=4500,
            tools=[genai_types.Tool(google_search=genai_types.GoogleSearch())],
            safety_settings=safety_settings_gemini
        )
        
        response = gemini_client.models.generate_content(
            model='models/gemini-2.5-flash',
            contents=prompt,
            config=config
        )
        
        # ğŸ”¥ ä¿®å¾©ï¼šæ·»åŠ ç©ºå€¼æª¢æŸ¥
        if response and hasattr(response, 'text') and response.text:
            return response.text.strip()
        else:
            logger.warning("Gemini API è¿”å›ç©ºéŸ¿æ‡‰")
            return "AIåˆ†ææš«æ™‚ç„¡æ³•ç”Ÿæˆï¼Œä½†è‚¡ç¥¨åŸºæœ¬è³‡æ–™å’ŒæŠ€è¡“æŒ‡æ¨™åˆ†ææ­£å¸¸é‹è¡Œ"
            
    except Exception as e:
        logger.error(f"Gemini æ–°èåˆ†æç”Ÿæˆå¤±æ•—: {e}")
        return f"AIæ–°èåˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼š{str(e)}"

# === å¾ stock_ga_web.py ç§»æ¤ï¼šSingleStockTrainer é¡åˆ¥ ===
class SingleStockTrainer:
    """å–®æ”¯è‚¡ç¥¨è¨“ç·´å™¨é¡åˆ¥ - Kç·šåœ–æ•´åˆç‰ˆ"""
    def __init__(self):
        # å›ºå®šçš„GAåƒæ•¸
        self.fixed_params = {
            'mutation_rate': 0.25,
            'crossover_rate': 0.7,
            'no_trade_penalty': 0.1,
            'nsga2_enabled': True
        }
        
        # é è¨­çš„è‡ªå®šç¾©æ¬Šé‡
        self.default_custom_weights = {
            'total_return_weight': 0.5,
            'avg_trade_return_weight': 0.40,
            'win_rate_weight': 0.05,
            'trade_count_weight': 0,
            'drawdown_weight': 0.05
        }
        
        self.system_a_config = GA_PARAMS_CONFIG.copy()
        self.system_b_config = GA_PARAMS_CONFIG_B.copy()

    def validate_inputs(self, ticker, start_date, end_date, system_type):
        """é©—è­‰è¼¸å…¥åƒæ•¸"""
        errors = []
        
        if not ticker or len(ticker.strip()) == 0:
            errors.append("è‚¡ç¥¨ä»£è™Ÿä¸èƒ½ç‚ºç©º")
        
        try:
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            end_dt = datetime.strptime(end_date, "%Y-%m-%d")
            
            if start_dt >= end_dt:
                errors.append("é–‹å§‹æ—¥æœŸå¿…é ˆæ—©æ–¼çµæŸæ—¥æœŸ")
            if end_dt > datetime.now():
                errors.append("çµæŸæ—¥æœŸä¸èƒ½è¶…éä»Šå¤©")
        except ValueError:
            errors.append("æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
        
        if system_type not in ['A', 'B']:
            errors.append("ç³»çµ±é¡å‹å¿…é ˆæ˜¯ A æˆ– B")
        
        return errors

    def validate_custom_weights(self, custom_weights):
        """é©—è­‰è‡ªå®šç¾©æ¬Šé‡"""
        errors = []
        required_weights = ['total_return_weight', 'avg_trade_return_weight',
                          'win_rate_weight', 'trade_count_weight', 'drawdown_weight']
        
        total_weight = 0
        for weight_name in required_weights:
            if weight_name not in custom_weights:
                errors.append(f"ç¼ºå°‘æ¬Šé‡åƒæ•¸: {weight_name}")
                continue
            
            try:
                value = float(custom_weights[weight_name])
                if value < 0 or value > 1:
                    errors.append(f"{weight_name} å¿…é ˆåœ¨ 0 åˆ° 1 ä¹‹é–“")
                total_weight += value
            except ValueError:
                errors.append(f"{weight_name} å¿…é ˆæ˜¯æœ‰æ•ˆçš„æ•¸å­—")
        
        if abs(total_weight - 1.0) > 0.01:
            errors.append(f"æ‰€æœ‰æ¬Šé‡ç¸½å’Œæ‡‰è©²ç­‰æ–¼1.0ï¼Œç›®å‰ç¸½å’Œç‚º: {total_weight:.3f}")
        
        return errors

    # æ‰¾åˆ° SingleStockTrainer é¡åˆ¥ä¸¦å®Œæ•´æ›¿æ› load_stock_data å‡½å¼
    # æª”æ¡ˆ: main_app.py
# åœ¨ SingleStockTrainer é¡åˆ¥ä¸­...

    # æ‰¾åˆ° SingleStockTrainer é¡åˆ¥ä¸¦å®Œæ•´æ›¿æ› load_stock_data å‡½å¼ (æœ€çµ‚ä¿®æ­£ç‰ˆ)
    def load_stock_data(self, ticker, start_date, end_date, system_type):
        """è¼‰å…¥è‚¡ç¥¨æ•¸æ“š - (V2.0 é ç†±æœŸåˆ†é›¢ç‰ˆ)"""
        try:
            # <<< NEW LOGIC START >>>
            # 1. å°‡ä½¿ç”¨è€…è¼¸å…¥çš„æ—¥æœŸå­—ä¸²è½‰æ›ç‚º datetime ç‰©ä»¶
            user_start_date_obj = datetime.strptime(start_date, "%Y-%m-%d")
            user_end_date_obj = datetime.strptime(end_date, "%Y-%m-%d")

            # 2. è¨ˆç®—ç”¨æ–¼æ•¸æ“šç²å–çš„çœŸæ­£èµ·å§‹æ—¥æœŸï¼ˆå¾€å‰æ¨120å¤©ï¼‰
            data_fetch_start_date_obj = user_start_date_obj - timedelta(days=120)
            data_fetch_start_date_str = data_fetch_start_date_obj.strftime("%Y-%m-%d")

            # 3. ç‚ºäº†ç¢ºä¿ yfinance åŒ…å«çµæŸæ—¥æœŸï¼Œå°‡å…¶åŠ ä¸€å¤©
            inclusive_end_date_for_yf = user_end_date_obj + timedelta(days=1)
            end_date_for_yf_str = inclusive_end_date_for_yf.strftime("%Y-%m-%d")

            logger.info(f"[Trainer Data] ä½¿ç”¨è€…å€é–“: {start_date} ~ {end_date}")
            logger.info(f"[Trainer Data] é ç†±æ•¸æ“šç²å–å€é–“: {data_fetch_start_date_str} ~ {end_date_for_yf_str}")
            
            # 4. ä½¿ç”¨æ–°çš„ã€æ›´æ—©çš„èµ·å§‹æ—¥æœŸä¾†å®šç¾©è¼‰å…¥å‡½å¼
            load_func_a = lambda t: ga_load_data(
                t, start_date=data_fetch_start_date_str, end_date=end_date_for_yf_str,
                sentiment_csv_path='2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv' if os.path.exists('2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv') else None,
                verbose=False
            )
            load_func_b = lambda t: load_stock_data_b(t, start_date=data_fetch_start_date_str, end_date=end_date_for_yf_str, verbose=False)
            # <<< NEW LOGIC END >>>

            is_tw_stock_code = re.fullmatch(r'\d{4,6}[A-Z]?', ticker)
            loaded_data = None
            
            # (å°è‚¡ .TW/.TWO æ™ºæ…§é‡è©¦é‚è¼¯ä¸éœ€è®Šæ›´)
            if is_tw_stock_code:
                logger.info(f"åµæ¸¬åˆ°å°è‚¡æ•¸å­—ä»£è™Ÿ {ticker}ï¼Œå°‡ä¾åºå˜—è©¦ .TW å’Œ .TWO å¾Œç¶´ã€‚")
                for suffix in ['.TW', '.TWO']:
                    potential_ticker = f"{ticker}{suffix}"
                    prices_check = None
                    if system_type == 'A':
                        loaded_data = load_func_a(potential_ticker)
                        prices_check = loaded_data[0]
                    else:
                        loaded_data = load_func_b(potential_ticker)
                        prices_check = loaded_data[0]
                    
                    if prices_check and len(prices_check) > 0:
                        logger.info(f"æˆåŠŸä½¿ç”¨ {potential_ticker} è¼‰å…¥æ•¸æ“šã€‚")
                        break
                    else:
                        loaded_data = None
            
            if not loaded_data:
                logger.info(f"åŸ·è¡Œæ¨™æº–æŸ¥è©¢ï¼š{ticker}")
                if system_type == 'A':
                    loaded_data = load_func_a(ticker)
                else:
                    loaded_data = load_func_b(ticker)
            
            prices_check = loaded_data[0]
            if not prices_check or len(prices_check) == 0:
                # <<< MODIFICATION: è¿”å› None çµ¦ iloc >>>
                return None, f"æ•¸æ“šä¸è¶³æˆ–è¼‰å…¥å¤±æ•— (å·²å˜—è©¦ .TW/.TWO)", None

            # <<< NEW LOGIC START >>>
            # 5. æ‰¾åˆ°ä½¿ç”¨è€…åŸå§‹ start_date åœ¨æ“´å±•æ•¸æ“šä¸­çš„ç´¢å¼•ä½ç½®
            all_dates = loaded_data[1]
            dates_pd = pd.to_datetime([d.date() for d in all_dates])
            
            try:
                # ä½¿ç”¨ searchsorted å¿«é€Ÿå®šä½
                user_start_date_iloc = dates_pd.searchsorted(user_start_date_obj, side='left')

                # é©—è­‰æ‰¾åˆ°çš„ç´¢å¼•æ˜¯å¦åœ¨ç¯„åœå…§ä¸”æœ‰æ•ˆ
                if user_start_date_iloc >= len(dates_pd):
                    raise IndexError("æ‰¾ä¸åˆ°é–‹å§‹æ—¥æœŸ") # å¦‚æœæ—¥æœŸè¶…å‡ºç¯„åœï¼Œè§¸ç™¼except
            except (IndexError, TypeError):
                 # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›ä¸€å€‹æ˜ç¢ºçš„éŒ¯èª¤è¨Šæ¯
                logger.warning(f"åœ¨ç²å–çš„æ•¸æ“šä¸­æ‰¾ä¸åˆ°ä½¿ç”¨è€…æŒ‡å®šçš„é–‹å§‹æ—¥æœŸ {start_date}ï¼Œå›æ¸¬ä¸­æ­¢ã€‚")
                return None, f"åœ¨ç²å–çš„æ•¸æ“šä¸­æ‰¾ä¸åˆ°ä½¿ç”¨è€…æŒ‡å®šçš„é–‹å§‹æ—¥æœŸ {start_date}ï¼Œè«‹ç¢ºèªè©²æ—¥æœŸç‚ºäº¤æ˜“æ—¥æˆ–é¸æ“‡å…¶ä»–æ—¥æœŸã€‚", None
            # <<< NEW LOGIC END >>>
            
            if system_type == 'A':
                prices, dates, stock_df, vix_series, sentiment_series = loaded_data
                precalculated, ready = ga_precompute_indicators(
                    stock_df, vix_series, STRATEGY_CONFIG_SHARED_GA,
                    sentiment_series=sentiment_series, verbose=False
                )
                if not ready: return None, "ç³»çµ±AæŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—", None
                return {
                    'prices': prices, 'dates': dates, 'stock_df': stock_df, 
                    'precalculated': precalculated, 'data_points': len(prices)
                }, None, user_start_date_iloc
            else: # ç³»çµ±B
                prices, dates, stock_df, vix_series = loaded_data
                precalculated, ready = precompute_indicators_b(
                    stock_df, vix_series, STRATEGY_CONFIG_B, verbose=False
                )
                if not ready: return None, "ç³»çµ±BæŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—", None
                return {
                    'prices': prices, 'dates': dates, 'stock_df': stock_df, 
                    'precalculated': precalculated, 'data_points': len(prices)
                }, None, user_start_date_iloc
                
        except Exception as e:
            logger.error(f"è¼‰å…¥æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return None, f"è¼‰å…¥æ•¸æ“šå¤±æ•—: {str(e)}", None

    def apply_fixed_and_custom_params(self, system_type, custom_weights, basic_params):
        """æ‡‰ç”¨å›ºå®šåƒæ•¸å’Œè‡ªå®šç¾©æ¬Šé‡åˆ°GAåƒæ•¸ - (ä¿®æ­£ç‰ˆï¼šåŒæ­¥æœ€å°äº¤æ˜“æ¬¡æ•¸)"""
        if system_type == 'A':
            config = self.system_a_config.copy()
        else:
            config = self.system_b_config.copy()
        
        config.update(self.fixed_params)
        
        # è™•ç†ä½¿ç”¨è€…å¯èª¿æ•´çš„åŸºç¤åƒæ•¸
        if 'generations' in basic_params:
            config['generations'] = max(5, min(100, int(basic_params['generations'])))
        if 'population_size' in basic_params:
            config['population_size'] = max(20, min(200, int(basic_params['population_size'])))
            
        # --- âœ¨ ä¿®æ­£é» START ---
        # ç¢ºä¿ä½¿ç”¨è€…è¨­å®šçš„ 'min_trades' åŒæ™‚æ›´æ–°è»Ÿæ€§æ‡²ç½°å’Œ NSGA-II çš„ç¡¬æ€§ç´„æŸ
        if 'min_trades' in basic_params:
            # 1. å¾å‰ç«¯ç²å–ä¸¦é©—è­‰äº¤æ˜“æ¬¡æ•¸å€¼ï¼Œç¢ºä¿å…¶åœ¨åˆç†ç¯„åœå…§
            user_min_trades = max(1, min(20, int(basic_params['min_trades'])))
            
            # 2. æ›´æ–°ç”¨æ–¼é©æ‡‰åº¦å‡½æ•¸ï¼ˆFitness Functionï¼‰çš„ã€Œè»Ÿæ€§æ‡²ç½°ã€åƒæ•¸
            #    é€™å€‹åƒæ•¸æ±ºå®šäº†äº¤æ˜“æ¬¡æ•¸ä¸è¶³æ™‚ï¼Œç¸½å›å ±çš„æ‡²ç½°åŠ›åº¦ã€‚
            config['min_trades_for_full_score'] = user_min_trades
            
            # 3. æ›´æ–°ç”¨æ–¼ NSGA-II æ¼”ç®—æ³•çš„ã€Œç¡¬æ€§ç´„æŸã€åƒæ•¸
            #    é€™å€‹åƒæ•¸å‘Šè¨´æ¼”ç®—æ³•ï¼Œäº¤æ˜“æ¬¡æ•¸å°‘æ–¼æ­¤å€¼çš„è§£æ˜¯ã€Œç„¡æ•ˆã€çš„ï¼Œæ‡‰ç›¡åŠ›é¿å…ã€‚
            config['min_required_trades'] = user_min_trades
            
            # ç‚ºäº†æ–¹ä¾¿åµéŒ¯ï¼Œå¯ä»¥åŠ ä¸Šæ—¥èªŒè¼¸å‡º
            logger.info(f"[Config Update] æœ€å°äº¤æ˜“æ¬¡æ•¸å·²åš´æ ¼è¨­å®šç‚º: {user_min_trades} (åŒæ­¥æ›´æ–°æ‡²ç½°èˆ‡ç´„æŸ)")
        # --- âœ¨ ä¿®æ­£é» END ---
        
        # è¨­å®š NSGA-II çš„é¸æ“‡æ–¹æ³•å’Œè‡ªå®šç¾©æ¬Šé‡
        config['nsga2_selection_method'] = 'custom_balance'
        config['custom_weights'] = custom_weights
        
        return config

    def generate_trading_signals(self, gene, data_result, ga_config, system_type):
        """ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿæ•¸æ“š"""
        try:
            logger.info(f"é–‹å§‹ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ - ç³»çµ±{system_type}")
            
            if system_type == 'A':
                def get_indicator_list(name, gene_indices, opt_keys):
                    params = [ga_config[k][gene[g_idx]] for g_idx, k in zip(gene_indices, opt_keys)]
                    key = tuple(params) if len(params) > 1 else params[0]
                    indicator_data = data_result['precalculated'].get(name, {}).get(key, [np.nan] * len(data_result['prices']))
                    return np.array(indicator_data, dtype=np.float64)
                
                result = run_strategy_numba_core(
                    np.array(gene, dtype=np.float64),
                    np.array(data_result['prices'], dtype=np.float64),
                    get_indicator_list('vix_ma', [GENE_MAP['vix_ma_p']], ['vix_ma_period_options']),
                    get_indicator_list('sentiment_ma', [GENE_MAP['sentiment_ma_p']], ['sentiment_ma_period_options']),
                    get_indicator_list('rsi', [GENE_MAP['rsi_p']], ['rsi_period_options']),
                    get_indicator_list('adx', [GENE_MAP['adx_p']], ['adx_period_options']),
                    get_indicator_list('bbl', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                    get_indicator_list('bbm', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                    get_indicator_list('bbu', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                    get_indicator_list('ma', [GENE_MAP['ma_s_p']], ['ma_period_options']),
                    get_indicator_list('ma', [GENE_MAP['ma_l_p']], ['ma_period_options']),
                    get_indicator_list('ema_s', [GENE_MAP['ema_s_p']], ['ema_s_period_options']),
                    get_indicator_list('ema_m', [GENE_MAP['ema_m_p']], ['ema_m_period_options']),
                    get_indicator_list('ema_l', [GENE_MAP['ema_l_p']], ['ema_l_period_options']),
                    get_indicator_list('atr', [GENE_MAP['atr_p']], ['atr_period_options']),
                    get_indicator_list('atr_ma', [GENE_MAP['atr_p']], ['atr_period_options']),
                    get_indicator_list('kd_k', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']],
                                     ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                    get_indicator_list('kd_d', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']],
                                     ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                    get_indicator_list('macd_line', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']],
                                     ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                    get_indicator_list('macd_signal', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']],
                                     ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                    ga_config.get('commission_rate', 0.003),
                    61
                )
                
                if result is None or len(result) < 6:
                    logger.warning("ç³»çµ±Aç­–ç•¥åŸ·è¡Œå¤±æ•—")
                    return None, None, None
                
                portfolio_values, buy_indices, buy_prices, sell_indices, sell_prices, _ = result
                
                buy_signals = []
                sell_signals = []
                
                if buy_indices is not None and len(buy_indices) > 0:
                    buy_signals = [{'date': data_result['dates'][i], 'price': buy_prices[idx] if buy_prices is not None and idx < len(buy_prices) else data_result['prices'][i]}
                                 for idx, i in enumerate(buy_indices) if i < len(data_result['dates'])]
                
                if sell_indices is not None and len(sell_indices) > 0:
                    sell_signals = [{'date': data_result['dates'][i], 'price': sell_prices[idx] if sell_prices is not None and idx < len(sell_prices) else data_result['prices'][i]}
                                  for idx, i in enumerate(sell_indices) if i < len(data_result['dates'])]
                
                logger.info(f"ç³»çµ±Aä¿¡è™Ÿç”Ÿæˆå®Œæˆ: {len(buy_signals)}è²·å…¥, {len(sell_signals)}è³£å‡º")
                return portfolio_values.tolist(), buy_signals, sell_signals
                
            else:  # ç³»çµ±B
                # è§£æåŸºå› åƒæ•¸
                rsi_buy_entry_threshold = float(gene[0])
                rsi_exit_threshold = float(gene[1])
                vix_threshold = float(gene[2])
                low_vol_exit_strategy = int(gene[3])
                rsi_p_choice = int(gene[4])
                vix_ma_p_choice = int(gene[5])
                bb_len_choice = int(gene[6])
                bb_std_choice = int(gene[7])
                adx_threshold = float(gene[8])
                high_vol_entry_choice = int(gene[9])
                
                # ç²å–æŒ‡æ¨™æ•¸æ“š
                rsi_period = STRATEGY_CONFIG_B['rsi_period_options'][rsi_p_choice]
                vix_ma_period = STRATEGY_CONFIG_B['vix_ma_period_options'][vix_ma_p_choice]
                bb_len = STRATEGY_CONFIG_B['bb_length_options'][bb_len_choice]
                bb_std = STRATEGY_CONFIG_B['bb_std_options'][bb_std_choice]
                
                rsi_list = data_result['precalculated']['rsi'][rsi_period]
                vix_ma_list = data_result['precalculated']['vix_ma'][vix_ma_period]
                bbl_list = data_result['precalculated']['bbl'][(bb_len, bb_std)]
                bbm_list = data_result['precalculated']['bbm'][(bb_len, bb_std)]
                adx_list = data_result['precalculated']['fixed']['adx_list']
                ma_short_list = data_result['precalculated']['fixed']['ma_short_list']
                ma_long_list = data_result['precalculated']['fixed']['ma_long_list']
                
                # åŸ·è¡Œç­–ç•¥
                portfolio_values, buy_signals, sell_signals = run_strategy_b(
                    rsi_buy_entry_threshold, rsi_exit_threshold, adx_threshold, vix_threshold,
                    low_vol_exit_strategy, high_vol_entry_choice,
                    ga_config['commission_rate'],
                    data_result['prices'], data_result['dates'],
                    rsi_list, bbl_list, bbm_list, adx_list,
                    vix_ma_list, ma_short_list, ma_long_list
                )
                
                # è½‰æ›ä¿¡è™Ÿæ ¼å¼
                buy_signals_formatted = [{'date': s[0], 'price': s[1]} for s in buy_signals]
                sell_signals_formatted = [{'date': s[0], 'price': s[1]} for s in sell_signals]
                
                logger.info(f"ç³»çµ±Bä¿¡è™Ÿç”Ÿæˆå®Œæˆ: {len(buy_signals_formatted)}è²·å…¥, {len(sell_signals_formatted)}è³£å‡º")
                return portfolio_values, buy_signals_formatted, sell_signals_formatted
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            logger.error(traceback.format_exc())
            return None, None, None

    def create_line_chart_with_signals(self, ticker, data_result, portfolio_values, buy_signals, sell_signals):
        """ç”¨æ”¶ç›¤åƒ¹ç·šåœ–å’Œäº¤æ˜“ä¿¡è™Ÿå‰µå»ºåœ–è¡¨"""
        try:
            df = data_result['stock_df'].copy()
            if df.index.name != 'Date':
                df = df.reset_index()
            
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
            else:
                df['Date'] = pd.to_datetime(df.index)
            df = df.reset_index(drop=True)
            
            fig = make_subplots(
                rows=2, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.1,
                row_heights=[0.7, 0.3],
                subplot_titles=(f'{ticker} åƒ¹æ ¼èµ°å‹¢èˆ‡äº¤æ˜“ä¿¡è™Ÿ', 'æŠ•è³‡çµ„åˆåƒ¹å€¼è®ŠåŒ–')
            )
            
            fig.add_trace(
                go.Scatter(
                    x=df['Date'],
                    y=data_result['prices'],
                    mode='lines',
                    name='æ”¶ç›¤åƒ¹',
                    line=dict(color='rgba(102, 126, 234, 0.7)', width=2)
                ),
                row=1, col=1
            )
            
            if buy_signals:
                buy_dates = [pd.to_datetime(signal['date']) for signal in buy_signals]
                buy_prices = [signal['price'] for signal in buy_signals]
                fig.add_trace(
                    go.Scatter(
                        x=buy_dates,
                        y=buy_prices,
                        mode='markers',
                        marker=dict(symbol='triangle-up', size=12, color='red', line=dict(width=2, color='darkred')),
                        name=f'è²·å…¥ ({len(buy_signals)}æ¬¡)',
                        hovertemplate='è²·å…¥ä¿¡è™Ÿ<br>æ—¥æœŸ: %{x}<br>åƒ¹æ ¼: %{y:.2f}<extra></extra>'
                    ),
                    row=1, col=1
                )
            
            if sell_signals:
                sell_dates = [pd.to_datetime(signal['date']) for signal in sell_signals]
                sell_prices = [signal['price'] for signal in sell_signals]
                fig.add_trace(
                    go.Scatter(
                        x=sell_dates,
                        y=sell_prices,
                        mode='markers',
                        marker=dict(symbol='triangle-down', size=12, color='blue', line=dict(width=2, color='darkblue')),
                        name=f'è³£å‡º ({len(sell_signals)}æ¬¡)',
                        hovertemplate='è³£å‡ºä¿¡è™Ÿ<br>æ—¥æœŸ: %{x}<br>åƒ¹æ ¼: %{y:.2f}<extra></extra>'
                    ),
                    row=1, col=1
                )
            
            if portfolio_values and len(portfolio_values) >= len(df):
                portfolio_data = portfolio_values[:len(df)]
                fig.add_trace(
                    go.Scatter(
                        x=df['Date'],
                        y=portfolio_data,
                        mode='lines',
                        line=dict(color='purple', width=2),
                        name='æŠ•è³‡çµ„åˆåƒ¹å€¼',
                        hovertemplate='çµ„åˆåƒ¹å€¼<br>æ—¥æœŸ: %{x}<br>åƒ¹å€¼: %{y:.4f}<extra></extra>'
                    ),
                    row=2, col=1
                )
            
            fig.update_layout(
                title={'text': f'{ticker} ç­–ç•¥å›æ¸¬çµæœ', 'x': 0.5, 'xanchor': 'center', 'font': {'size': 18}},
                xaxis_title='æ—¥æœŸ', yaxis_title='è‚¡åƒ¹',
                xaxis2_title='', yaxis2_title='çµ„åˆåƒ¹å€¼',
                height=600, showlegend=True,
                xaxis_rangeslider_visible=False,
                hovermode='x unified', template='plotly_white'
            )
            
            fig.update_xaxes(tickformat='%Y-%m-%d', tickangle=45)
            
            chart_json = fig.to_json()
            logger.info(f"æˆåŠŸç”Ÿæˆ {ticker} çš„Plotlyç·šåœ–JSON")
            return chart_json
            
        except Exception as e:
            logger.error(f"å‰µå»ºç·šåœ–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            logger.error(traceback.format_exc())
            return None

    def calculate_detailed_metrics(self, gene, data_result, ga_config, system_type):
        """è¨ˆç®—è©³ç´°ç¸¾æ•ˆæŒ‡æ¨™ (å·²é‡æ§‹ç‚ºä½¿ç”¨ utils)"""
        try:
            portfolio_values, buy_signals, sell_signals = self.generate_trading_signals(gene, data_result, ga_config, system_type)
            if not portfolio_values: 
                return {}
            
            # ğŸ”¥ ç›´æ¥å‘¼å« utils ä¸­çš„å‡½å¼
            metrics = calculate_performance_metrics(
                portfolio_values,
                data_result['dates'],
                buy_signals,
                sell_signals,
                data_result['prices']
            )
            
            return metrics
        except Exception as e:
            logger.error(f"è¨ˆç®—è©³ç´°æŒ‡æ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return {}

    def analyze_signal_status(self, buy_signals, sell_signals):
        """åˆ†ææœ€æ–°çš„ä¿¡è™Ÿç‹€æ…‹ï¼Œè¿”å›ä¸€å€‹æç¤ºå­—ä¸²"""
        if not buy_signals and not sell_signals: 
            return "ç›®å‰ç„¡ä»»ä½•è¨Šè™Ÿ"
        
        today = datetime.now().date()
        seven_days_ago = today - timedelta(days=7)
        
        last_buy_date = pd.to_datetime(buy_signals[-1]['date']).date() if buy_signals else None
        last_sell_date = pd.to_datetime(sell_signals[-1]['date']).date() if sell_signals else None
        
        # 1. æª¢æŸ¥è¿‘æœŸä¿¡è™Ÿ
        recent_buy_signal = last_buy_date if last_buy_date and last_buy_date >= seven_days_ago else None
        recent_sell_signal = last_sell_date if last_sell_date and last_sell_date >= seven_days_ago else None
        
        if recent_buy_signal and (not recent_sell_signal or recent_buy_signal >= recent_sell_signal):
            return f"æ³¨æ„ï¼š{recent_buy_signal.strftime('%Y/%m/%d')} æœ‰è²·å…¥è¨Šè™Ÿï¼"
        
        if recent_sell_signal and (not recent_buy_signal or recent_sell_signal > recent_buy_signal):
            return f"æ³¨æ„ï¼š{recent_sell_signal.strftime('%Y/%m/%d')} æœ‰è³£å‡ºè¨Šè™Ÿï¼"
        
        # 2. å¦‚æœæ²’æœ‰è¿‘æœŸä¿¡è™Ÿï¼Œåˆ¤æ–·é•·æœŸæŒæœ‰ç‹€æ…‹
        if last_buy_date and (not last_sell_date or last_buy_date > last_sell_date):
            return "ç›®å‰ç­–ç•¥ç‹€æ…‹ç‚ºã€ŒæŒæœ‰ä¸­ã€"
        else:
            return "ç›®å‰ç­–ç•¥ç‹€æ…‹ç‚ºã€Œç„¡å€‰ä½ã€"

    # åœ¨ main_app.py ä¸­ï¼Œæ‰¾åˆ° SingleStockTrainer é¡åˆ¥ä¸¦æ›¿æ›ä»¥ä¸‹å…©å€‹å‡½å¼

    def run_training(self, ticker, start_date, end_date, system_type, custom_weights, basic_params, num_runs=10):
        """åŸ·è¡Œè¨“ç·´ - (V2.5 åƒ…ç‚ºTop1ç”Ÿæˆåœ–è¡¨)"""
        try:
            data_result, error_msg, user_start_date_iloc = self.load_stock_data(ticker, start_date, end_date, system_type)
            if error_msg: 
                return {'success': False, 'errors': [error_msg]}
            
            errors = self.validate_inputs(ticker, start_date, end_date, system_type)
            if errors: return {'success': False, 'errors': errors}
            weight_errors = self.validate_custom_weights(custom_weights)
            if weight_errors: return {'success': False, 'errors': weight_errors}
            
            ga_config = self.apply_fixed_and_custom_params(system_type, custom_weights, basic_params)
            
            strategy_pool = []
            logger.info(f"é–‹å§‹ç‚º {ticker} åŸ·è¡Œ {num_runs} æ¬¡ç³»çµ±{system_type} NSGA-IIå„ªåŒ– (é«˜æ•ˆæ¨¡å¼)...")
            
            for run_idx in range(num_runs):
                try:
                    runner_func = genetic_algorithm_unified if system_type == 'A' else genetic_algorithm_unified_b
                    result = runner_func(data_result['prices'], data_result['dates'], data_result['precalculated'], ga_config)
                    if result and result[0] is not None:
                        gene, _ = result
                        metrics = self.calculate_detailed_metrics(gene, data_result, ga_config, system_type)
                        if not metrics: continue
                        strategy_pool.append({
                            'gene': gene, 'fitness': metrics.get('total_return', 0),
                            'metrics': metrics, 'run': run_idx + 1,
                        })
                except Exception as e:
                    logger.warning(f"ç¬¬ {run_idx + 1} æ¬¡é‹è¡Œå¤±æ•—: {e}")
                    continue
            
            if not strategy_pool: 
                return {'success': False, 'errors': ['æ‰€æœ‰è¨“ç·´é‹è¡Œéƒ½å¤±æ•—äº†']}
            
            strategy_pool.sort(key=lambda x: x['fitness'], reverse=True)
            top_3 = strategy_pool[:3]
            
            results = []
            logger.info(f"è¨“ç·´å®Œæˆï¼Œé–‹å§‹ç‚º Top {len(top_3)} ç­–ç•¥ç”Ÿæˆåœ–è¡¨èˆ‡æœ€çµ‚ç¸¾æ•ˆ...")

            for i, strategy in enumerate(top_3):
                portfolio_values, buy_signals, sell_signals = self.generate_trading_signals(
                    strategy['gene'], data_result, ga_config, system_type
                )
                
                # å°‡URLåˆå§‹åŒ–ç‚ºNone
                chart_image_url, chart_interactive_url = None, None
                
                if portfolio_values is not None:
                    sliced_portfolio_raw = portfolio_values[user_start_date_iloc:]
                    sliced_dates = data_result['dates'][user_start_date_iloc:]
                    sliced_prices = data_result['prices'][user_start_date_iloc:]
                    
                    period_buy_signals, period_sell_signals = self._filter_signals_for_period(buy_signals, sell_signals, start_date)

                    final_portfolio_for_metrics = []
                    
                    if not period_buy_signals and not period_sell_signals:
                        final_portfolio_for_metrics = [1.0] * len(sliced_dates)
                    else:
                        first_trade_date = period_buy_signals[0]['date']
                        first_trade_iloc = next((i for i, d in enumerate(sliced_dates) if d >= first_trade_date), 0)
                        metrics_prefix = [1.0] * first_trade_iloc
                        trade_period_portfolio = sliced_portfolio_raw[first_trade_iloc:]
                        initial_trade_value = trade_period_portfolio[0] if len(trade_period_portfolio) > 0 else 1.0
                        normalized_trade_curve = [p / initial_trade_value for p in trade_period_portfolio] if initial_trade_value > 0 else trade_period_portfolio
                        final_portfolio_for_metrics.extend(metrics_prefix)
                        final_portfolio_for_metrics.extend(normalized_trade_curve)
                    
                    # æŒ‡æ¨™è¨ˆç®—å°æ‰€æœ‰Top3ç­–ç•¥éƒ½åŸ·è¡Œ
                    final_display_metrics = calculate_performance_metrics(
                        final_portfolio_for_metrics,
                        sliced_dates, 
                        period_buy_signals, period_sell_signals, sliced_prices,
                        risk_free_rate=ga_config.get('risk_free_rate', 0.025),
                        commission_rate=ga_config.get('commission_rate', 0.0035)
                    )
                    
                    # â–¼â–¼â–¼â–¼â–¼ ã€æ ¸å¿ƒä¿®æ”¹é»ã€‘ â–¼â–¼â–¼â–¼â–¼
                    # åªæœ‰ç•¶ç­–ç•¥æ˜¯Top 1 (i == 0) æ™‚ï¼Œæ‰ç”Ÿæˆåœ–è¡¨
                    if i == 0:
                        logger.info(f"  -> ç‚º Top 1 ç­–ç•¥ç”Ÿæˆåœ–è¡¨...")
                        chart_image_url, chart_interactive_url = create_backtest_chart_assets(
                            ticker, f"System{system_type}", strategy['run'],
                            final_portfolio_for_metrics, 
                            sliced_prices, sliced_dates,
                            period_buy_signals, period_sell_signals
                        )
                    # â–²â–²â–²â–²â–² ã€ä¿®æ”¹çµæŸã€‘ â–²â–²â–²â–²â–²
                else:
                    final_display_metrics = strategy['metrics']

                formatter_func = format_ga_gene_parameters_to_text if system_type == 'A' else format_gene_parameters_to_text_b
                description = formatter_func(strategy['gene'])
                cache_buster = f"?v={int(time.time())}"
                
                results.append({
                    'rank': i + 1, 'gene': strategy['gene'],
                    'metrics': final_display_metrics,
                    'description': description,
                    'chart_image_url': f"{chart_image_url}{cache_buster}" if chart_image_url else None,
                    'chart_interactive_url': f"{chart_interactive_url}{cache_buster}" if chart_interactive_url else None
                })
            
            logger.info("Top 3 ç­–ç•¥ç¸¾æ•ˆè¨ˆç®—å®Œæˆ (åƒ… Top 1 ç”Ÿæˆåœ–è¡¨)ã€‚")
            return {
                'success': True, 'ticker': ticker, 'system_type': system_type,
                'training_period': f"{start_date} ~ {end_date}",
                'results': results
            }
            
        except Exception as e:
            logger.error(f"è¨“ç·´éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return {'success': False, 'errors': [f'è¨“ç·´å¤±æ•—: {str(e)}']}


    def _filter_signals_for_period(self, buy_signals, sell_signals, start_date):
        """
        (V2.2 æ–°å¢) æ™ºæ…§éæ¿¾ä¸¦ä¿®æ­£äº¤æ˜“è¨Šè™Ÿï¼Œè§£æ±º"å­¤å…’è³£å‡º"å•é¡Œã€‚
        """
        start_date_obj = datetime.strptime(start_date, "%Y-%m-%d")

        # 1. å…ˆéæ¿¾å‡ºåœ¨å›æ¸¬å€é–“å…§çš„æ‰€æœ‰è¨Šè™Ÿ
        period_buys = [s for s in buy_signals if s['date'] >= start_date_obj]
        period_sells = [s for s in sell_signals if s['date'] >= start_date_obj]

        if not period_buys and not period_sells:
            return [], []

        # 2. è™•ç†"å­¤å…’è³£å‡º"å•é¡Œ
        first_buy_date = period_buys[0]['date'] if period_buys else None
        first_sell_date = period_sells[0]['date'] if period_sells else None

        # å¦‚æœå€é–“å…§æœ‰è³£å‡ºè¨Šè™Ÿï¼Œä½†æ²’æœ‰è²·å…¥è¨Šè™Ÿï¼Œæˆ–è€…ç¬¬ä¸€å€‹è³£å‡ºè¨Šè™Ÿæ—©æ–¼ç¬¬ä¸€å€‹è²·å…¥è¨Šè™Ÿ
        # é€™æ„å‘³è‘—ç¬¬ä¸€å€‹è³£å‡ºæ˜¯å°æ‡‰é ç†±æœŸçš„è²·å…¥ï¼Œæˆ‘å€‘å¿…é ˆå°‡å…¶ç§»é™¤
        if first_sell_date and (first_buy_date is None or first_sell_date < first_buy_date):
            # æŒçºŒç§»é™¤é–‹é ­çš„è³£å‡ºè¨Šè™Ÿï¼Œç›´åˆ°ç¬¬ä¸€å€‹è¨Šè™Ÿæ˜¯è²·å…¥ç‚ºæ­¢
            while period_sells and (not period_buys or period_sells[0]['date'] < period_buys[0]['date']):
                logger.info(f"ç§»é™¤å­¤å…’è³£å‡ºè¨Šè™Ÿ: {period_sells[0]['date'].strftime('%Y-%m-%d')}")
                period_sells.pop(0)

        return period_buys, period_sells
    
    # =================== ã€ä¿®æ”¹æ­¤æ–¹æ³•ã€‘ ===================
# åœ¨ SingleStockTrainer é¡åˆ¥ä¸­...
    # æª”æ¡ˆ: main_app.py -> class SingleStockTrainer

    # æª”æ¡ˆ: main_app.py -> class SingleStockTrainer

    def run_manual_backtest(self, ticker, gene, start_date, end_date):
        """åŸ·è¡Œæ‰‹å‹•å›æ¸¬ - (V2.4 åœ–è¡¨å¿ å¯¦ç‰ˆ)"""
        try:
            system_type = 'A' if len(gene) in range(27, 29) else 'B' if len(gene) in range(9, 11) else None
            if not system_type: 
                return {'success': False, 'error': f"ç„¡æ³•è­˜åˆ¥çš„åŸºå› é•·åº¦: {len(gene)}"}
            
            end_date_obj = datetime.strptime(end_date, "%Y-%m-%d").date()
            today = datetime.now().date()
            if end_date_obj > today:
                 return {'success': False, 'error': 'çµæŸæ—¥æœŸä¸èƒ½æ™šæ–¼ä»Šå¤©'}

            data_result, error_msg, user_start_date_iloc = self.load_stock_data(ticker, start_date, end_date, system_type)
            if error_msg: 
                return {'success': False, 'error': error_msg}
            
            ga_config = self.system_a_config if system_type == 'A' else self.system_b_config
            
            portfolio_values, buy_signals, sell_signals = self.generate_trading_signals(gene, data_result, ga_config, system_type)
            if not portfolio_values: 
                return {'success': False, 'error': 'ç„¡æ³•ç”Ÿæˆå›æ¸¬çµæœï¼Œå¯èƒ½æ˜¯æ­¤åŸºå› åœ¨æ­¤æœŸé–“ç„¡äº¤æ˜“ã€‚'}
            
            sliced_portfolio_raw = portfolio_values[user_start_date_iloc:]
            sliced_dates = data_result['dates'][user_start_date_iloc:]
            sliced_prices = data_result['prices'][user_start_date_iloc:]
            
            period_buy_signals, period_sell_signals = self._filter_signals_for_period(buy_signals, sell_signals, start_date)

            final_portfolio_for_metrics = []

            if not period_buy_signals and not period_sell_signals:
                final_portfolio_for_metrics = [1.0] * len(sliced_dates)
            else:
                first_trade_date = period_buy_signals[0]['date']
                first_trade_iloc = next((i for i, d in enumerate(sliced_dates) if d >= first_trade_date), 0)
                metrics_prefix = [1.0] * first_trade_iloc
                trade_period_portfolio = sliced_portfolio_raw[first_trade_iloc:]
                initial_trade_value = trade_period_portfolio[0] if len(trade_period_portfolio) > 0 else 1.0
                normalized_trade_curve = [p / initial_trade_value for p in trade_period_portfolio] if initial_trade_value > 0 else trade_period_portfolio
                final_portfolio_for_metrics.extend(metrics_prefix)
                final_portfolio_for_metrics.extend(normalized_trade_curve)

            metrics = calculate_performance_metrics(
                final_portfolio_for_metrics,
                sliced_dates,
                period_buy_signals, period_sell_signals,
                sliced_prices,
                risk_free_rate=ga_config.get('risk_free_rate', 0.025),
                commission_rate=ga_config.get('commission_rate', 0.0035)
            )

            # â–¼â–¼â–¼â–¼â–¼ ã€å”¯ä¸€çš„ä¿®æ”¹é»ã€‘ â–¼â–¼â–¼â–¼â–¼
            # å°‡ B&H å¡«å……çš„ display_portfolio_values æ›¿æ›ç‚ºçœŸå¯¦çš„ final_portfolio_for_metrics
            chart_image_url, chart_interactive_url = create_backtest_chart_assets(
                ticker, f"System{system_type}", "Manual",
                final_portfolio_for_metrics, # <--- å‚³éçœŸå¯¦çš„ç¸¾æ•ˆæ›²ç·š
                sliced_prices, sliced_dates,
                period_buy_signals, period_sell_signals
            )
            # â–²â–²â–²â–²â–² ã€ä¿®æ”¹çµæŸã€‘ â–²â–²â–²â–²â–²

            signal_status = None
            if end_date_obj == today:
                signal_status = self.analyze_signal_status(period_buy_signals, period_sell_signals)
            
            cache_buster = f"?v={int(time.time())}"

            return {
                'success': True, 'ticker': ticker, 'system_type_detected': f'ç³»çµ± {system_type}',
                'backtest_period': f"{start_date} ~ {end_date}",
                'metrics': metrics, 
                'chart_image_url': f"{chart_image_url}{cache_buster}" if chart_image_url else None, 
                'chart_interactive_url': f"{chart_interactive_url}{cache_buster}" if chart_interactive_url else None, 
                'signal_status': signal_status
            }
            
        except Exception as e:
            logger.error(f"æ‰‹å‹•å›æ¸¬éç¨‹ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
            return {'success': False, 'error': f'å›æ¸¬å¤±æ•—: {str(e)}'}

# ==============================================================================
#           >>> ã€æ­¥é©Ÿ 1: æ–°å¢ä½¿ç”¨è€…ç­–ç•¥ç›£æ§çš„æ ¸å¿ƒé‚è¼¯ã€‘ <<<
# ==============================================================================
class UserStrategyMonitor:
    """
    å°ˆé–€ç”¨æ–¼æ¯æ—¥æƒæå’Œæ›´æ–°ä½¿ç”¨è€…å„²å­˜ç­–ç•¥çš„æœ€æ–°ä¿¡è™Ÿã€‚
    """
    def __init__(self):
        # ä½¿ç”¨ä¸€å€‹è¼ƒçŸ­çš„å›æ¸¬é€±æœŸä»¥å¤§å¹…æé«˜æ•ˆèƒ½
        self.scan_period_days = 365 # åªå›æ¸¬æœ€è¿‘365å¤©çš„æ•¸æ“š
        self.signal_check_days = 7   # åˆ¤æ–·æœ€è¿‘7å¤©å…§çš„ä¿¡è™Ÿ
        self.start_date, self.end_date = self._get_date_range()
        self.trainer = SingleStockTrainer() # å€Ÿç”¨å…¶å…§éƒ¨æ–¹æ³•
        logger.info(f"ğŸ‘¤ [ä½¿ç”¨è€…ç­–ç•¥ç›£æ§] ç›£æ§å™¨åˆå§‹åŒ–ã€‚æƒææœŸé–“: {self.start_date} to {self.end_date}")

    def _get_date_range(self):
        # â–¼â–¼â–¼â–¼â–¼ã€éœ€æ±‚ä¿®æ”¹ã€‘â–¼â–¼â–¼â–¼â–¼
        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨æŒ‡å®šçš„ç›®æ¨™æƒææ—¥æœŸ
        if TARGET_SCAN_DATE:
            logger.info(f"ğŸ‘¤ [ä½¿ç”¨è€…ç­–ç•¥ç›£æ§] *** åµæ¸¬åˆ°ç›®æ¨™æƒææ—¥æœŸ: {TARGET_SCAN_DATE} ***")
            end_date_obj = datetime.strptime(TARGET_SCAN_DATE, "%Y-%m-%d").date()
        else:
            # æ¢å¾©æ­£å¸¸é‚è¼¯
            end_date_obj = datetime.now(pytz.timezone('Asia/Taipei')).date()
        # â–²â–²â–²â–²â–² ä¿®æ”¹çµæŸ â–²â–²â–²â–²â–²
        
        start_date_obj = end_date_obj - timedelta(days=self.scan_period_days)
        inclusive_end_date_for_yf = end_date_obj + timedelta(days=1)
        
        return start_date_obj.strftime("%Y-%m-%d"), inclusive_end_date_for_yf.strftime("%Y-%m-%d")


    def get_all_user_strategies(self):
        """å¾è³‡æ–™åº«ç²å–æ‰€æœ‰ä½¿ç”¨è€…å„²å­˜çš„ç­–ç•¥ã€‚"""
        query = "SELECT id, ticker, gene FROM saved_strategies"
        strategies = execute_db_query(query, fetch_all=True)
        logger.info(f"ğŸ‘¤ [ä½¿ç”¨è€…ç­–ç•¥ç›£æ§] å¾è³‡æ–™åº«æ‰¾åˆ° {len(strategies)} æ¢ä½¿ç”¨è€…ç­–ç•¥éœ€è¦æƒæã€‚")
        return strategies

# æª”æ¡ˆ: main_appå‚™åˆ†.py
# åœ¨ class UserStrategyMonitor ä¸­...

    def scan_strategy_for_recent_signal(self, ticker, gene_str):
                    
            try:
                gene = json.loads(gene_str)
                system_type = 'A' if len(gene) in range(27, 29) else 'B' if len(gene) in range(9, 11) else None
                if not system_type: return {'signal_type': 'NONE', 'signal_date': None}

                data_result, error_msg, _ = self.trainer.load_stock_data(ticker, self.start_date, self.end_date, system_type)
                
                if not data_result: 
                    if error_msg:
                        logger.warning(f"  -> æ•¸æ“šè¼‰å…¥å¤±æ•— for {ticker}: {error_msg}")
                    return {'signal_type': 'NONE', 'signal_date': None}

                ga_config = self.trainer.system_a_config if system_type == 'A' else self.trainer.system_b_config
                _, buy_signals, sell_signals = self.trainer.generate_trading_signals(gene, data_result, ga_config, system_type)

                last_buy_date = pd.to_datetime(buy_signals[-1]['date']).date() if buy_signals else None
                last_sell_date = pd.to_datetime(sell_signals[-1]['date']).date() if sell_signals else None
                
                # â–¼â–¼â–¼â–¼â–¼ã€éœ€æ±‚ä¿®æ”¹ã€‘â–¼â–¼â–¼â–¼â–¼
                # å†æ¬¡æª¢æŸ¥æ˜¯å¦å­˜åœ¨æŒ‡å®šçš„ç›®æ¨™æƒææ—¥æœŸï¼Œä»¥ç¢ºä¿æ—¥æœŸæ¯”è¼ƒåŸºæº–ä¸€è‡´
                if TARGET_SCAN_DATE:
                    scan_base_date = datetime.strptime(TARGET_SCAN_DATE, "%Y-%m-%d").date()
                else:
                    scan_base_date = datetime.now().date()
                # â–²â–²â–²â–²â–² ä¿®æ”¹çµæŸ â–²â–²â–²â–²â–²
                
                # æ‰¾å‡ºåœ¨ç›£æ¸¬æœŸå…§çš„è¿‘æœŸè²·è³£ä¿¡è™Ÿ
                # ä½¿ç”¨ scan_base_date ä¾†å–ä»£åŸæœ¬çš„ today
                recent_buy = last_buy_date if last_buy_date and (scan_base_date - last_buy_date).days < self.signal_check_days else None
                recent_sell = last_sell_date if last_sell_date and (scan_base_date - last_sell_date).days < self.signal_check_days else None
                
                final_signal_type = 'NONE'
                final_signal_date = None

                # åˆ¤æ–·æœ€æ–°çš„ "è¿‘æœŸ" ä¿¡è™Ÿ
                if recent_buy and recent_sell:
                    if recent_buy >= recent_sell:
                        final_signal_type = 'BUY'
                        final_signal_date = recent_buy
                    else:
                        final_signal_type = 'SELL'
                        final_signal_date = recent_sell
                elif recent_buy:
                    final_signal_type = 'BUY'
                    final_signal_date = recent_buy
                elif recent_sell:
                    final_signal_type = 'SELL'
                    final_signal_date = recent_sell
                
                # å¦‚æœè¿‘æœŸæ²’æœ‰ä»»ä½•æ–°ä¿¡è™Ÿï¼Œå‰‡åˆ¤æ–·é•·æœŸæŒå€‰ç‹€æ…‹
                if final_signal_type == 'NONE':
                    if last_buy_date and (not last_sell_date or last_buy_date > last_sell_date):
                        final_signal_type = 'HOLD'
                        final_signal_date = last_buy_date
                    else:
                        final_signal_type = 'NOP'
                        final_signal_date = last_sell_date
                
                return {'signal_type': final_signal_type, 'signal_date': final_signal_date}

            except Exception as e:
                logger.warning(f"  -> æƒæç­–ç•¥ {ticker} æ™‚å‡ºéŒ¯: {e}")
                return {'signal_type': 'NONE', 'signal_date': None}
    
    def run_scan_and_update_db(self):
        """
        åŸ·è¡Œå®Œæ•´æµç¨‹ï¼šç²å–ç­–ç•¥ -> æƒæ -> æ›´æ–°è³‡æ–™åº«
        """
        all_strategies = self.get_all_user_strategies()
        if not all_strategies:
            logger.info("ğŸ‘¤ [ä½¿ç”¨è€…ç­–ç•¥ç›£æ§] æ²’æœ‰æ‰¾åˆ°ä»»ä½•ä½¿ç”¨è€…ç­–ç•¥ï¼Œä»»å‹™çµæŸã€‚")
            return

        update_payloads = []
        for i, strategy in enumerate(all_strategies):
            logger.info(f"  - ({i+1}/{len(all_strategies)}) æ­£åœ¨æƒæç­–ç•¥ ID: {strategy['id']}, Ticker: {strategy['ticker']}...")
            signal_result = self.scan_strategy_for_recent_signal(strategy['ticker'], strategy['gene'])
            
            update_payloads.append({
                'id': strategy['id'],
                'last_signal_type': signal_result['signal_type'],
                'last_signal_date': signal_result['signal_date'],
                'last_checked_at': datetime.now()
            })

        # æ‰¹æ¬¡æ›´æ–°è³‡æ–™åº«
        if update_payloads:
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cursor:
                    update_query = """
                    UPDATE saved_strategies 
                    SET last_signal_type = %s, last_signal_date = %s, last_checked_at = %s
                    WHERE id = %s
                    """
                    # å°‡å­—å…¸åˆ—è¡¨è½‰æ›ç‚ºå…ƒçµ„åˆ—è¡¨
                    update_tuples = [
                        (p['last_signal_type'], p['last_signal_date'], p['last_checked_at'], p['id'])
                        for p in update_payloads
                    ]
                    cursor.executemany(update_query, update_tuples)
                    conn.commit()
                logger.info(f"ğŸ’¾ [ä½¿ç”¨è€…ç­–ç•¥ç›£æ§] æˆåŠŸæ‰¹æ¬¡æ›´æ–°äº† {len(update_payloads)} æ¢ç­–ç•¥çš„ä¿¡è™Ÿç‹€æ…‹ã€‚")
            except Exception as e:
                logger.error(f"âŒ [ä½¿ç”¨è€…ç­–ç•¥ç›£æ§] æ‰¹æ¬¡æ›´æ–°è³‡æ–™åº«å¤±æ•—: {e}", exc_info=True)
            finally:
                if conn: conn.close()
        
        logger.info("âœ… [ä½¿ç”¨è€…ç­–ç•¥ç›£æ§] æ‰€æœ‰ä½¿ç”¨è€…ç­–ç•¥æƒæèˆ‡æ›´æ–°ä»»å‹™å®Œæˆã€‚")

# ==============================================================================
#           >>> ã€æ­¥é©Ÿ 2: æ–°å¢æ’ç¨‹ä»»å‹™çš„ä¸»å‡½å¼ã€‘ <<<
# ==============================================================================
def run_user_strategies_scan():
    """æ¯æ—¥è‡ªå‹•åŸ·è¡Œçš„ä½¿ç”¨è€…ç­–ç•¥ç›£æ§ä»»å‹™"""
    with app.app_context():
        logger.info("="*50 + f"\nğŸ‘¤ [æ’ç¨‹ä»»å‹™] å•Ÿå‹•ä½¿ç”¨è€…ç­–ç•¥æ¯æ—¥æƒæ... (å°ç£æ™‚é–“: {datetime.now(pytz.timezone('Asia/Taipei'))})\n" + "="*50)
        try:
            if not ENGINES_IMPORTED:
                logger.error("âŒ [æ’ç¨‹ä»»å‹™] å›æ¸¬å¼•æ“æ¨¡çµ„æœªæˆåŠŸå°å…¥ã€‚ä½¿ç”¨è€…ç­–ç•¥æƒæä»»å‹™ä¸­æ­¢ã€‚")
                return
            
            monitor = UserStrategyMonitor()
            monitor.run_scan_and_update_db()

        except Exception as e:
            logger.error(f"\nâŒ [æ’ç¨‹ä»»å‹™] ä½¿ç”¨è€…ç­–ç•¥æƒæåŸ·è¡ŒæœŸé–“ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}\n{traceback.format_exc()}")
        finally:
            logger.info("=" * 50)

# å»ºç«‹è¨“ç·´å™¨å¯¦ä¾‹
trainer = SingleStockTrainer()

# ==============================================================================
# >>> ä»¥ä¸‹ç‚ºåŸå§‹ program.py çš„å…¶ä»–åŠŸèƒ½æ¨¡çµ„ (çœç•¥ä»¥ç¯€çœç¯‡å¹…ï¼Œä½†å¯¦éš›ä½¿ç”¨æ™‚éœ€è¦åŒ…å«) <<<
# ==============================================================================

# æ–°èæƒ…ç·’åˆ†æç›¸é—œå¸¸æ•¸å’Œå‡½å¼
MOCK_TODAY = None
MAX_TOTAL_HEADLINES = 100
MAX_HEADLINES_PER_TOPIC = 5
CSV_FILEPATH = '2021-2025æ¯é€±æ–°èåŠæƒ…ç·’åˆ†æ.csv'

TARGET_COMPANIES_AND_TOPICS = {
    "Apple": "AAPL", "Microsoft": "MSFT", "Nvidia": "NVDA", "Google": "GOOGL",
    "Amazon": "AMZN", "Meta": "META", "Tesla": "TSLA",
    "S&P 500": None, "Nasdaq": None, "Dow Jones": None, "Federal Reserve": "Fed",
    "inflation": "CPI", "jobs report": "nonfarm payrolls", "interest rates": None,
    "crude oil": "WTI", "US election": None, "trade war": "tariffs","war": "war",
    "Trump": "tariffs",
}

# FinBERT æ¨¡å‹ç›¸é—œ
finbert_tokenizer = None
finbert_model = None

if not FINBERT_AVAILABLE:
    logger.warning("PyTorch æˆ– Transformers æœªå®‰è£ï¼ŒFinBERT æƒ…ç·’åˆ†æåŠŸèƒ½å°‡è¢«è·³éã€‚")


# === ä¾†è‡ª program.py çš„åŸå§‹é¦–é è·¯ç”± ===
@app.route('/')
def home():
    """åŸå§‹å¸‚å ´åˆ†æå„€è¡¨æ¿é¦–é """
    return redirect(url_for('trainer_page'))

# === å¾ stock_ga_web.py ç§»æ¤ï¼šç­–ç•¥è¨“ç·´å¹³å°è·¯ç”± ===
@app.route('/trainer')
@login_required
def trainer_page():
    """ç­–ç•¥è¨“ç·´å¹³å°ä¸»é é¢"""
    return render_template('index_page.html')

@app.route('/login')
def login_page():
    """æä¾›ç™»å…¥é é¢"""
    if current_user.is_authenticated:
        return redirect(url_for('trainer_page'))
    return render_template('login.html')

# === å¾ stock_ga_web.py ç§»æ¤ï¼šä½¿ç”¨è€…èªè­‰ API ===
@app.route('/api/register', methods=['POST'])
def api_register():
    data = request.get_json()
    username = data.get('username')
    email = data.get('email')
    password = data.get('password')
    password_confirm = data.get('password_confirm')
    
    if not all([username, email, password, password_confirm]):
        return jsonify({'success': False, 'message': 'æ‰€æœ‰æ¬„ä½éƒ½ä¸èƒ½ç‚ºç©º'}), 400
    
    if password != password_confirm:
        return jsonify({'success': False, 'message': 'å…©æ¬¡è¼¸å…¥çš„å¯†ç¢¼ä¸ä¸€è‡´'}), 400
    
    if execute_db_query("SELECT id FROM users WHERE email = %s", (email,), fetch_one=True):
        return jsonify({'success': False, 'message': 'æ­¤ Email å·²è¢«è¨»å†Š'}), 409
    
    password_hash = generate_password_hash(password)
    sql = "INSERT INTO users (username, email, password_hash) VALUES (%s, %s, %s)"
    execute_db_query(sql, (username, email, password_hash))
    
    return jsonify({'success': True, 'message': 'è¨»å†ŠæˆåŠŸï¼è«‹ä½¿ç”¨ Email ç™»å…¥ã€‚'}), 201

@app.route('/api/login', methods=['POST'])
def api_login():
    data = request.get_json()
    email = data.get('email')
    password = data.get('password')
    
    user_data = execute_db_query("SELECT * FROM users WHERE email = %s", (email,), fetch_one=True)
    
    if user_data and check_password_hash(user_data['password_hash'], password):
        user = User(user_data)
        login_user(user, remember=True)
        
        # é—œéµï¼šç²å– next åƒæ•¸ï¼Œå¦‚æœæ²’æœ‰ï¼Œå°±é è¨­è·³è½‰åˆ° /trainer
        next_url = request.args.get('next')
        # å¢åŠ å®‰å…¨æ€§æª¢æŸ¥ï¼Œé˜²æ­¢é–‹æ”¾é‡å°å‘æ¼æ´
        if not next_url or not next_url.startswith('/'):
            next_url = url_for('trainer_page')
            
        return jsonify({'success': True, 'message': 'ç™»å…¥æˆåŠŸ', 'redirect_url': next_url}) # <--- è¿”å›é‡å°å‘ URL
    
    return jsonify({'success': False, 'message': 'Email æˆ–å¯†ç¢¼éŒ¯èª¤'}), 401

@app.route('/api/logout')
@login_required
def api_logout():
    logout_user()
    return jsonify({'success': True, 'message': 'å·²æˆåŠŸç™»å‡º'})

@app.route('/api/user/status')
def user_status():
    if current_user.is_authenticated:
        return jsonify({'logged_in': True, 'username': current_user.username})
    return jsonify({'logged_in': False})

# === å¾ stock_ga_web.py ç§»æ¤ï¼šæ ¸å¿ƒåŠŸèƒ½ API (å·²å—ä¿è­·) ===
@app.route('/api/train', methods=['POST'])
@login_required
def api_train():
    """
    (æ–°ç‰ˆ) è¨“ç·´APIç«¯é» - æ¥æ”¶è«‹æ±‚ï¼Œç”¢ç”Ÿä»»å‹™IDï¼Œä¸¦å°‡ä»»å‹™æ”¾å…¥ä½‡åˆ—ã€‚
    """
    if not ENGINES_IMPORTED:
        return jsonify({'success': False, 'errors': ['éºå‚³ç®—æ³•å¼•æ“æœªæ­£ç¢ºè¼‰å…¥']}), 500
    
    try:
        data = request.json
        ticker = data.get('ticker', '').strip().upper()
        start_date = data.get('start_date')
        end_date = data.get('end_date')
        custom_weights = data.get('custom_weights', trainer.default_custom_weights)
        
        logger.info(f"Validating ticker '{ticker}' and checking if it needs to be added to lists...")
        analyzer = EnhancedStockAnalyzer(ticker)
        stock_data = analyzer.get_basic_stock_data()
        
        if not stock_data.get("success"):
            return jsonify({'success': False, 'errors': [stock_data.get('error', 'Invalid ticker')]}), 400
        
        validated_ticker = stock_data['ticker']
        market = stock_data['market']
        log_new_ticker_to_csv(validated_ticker, market)
        
        basic_params_from_user = data.get('basic_params', {})
        
        # â–¼â–¼â–¼â–¼â–¼ã€éœ€æ±‚ä¿®æ”¹ã€‘æš—æ”¹æœ€ä½äº¤æ˜“æ¬¡æ•¸ â–¼â–¼â–¼â–¼â–¼
        user_min_trades = int(basic_params_from_user.get('min_trades', 4))
        # å¦‚æœä½¿ç”¨è€…è¨­å®šçš„äº¤æ˜“æ¬¡æ•¸ä½æ–¼ 3ï¼Œå‰‡åœ¨å¾Œç«¯å¼·åˆ¶ä¿®æ”¹ç‚º 3
        effective_min_trades = 3 if user_min_trades < 3 else user_min_trades
        if effective_min_trades != user_min_trades:
            logger.info(f"[Trainer] ä½¿ç”¨è€…è¨­å®š min_trades={user_min_trades}ï¼Œå·²è‡ªå‹•ä¿®æ­£ç‚º {effective_min_trades}ã€‚")
        
        fixed_basic_params = {
            'min_trades': effective_min_trades # ä½¿ç”¨ä¿®æ­£å¾Œçš„å€¼
        }
        # â–²â–²â–²â–²â–² ä¿®æ”¹çµæŸ â–²â–²â–²â–²â–²

        task_id = str(uuid.uuid4())

        task_data = {
            'ticker': validated_ticker,
            'start_date': start_date,
            'end_date': end_date,
            'custom_weights': custom_weights,
            'basic_params': fixed_basic_params
        }
        
        task_queue.put((task_id, task_data))
        
        with results_lock:
            task_results[task_id] = {'status': 'QUEUED'}
        
        logger.info(f"ğŸ“¥ è¨“ç·´ä»»å‹™å·²åŠ å…¥ä½‡åˆ—ï¼ŒID: {task_id}ã€‚ç›®å‰ä½‡åˆ—å¤§å°: {task_queue.qsize()}")
        return jsonify({
            'success': True,
            'message': 'è¨“ç·´ä»»å‹™å·²æˆåŠŸæäº¤ï¼Œæ­£åœ¨æ’éšŠç­‰å€™åŸ·è¡Œã€‚',
            'task_id': task_id,
        }), 202

    except Exception as e:
        logger.error(f"APIéŒ¯èª¤ /api/train: {e}", exc_info=True)
        return jsonify({'success': False, 'errors': [f'APIä¼ºæœå™¨éŒ¯èª¤: {str(e)}']}), 500

# ã€æ–°å¢ç¨‹å¼ç¢¼ STARTã€‘
# åœ¨ /api/train ä¹‹å¾Œï¼Œæ–°å¢é€™å€‹ç”¨æ–¼ç‹€æ…‹æŸ¥è©¢çš„ API
@app.route('/api/task_status/<string:task_id>')
@login_required
def get_task_status(task_id):
    """æŸ¥è©¢å…§å»ºä»»å‹™ç³»çµ±çš„ç‹€æ…‹å’Œçµæœã€‚"""
    with results_lock:
        # å¾çµæœå­—å…¸ä¸­å®‰å…¨åœ°ç²å–ä»»å‹™è³‡è¨Š
        task = task_results.get(task_id, {})
    
    # å¦‚æœä»»å‹™å®Œæˆ(æˆåŠŸæˆ–å¤±æ•—)ï¼Œæˆ‘å€‘æ‰è¿”å›çµæœï¼Œå¦å‰‡ result ç‚º null
    result_payload = None
    if task.get('status') in ['SUCCESS', 'FAILURE']:
        result_payload = task.get('result')

    response = {
        'task_id': task_id,
        'status': task.get('status', 'NOT_FOUND'), # å¦‚æœ task_id ä¸å­˜åœ¨ï¼Œè¿”å› NOT_FOUND
        'result': result_payload
    }
    return jsonify(response)
# ã€æ–°å¢ç¨‹å¼ç¢¼ ENDã€‘

# =================== ã€ä¿®æ”¹æ­¤å‡½å¼ã€‘ ===================
@app.route('/api/manual-backtest', methods=['POST'])
@login_required
def api_manual_backtest():
    if not ENGINES_IMPORTED:
        return jsonify({'success': False, 'error': 'éºå‚³ç®—æ³•å¼•æ“æœªæ­£ç¢ºè¼‰å…¥'}), 500
    
    try:
        data = request.json
        ticker = data.get('ticker', '').strip().upper()
        gene = data.get('gene')
        # ã€ä¿®æ”¹é»ã€‘æ¥æ”¶ start_date å’Œ end_dateï¼Œä¸å†ä½¿ç”¨ duration_months
        start_date = data.get('start_date')
        end_date = data.get('end_date')
        
        # ã€ä¿®æ”¹é»ã€‘æ›´æ–°é©—è­‰é‚è¼¯
        if not all([ticker, gene, start_date, end_date]) or not isinstance(gene, list):
            return jsonify({'success': False, 'error': 'ç„¡æ•ˆçš„è¼¸å…¥åƒæ•¸'}), 400
        
        # ã€ä¿®æ”¹é»ã€‘å°‡æ–°åƒæ•¸å‚³éçµ¦æ ¸å¿ƒæ–¹æ³•
        result = trainer.run_manual_backtest(ticker, gene, start_date, end_date)
        return jsonify(result)
    except Exception as e:
        logger.error(f"æ‰‹å‹•å›æ¸¬APIéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'error': f'API ä¼ºæœå™¨éŒ¯èª¤: {str(e)}'}), 500

# === å¾ stock_ga_web.py ç§»æ¤ï¼šç­–ç•¥ç®¡ç† API ===
@app.route('/api/strategies', methods=['POST'])
@login_required
def save_strategy():
    """å„²å­˜ä¸€å€‹æ–°ç­–ç•¥åˆ°ä½¿ç”¨è€…çš„æ¸…å–®ä¸­"""
    try:
        data = request.get_json()
        required_fields = ['ticker', 'train_start_date', 'train_end_date', 'gene', 'metrics', 'strategy_details']
        if not all(field in data for field in required_fields):
            return jsonify({'success': False, 'message': 'ç¼ºå°‘å¿…è¦åƒæ•¸'}), 400
        
        metrics = data['metrics']
        
        sql = """
        INSERT INTO saved_strategies (
            user_id, ticker, train_start_date, train_end_date, gene,
            win_rate, total_return, trade_count, avg_trade_return, max_drawdown, sharpe_ratio,
            max_trade_extremes, strategy_details
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        args = (
            current_user.id,
            data['ticker'],
            data['train_start_date'],
            data['train_end_date'],
            json.dumps(data.get('gene', [])),
            metrics.get('win_rate_pct', 0.0),
            metrics.get('total_return', 0.0),
            metrics.get('trade_count', 0),
            metrics.get('average_trade_return', 0.0),
            metrics.get('max_drawdown', 0.0),
            metrics.get('sharpe_ratio', 0.0),  # <--- æ–°å¢é€™ä¸€è¡Œ
            f"{metrics.get('max_trade_gain_pct', 0.0):.2f}% / {metrics.get('max_trade_drop_pct', 0.0):.2f}%", 
            data.get('strategy_details', '')
        )
        
        execute_db_query(sql, args)
        return jsonify({'success': True, 'message': 'ç­–ç•¥å·²æˆåŠŸå„²å­˜ï¼'}), 201
    except Exception as e:
        logger.error(f"å„²å­˜ç­–ç•¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨éŒ¯èª¤: {str(e)}'}), 500

@app.route('/api/strategies', methods=['GET'])
@login_required
def get_strategies():
    """ç²å–ç›®å‰ä½¿ç”¨è€…å„²å­˜çš„æ‰€æœ‰ç­–ç•¥"""
    try:
        sql = "SELECT * FROM saved_strategies WHERE user_id = %s ORDER BY saved_at DESC"
        strategies_from_db = execute_db_query(sql, (current_user.id,), fetch_all=True)
        
        strategies_serializable = []
        if strategies_from_db:
            for s in strategies_from_db:
                for key in ['win_rate', 'total_return', 'avg_trade_return', 'max_drawdown']:
                    if s.get(key) is not None:
                        s[key] = float(s[key])
                
                if isinstance(s.get('gene'), str):
                    try:
                        s['gene'] = json.loads(s['gene'])
                    except json.JSONDecodeError:
                        s['gene'] = []
                
                for dt_key in ['saved_at', 'train_start_date', 'train_end_date']:
                    if isinstance(s.get(dt_key), (datetime, date)):
                        s[dt_key] = s[dt_key].isoformat().split('T')[0]
                
                strategies_serializable.append(s)
        
        return jsonify({'success': True, 'strategies': strategies_serializable})
    except Exception as e:
        logger.error(f"ç²å–ç­–ç•¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨éŒ¯èª¤: {str(e)}'}), 500

@app.route('/api/strategies/<int:strategy_id>', methods=['DELETE'])
@login_required
def delete_strategy(strategy_id):
    """åˆªé™¤ä¸€å€‹æŒ‡å®šçš„ç­–ç•¥"""
    try:
        sql = "DELETE FROM saved_strategies WHERE id = %s AND user_id = %s"
        rowcount = execute_db_query(sql, (strategy_id, current_user.id))
        
        if rowcount > 0:
            return jsonify({'success': True, 'message': 'ç­–ç•¥å·²åˆªé™¤'})
        else:
            return jsonify({'success': False, 'message': 'æ‰¾ä¸åˆ°ç­–ç•¥æˆ–æ¬Šé™ä¸è¶³'}), 404
            
    except Exception as e:
        logger.error(f"åˆªé™¤ç­–ç•¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨éŒ¯èª¤: {e}'}), 500

@app.route('/api/strategies/batch-delete', methods=['DELETE'])
@login_required
def batch_delete_strategies():
    """æ‰¹æ¬¡åˆªé™¤å¤šå€‹æŒ‡å®šçš„ç­–ç•¥"""
    try:
        data = request.get_json()
        strategy_ids = data.get('strategy_ids')

        # é©—è­‰è¼¸å…¥
        if not strategy_ids or not isinstance(strategy_ids, list):
            return jsonify({'success': False, 'message': 'ç„¡æ•ˆçš„è«‹æ±‚ï¼Œæœªæä¾›ç­–ç•¥ ID æ¸…å–®'}), 400
        
        # ç¢ºä¿æ‰€æœ‰ ID éƒ½æ˜¯æ•¸å­—ï¼Œå¢åŠ å®‰å…¨æ€§
        if not all(isinstance(sid, int) for sid in strategy_ids):
            return jsonify({'success': False, 'message': 'ç„¡æ•ˆçš„ç­–ç•¥ ID æ ¼å¼'}), 400

        # å‰µå»ºå°æ‡‰æ•¸é‡çš„ä½”ä½ç¬¦
        placeholders = ', '.join(['%s'] * len(strategy_ids))
        
        # å»ºç«‹ SQL æŸ¥è©¢ï¼Œç¢ºä¿åªåˆªé™¤å±¬æ–¼ç•¶å‰ä½¿ç”¨è€…çš„ç­–ç•¥
        sql = f"DELETE FROM saved_strategies WHERE id IN ({placeholders}) AND user_id = %s"
        
        # æº–å‚™åƒæ•¸ï¼Œå°‡ user_id æ”¾åœ¨æœ€å¾Œ
        params = tuple(strategy_ids) + (current_user.id,)
        
        rowcount = execute_db_query(sql, params)
        
        return jsonify({'success': True, 'message': f'å·²æˆåŠŸåˆªé™¤ {rowcount} å€‹ç­–ç•¥'})

    except Exception as e:
        logger.error(f"æ‰¹æ¬¡åˆªé™¤ç­–ç•¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨éŒ¯èª¤: {str(e)}'}), 500
    
# ==============================================================================
# >>> æ–°å¢ï¼šè³‡é‡‘é…ç½® API ç«¯é» <<<
# ==============================================================================

def _build_allocation_prompt(risk_profile, strategies_data):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼å‹•æ…‹ç”Ÿæˆçµ¦ Gemini çš„ Prompt - åŠ å¼·ç‰ˆ"""
    
    # 1. æ§‹å»ºç­–ç•¥è³‡ç”¢çš„æ–‡å­—æè¿°
    assets_description = ""
    search_queries = []
    
    for i, strategy in enumerate(strategies_data, 1):
        # --- START: ä¿®æ­£å¾Œçš„ç¨‹å¼ç¢¼å€å¡Š ---
        # è™•ç†æœ€å¤§æ¼²è·Œå¹…ï¼Œä½¿å…¶æ›´ç©©å¥
        extremes_str = strategy.get('max_trade_extremes', '0% / 0%')
        parts = extremes_str.split('/')

        if len(parts) == 2:
            # é€™æ˜¯é æœŸçš„æ ¼å¼ï¼Œä¾‹å¦‚: "-12.3% / +25.4%"
            max_drop = parts[0].strip()
            max_gain = parts[1].strip()
        else:
            # è™•ç†é‚Šç•Œæƒ…æ³ï¼Œä¾‹å¦‚ "N/A" æˆ–å…¶ä»–æ²’æœ‰ '/' çš„æ ¼å¼
            max_drop = parts[0].strip() if parts else 'N/A'
            max_gain = 'N/A' # çµ¦ä¸€å€‹å®‰å…¨çš„é è¨­å€¼
        # --- END: ä¿®æ­£å¾Œçš„ç¨‹å¼ç¢¼å€å¡Š ---
        
        # ç‚ºæ¯å€‹è‚¡ç¥¨æº–å‚™æœå°‹é—œéµå­—
        ticker = strategy['ticker']
        search_queries.append(f"{ticker} stock news today")
        search_queries.append(f"{ticker} earnings financial results")
        
        assets_description += f"""
è³‡ç”¢ {i}: {ticker}
- ç¸½å ±é…¬ç‡: {float(strategy['total_return'])*100:+.2f}%
- å¹³å‡äº¤æ˜“å ±é…¬ç‡: {float(strategy['avg_trade_return'])*100:+.3f}%
- å‹ç‡: {float(strategy['win_rate']):.1f}%
- æœ€å¤§å›æ’¤: -{float(strategy['max_drawdown'])*100:.2f}%
- æœ€å¤§æ¼²è·Œå¹…: {max_gain} / {max_drop}
"""

    # 2. æ§‹å»ºå®Œæ•´çš„ Promptï¼ˆå„ªåŒ–ç‰ˆï¼‰
    prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„æŠ•è³‡çµ„åˆç¶“ç†ï¼Œéœ€è¦ç‚ºå®¢æˆ¶åˆ†é…æŠ•è³‡è³‡é‡‘ã€‚

**ç¬¬ä¸€æ­¥ï¼šæœå°‹æœ€æ–°è³‡è¨Š**
è«‹ä½¿ç”¨ Google Search å·¥å…·æœå°‹ä»¥ä¸‹æ¯å€‹è‚¡ç¥¨çš„æœ€æ–°è³‡è¨Šï¼š

{chr(10).join([f"- {query}" for query in search_queries])}

é‡é»æœå°‹å…§å®¹ï¼š
- æœ€æ–°è²¡å ±å’Œæ¥­ç¸¾è¡¨ç¾
- é‡å¤§æ–°èäº‹ä»¶å’Œå…¬å¸å‹•æ…‹
- åˆ†æå¸«è©•ç´šå’Œç›®æ¨™åƒ¹
- è¡Œæ¥­è¶¨å‹¢å’Œå¸‚å ´æƒ…ç·’

**ç¬¬äºŒæ­¥ï¼šæŠ•è³‡çµ„åˆåˆ†æ**

å®¢æˆ¶é¢¨éšªåå¥½: {risk_profile}
- ä¿å®ˆå‹ï¼šé‡è¦–ç©©å®šæ€§ï¼Œå„ªå…ˆä½å›æ’¤ã€é«˜å‹ç‡çš„ç­–ç•¥
- å‡è¡¡å‹ï¼šå¹³è¡¡æ”¶ç›Šèˆ‡é¢¨éšªï¼Œå°‹æ±‚æœ€ä½³é¢¨éšªèª¿æ•´å¾Œå ±é…¬
- ç©æ¥µå‹ï¼šè¿½æ±‚é«˜å ±é…¬ï¼Œå¯æ‰¿å—è¼ƒé«˜æ³¢å‹•ï¼Œä½†ä»éœ€ç¨å¾®å›æ’¤é¢¨éšªåŠå‹ç‡

ç­–ç•¥è³‡ç”¢ç¸¾æ•ˆæ•¸æ“š:
{assets_description}

**æ­¥é©Ÿ 3ï¼šè¼¸å‡ºçµæœ**
åŸºæ–¼ä»¥ä¸Šæ‰€æœ‰è³‡è¨Šï¼Œ**åš´æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›æ‡‰**ï¼Œä¸è¦æœ‰ä»»ä½•é¡å¤–æ–‡å­—æˆ–markdownã€‚ç†ç”±(justification)å¿…é ˆéå¸¸ç°¡æ½”ï¼Œé™æ–¼30-50å­—ã€‚

{{
  "allocations": [
    {{"ticker": "è‚¡ç¥¨ä»£è™Ÿ", "percentage": æ•¸å­—}},
    {{"ticker": "è‚¡ç¥¨ä»£è™Ÿ", "percentage": æ•¸å­—}}
  ],
  "reasoning": {{
    "overall_summary": "å°æ•´é«”é…ç½®ç­–ç•¥çš„ç°¡çŸ­ç¸½çµ(50-70å­—)ã€‚",
    "per_stock_analysis": [
      {{
        "ticker": "è‚¡ç¥¨ä»£è™Ÿ",
        "role_in_portfolio": "ç”¨ 'æ ¸å¿ƒå¢é•·'ã€'è¡›æ˜Ÿé…ç½®' æˆ– 'ç©©å®šåŸºçŸ³' ä¾†å®šç¾©å…¶è§’è‰²ã€‚",
        "justification": "ä¸€å¥è©±è§£é‡‹ç‚ºä½•å¦‚æ­¤é…ç½®ï¼Œä»¥åŠå®ƒåœ¨çµ„åˆä¸­çš„ä½œç”¨ã€‚"
      }}
    ]
  }}
}}

**è¼¸å‡ºè¦æ±‚ï¼š**
- æ‰€æœ‰ç™¾åˆ†æ¯”ç¸½å’Œå¿…é ˆæ˜¯100ã€‚
- åˆ†æç†ç”±å¿…é ˆç²¾ç…‰ã€å°ˆæ¥­ã€ç›´æŒ‡æ ¸å¿ƒã€‚
- **æœ€çµ‚çš„è¼¸å‡ºå…§å®¹ä¸­ï¼Œçµ•å°ä¸èƒ½åŒ…å«ä»»ä½•æ–¹æ‹¬è™Ÿ `[]` åŠ ä¸Šæ•¸å­—çš„å¼•æ–‡æ¨™è¨˜ã€åŸºå› åºåˆ—ã€‚**
"""
    
    return prompt

def _build_new_gemini_prompt(tickers_list):
    """
    ç‚ºæˆ‘å€‘çš„é‡åŒ–æ¨¡å‹ï¼Œç”Ÿæˆä¸€å€‹å°ˆæ³¨æ–¼å¸‚å ´åˆ†æçš„ Gemini Promptã€‚
    """
    unique_tickers = sorted(list(set(tickers_list)))

    prompt = f"""ä½ æ˜¯é ‚å°–çš„é‡‘èå¸‚å ´åˆ†æå¸«ã€‚è«‹åŸºæ–¼æœ€æ–°çš„å¸‚å ´è³‡è¨Šï¼Œç‚ºä»¥ä¸‹è‚¡ç¥¨æ¸…å–®æä¾›ç°¡æ½”çš„è³ªåŒ–åˆ†æã€‚

**åˆ†æç›®æ¨™è‚¡ç¥¨:**

{json.dumps(unique_tickers, indent=2)}

**ä»»å‹™:**

1. ä½¿ç”¨ Google Search æœå°‹æ¯æ”¯è‚¡ç¥¨æœ€è¿‘ä¸€å€‹æœˆçš„é‡å¤§æ–°èã€è²¡å ±è¡¨ç¾ã€åˆ†æå¸«è©•ç´šè®ŠåŒ–ã€‚

2. åˆ¤æ–·æ¯æ”¯è‚¡ç¥¨ç•¶å‰çš„å¸‚å ´æƒ…ç·’å’ŒçŸ­æœŸï¼ˆæœªä¾†1-3å€‹æœˆï¼‰çš„æ½›åœ¨å‚¬åŒ–åŠ‘æˆ–é¢¨éšªã€‚

**è¼¸å‡ºæ ¼å¼:**

è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼Œä¸è¦æœ‰ä»»ä½•é¡å¤–æ–‡å­—æˆ– markdownã€‚

{{

"analysis": [

{{

"ticker": "è‚¡ç¥¨ä»£è™Ÿ",

"sentiment": "ç”¨ 'Bullish', 'Neutral', 'Bearish' ä¸‰å€‹è©ä¹‹ä¸€ä¾†æè¿°",

"summary": "ä¸€å¥è©±ç¸½çµå…¶ç•¶å‰çš„å¸‚å ´åœ°ä½å’ŒçŸ­æœŸå±•æœ› (30-50å­—ã€ä½¿ç”¨ç¹é«”ä¸­æ–‡)ã€‚"

}}

],

"overall_summary": "å°é€™å¹¾æ”¯è‚¡ç¥¨æ‰€åœ¨çš„å¸‚å ´æ¿å¡Šæˆ–æ•´é«”å¸‚å ´æ°›åœçš„ç°¡çŸ­ç¸½çµ (50-70å­—ã€ä½¿ç”¨ç¹é«”ä¸­æ–‡)ã€‚"

}}

**é‡è¦æé†’ï¼š**

- `summary` å…§å®¹å¿…é ˆç°¡æ½”ã€ç²¾æº–ã€‚

- æœ€çµ‚çš„è¼¸å‡ºå…§å®¹ä¸­ï¼Œçµ•å°ä¸èƒ½åŒ…å«ä»»ä½•æ–¹æ‹¬è™Ÿ `[]` åŠ ä¸Šæ•¸å­—çš„å¼•æ–‡æ¨™è¨˜ã€‚

"""

    return prompt


def calculate_annualized_return(total_return, start_date_str, end_date_str):
    """æ ¹æ“šç¸½å ±é…¬ç‡å’Œèµ·è¨–æ—¥æœŸï¼Œè¨ˆç®—å¹´åŒ–å ±é…¬ç‡ (CAGR)ã€‚"""
    try:
        # ç¢ºä¿æ—¥æœŸæ˜¯å­—ä¸²æ ¼å¼
        start_date = datetime.strptime(str(start_date_str), '%Y-%m-%d')
        end_date = datetime.strptime(str(end_date_str), '%Y-%m-%d')
        
        days = (end_date - start_date).days
        if days <= 30: # å¦‚æœè¨“ç·´æœŸå¤ªçŸ­ï¼Œå¹´åŒ–æ„ç¾©ä¸å¤§ï¼Œç›´æ¥è¿”å›0æˆ–ç¸½å ±é…¬
            return total_return 

        number_of_years = days / 365.25
        if number_of_years <= 0: return 0.0

        ending_value = 1 + float(total_return)
        # è™•ç† total_return æ˜¯è² æ•¸çš„æƒ…æ³
        if ending_value < 0:
            return -1.0 # å¦‚æœè™§åˆ°æœ¬é‡‘éƒ½æ²’äº†ï¼Œå¹´åŒ–æ˜¯è² ç„¡çª®ï¼Œè¿”å›-100%

        annualized_rate = (ending_value ** (1 / number_of_years)) - 1
        return annualized_rate
    except (ValueError, TypeError, AttributeError):
        # å¦‚æœæ—¥æœŸæ ¼å¼éŒ¯èª¤æˆ–ç„¡æ•ˆï¼Œè¿”å›ä¸€å€‹å®‰å…¨çš„0.0
        return 0.0

def assign_portfolio_roles(strategies_data):
    """
    æ ¹æ“šç­–ç•¥çš„åˆ†æ•¸ï¼Œåˆ†é…ã€Œæ ¸å¿ƒå¢é•·ã€ã€ã€Œç©©å®šåŸºçŸ³ã€ã€ã€Œè¡›æ˜Ÿé…ç½®ã€çš„è§’è‰²ã€‚
    
    Args:
        strategies_data: åŒ…å«æ¯å€‹ç­–ç•¥æ‰€æœ‰æ•¸æ“šçš„åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹å­—å…¸ï¼Œ
                         å¿…é ˆåŒ…å« 'ticker', 'final_adjusted_score', 'stability_score'ã€‚
                                     
    Returns:
        ä¸€å€‹å­—å…¸ï¼Œéµæ˜¯ tickerï¼Œå€¼æ˜¯åˆ†é…çš„è§’è‰²å­—ä¸²ã€‚
    """
    if not strategies_data:
        return {}

    # è™•ç†åªæœ‰ä¸€å€‹ç­–ç•¥çš„æƒ…æ³
    if len(strategies_data) == 1:
        return {strategies_data[0]['ticker']: 'æ ¸å¿ƒå¢é•·'}

    # æŒ‰ final_adjusted_score é™åºæ’åº
    strategies_sorted = sorted(strategies_data, key=lambda x: x['final_adjusted_score'], reverse=True)
    
    # 1. æŒ‡å®šã€Œæ ¸å¿ƒå¢é•·ã€
    core_growth_strategy = strategies_sorted[0]
    roles = {core_growth_strategy['ticker']: 'æ ¸å¿ƒå¢é•·'}
    
    # 2. åœ¨å‰©é¤˜ç­–ç•¥ä¸­ï¼Œæ‰¾å‡ºã€Œç©©å®šåŸºçŸ³ã€
    remaining_strategies = [s for s in strategies_data if s['ticker'] != core_growth_strategy['ticker']]
    
    if remaining_strategies:
        stable_cornerstone_strategy = max(remaining_strategies, key=lambda x: x['stability_score'])
        roles[stable_cornerstone_strategy['ticker']] = 'ç©©å®šåŸºçŸ³'

    # 3. å…¶é¤˜çš„éƒ½æ˜¯ã€Œè¡›æ˜Ÿé…ç½®ã€
    for strategy in strategies_data:
        if strategy['ticker'] not in roles:
            roles[strategy['ticker']] = 'è¡›æ˜Ÿé…ç½®'
            
    return roles

def _allocate_percentages_largest_remainder(strategies):
    """
    ä½¿ç”¨æœ€å¤§é¤˜é¡æ³•ä¾†åˆ†é…æ•´æ•¸ç™¾åˆ†æ¯”ï¼Œç¢ºä¿ç¸½å’Œç‚º100ä¸”ç„¡è² æ•¸ã€‚
    Args:
        strategies: ä¸€å€‹å­—å…¸åˆ—è¡¨ï¼Œæ¯å€‹å­—å…¸å¿…é ˆåŒ…å« 'ticker' å’Œ 'final_adjusted_score'ã€‚
    Returns:
        ä¸€å€‹å­—å…¸åˆ—è¡¨ï¼ŒåŒ…å« 'ticker' å’Œ 'percentage'ã€‚
    """
    total_score = sum(s['final_adjusted_score'] for s in strategies)
    if total_score <= 0:
        # å¦‚æœç¸½åˆ†ç‚º0æˆ–è² æ•¸ï¼Œå‰‡å¹³å‡åˆ†é…
        equal_share = 100 // len(strategies)
        remainder = 100 % len(strategies)
        allocations = [{'ticker': s['ticker'], 'percentage': equal_share} for s in strategies]
        for i in range(remainder):
            allocations[i]['percentage'] += 1
        return allocations

    # 1. è¨ˆç®—æ¯å€‹ç­–ç•¥çš„ç²¾ç¢ºç™¾åˆ†æ¯”å’Œé¤˜é¡
    for s in strategies:
        exact_percentage = (s['final_adjusted_score'] / total_score) * 100
        s['exact_percentage'] = exact_percentage
        s['floor_percentage'] = int(exact_percentage)
        s['remainder'] = exact_percentage - s['floor_percentage']

    # 2. åˆ†é…åŸºç¤ç™¾åˆ†æ¯” (æ•´æ•¸éƒ¨åˆ†)
    allocated_sum = sum(s['floor_percentage'] for s in strategies)
    
    # 3. è¨ˆç®—é‚„éœ€åˆ†é…å¤šå°‘å€‹ 1%
    remainder_to_distribute = 100 - allocated_sum

    # 4. æ ¹æ“šé¤˜é¡å¤§å°æ’åºï¼Œä¾†æ±ºå®šèª°èƒ½ç²å¾—é¡å¤–çš„ 1%
    strategies.sort(key=lambda x: x['remainder'], reverse=True)

    # 5. åˆ†é…å‰©é¤˜çš„ç™¾åˆ†æ¯”
    for i in range(remainder_to_distribute):
        strategies[i]['floor_percentage'] += 1

    # 6. æ•´ç†ä¸¦è¿”å›æœ€çµ‚çµæœ
    final_allocations = [
        {'ticker': s['ticker'], 'percentage': s['floor_percentage']}
        for s in strategies
    ]
    
    # æŒ‰ç™¾åˆ†æ¯”é™åºè¿”å›ï¼Œè®“å‰ç«¯é¡¯ç¤ºæ›´å¥½çœ‹
    final_allocations.sort(key=lambda x: x['percentage'], reverse=True)
    
    return final_allocations

@app.route('/api/capital-allocation', methods=['POST'])
@login_required
def api_capital_allocation():
    try:
        data = request.get_json()
        strategy_ids = data.get('strategy_ids')
        risk_profile = data.get('risk_profile')

        if not all([strategy_ids, risk_profile]):
            return jsonify({'success': False, 'message': 'ç„¡æ•ˆçš„è«‹æ±‚åƒæ•¸'}), 400

        placeholders = ', '.join(['%s'] * len(strategy_ids))
        sql = f"""
        SELECT id, ticker, total_return, sharpe_ratio, max_drawdown, win_rate,
               train_start_date, train_end_date
        FROM saved_strategies
        WHERE id IN ({placeholders}) AND user_id = %s
        """
        params = tuple(strategy_ids) + (current_user.id,)
        strategies_from_db = execute_db_query(sql, params, fetch_all=True)

        if not strategies_from_db:
            return jsonify({'success': False, 'message': 'æ‰¾ä¸åˆ°ç­–ç•¥'}), 404

        processed_strategies = [{
            'id': s['id'], 'ticker': s['ticker'],
            'annualized_return': calculate_annualized_return(s['total_return'], s['train_start_date'], s['train_end_date']),
            'sharpe_ratio': float(s.get('sharpe_ratio', 0.0)),
            'max_drawdown': float(s.get('max_drawdown', 0.0)),
            'win_rate': float(s.get('win_rate', 0.0))
        } for s in strategies_from_db]

        metrics_to_normalize = ['annualized_return', 'sharpe_ratio', 'max_drawdown', 'win_rate']
        for metric in metrics_to_normalize:
            values = [s[metric] for s in processed_strategies if s.get(metric) is not None]
            if not values: continue
            min_val, max_val = min(values), max(values)
            for s in processed_strategies:
                value = s.get(metric)
                norm_key = f'norm_{metric}'
                if value is None or max_val == min_val:
                    s[norm_key] = 50.0; continue
                if metric == 'max_drawdown':
                    s[norm_key] = 100 * (max_val - value) / (max_val - min_val)
                else:
                    s[norm_key] = 100 * (value - min_val) / (max_val - min_val)

        weights = WEIGHTS.get(risk_profile, WEIGHTS['å‡è¡¡å‹'])
        tickers_list = list(set([s['ticker'] for s in processed_strategies]))
        
        gemini_analysis = {"analysis": [], "overall_summary": "AIå¸‚å ´ç¸½çµç”Ÿæˆä¸­..."}
        if gemini_client and tickers_list:
            try:
                prompt_text = _build_new_gemini_prompt(tickers_list)
                config = genai_types.GenerateContentConfig(
                    temperature=0.3, 
                    tools=[genai_types.Tool(google_search=genai_types.GoogleSearch())]
                )
                response = gemini_client.models.generate_content(
                    model='models/gemini-2.5-flash', contents=prompt_text, config=config
                )
                if response and hasattr(response, 'text') and response.text:
                    cleaned_text = response.text.strip().replace('```json', '').replace('```', '').strip()
                    if cleaned_text:
                        gemini_analysis = json.loads(cleaned_text)
            except Exception as gemini_err:
                logger.error(f"Gemini API èª¿ç”¨å¤±æ•—: {gemini_err}")
        
        # --- (è¨ˆç®—åˆ†æ•¸çš„é‚è¼¯) ---
        for s in processed_strategies:
            s['quant_score'] = (s.get('norm_annualized_return', 50) * weights['annualized_return'] +
                              s.get('norm_sharpe_ratio', 50) * weights['sharpe_ratio'] +
                              s.get('norm_max_drawdown', 50) * weights['max_drawdown'] +
                              s.get('norm_win_rate', 50) * weights['win_rate'])
            s['stability_score'] = (s.get('norm_max_drawdown', 50) * 0.6) + (s.get('norm_win_rate', 50) * 0.4)
            
            ticker_analysis = next((item for item in gemini_analysis.get('analysis', []) if item['ticker'] == s['ticker']), None)
            sentiment = ticker_analysis['sentiment'] if ticker_analysis else 'Neutral'
            
            # â–¼â–¼â–¼â–¼â–¼ã€ä¿®æ”¹é» 1ã€‘å°‡ sentiment æ¨™ç±¤ç›´æ¥å­˜å…¥ç­–ç•¥å­—å…¸ä¸­ â–¼â–¼â–¼â–¼â–¼
            s['ai_sentiment'] = sentiment
            # â–²â–²â–²â–²â–² ä¿®æ”¹çµæŸ â–²â–²â–²â–²â–²

            ai_factor = AI_ADJUSTMENT_FACTORS.get(sentiment, 1.0)
            s['final_adjusted_score'] = s['quant_score'] * ai_factor
            s['ai_summary'] = ticker_analysis['summary'] if ticker_analysis else "ç„¡å³æ™‚å¸‚å ´åˆ†æã€‚"

        final_allocations = _allocate_percentages_largest_remainder(processed_strategies)
        
        portfolio_roles = assign_portfolio_roles(processed_strategies)
        
        reasoning = {
            "overall_summary": gemini_analysis.get("overall_summary", "AIå¸‚å ´ç¸½çµç”Ÿæˆå¤±æ•—ã€‚"),
            "per_stock_analysis": [{
                "ticker": s['ticker'],
                "role_in_portfolio": portfolio_roles.get(s['ticker']),
                "justification": s['ai_summary'],
                # â–¼â–¼â–¼â–¼â–¼ã€ä¿®æ”¹é» 2ã€‘å°‡ sentiment æ¨™ç±¤åŠ å…¥åˆ°å›å‚³çµ¦å‰ç«¯çš„ reasoning ç‰©ä»¶ä¸­ â–¼â–¼â–¼â–¼â–¼
                "ai_sentiment": s['ai_sentiment']
                # â–²â–²â–²â–²â–² ä¿®æ”¹çµæŸ â–²â–²â–²â–²â–²
            } for s in processed_strategies]
        }

        final_data = {"allocations": final_allocations, "reasoning": reasoning}
        return jsonify({"success": True, "data": final_data})

    except Exception as e:
        logger.error(f"è³‡é‡‘é…ç½® API ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤: {str(e)}'}), 500
    

@app.route('/api/lookup-strategy', methods=['GET'])
@login_required
def api_lookup_strategy():
    """
    æŸ¥è©¢è³‡æ–™åº«ä¸­å·²å­˜åœ¨çš„ã€é‡å°ç‰¹å®šè‚¡ç¥¨çš„æœ€ä½³ç­–ç•¥ (ç³»çµ±Aå’Œç³»çµ±Bçš„Rank 1)ã€‚
    """
    try:
        ticker_query = request.args.get('ticker', '').strip().upper()
        if not ticker_query:
            return jsonify({'success': False, 'message': 'è«‹æä¾›è‚¡ç¥¨ä»£è™Ÿ'}), 400

        # --- æ­¥é©Ÿ 1: ä½¿ç”¨ EnhancedStockAnalyzer é©—è­‰ä¸¦ç²å–æ¨™æº–åŒ–çš„è‚¡ç¥¨ä»£è™Ÿ ---
        # é€™æ¨£å¯ä»¥è‡ªå‹•è™•ç†ä¾‹å¦‚ "2330" -> "2330.TW" çš„æƒ…æ³
        analyzer = EnhancedStockAnalyzer(ticker_query)
        stock_data = analyzer.get_basic_stock_data()
        
        if not stock_data.get("success"):
            return jsonify({'success': False, 'message': f"ç„¡æ•ˆçš„è‚¡ç¥¨ä»£è™Ÿ: {stock_data.get('error', 'æœªçŸ¥éŒ¯èª¤')}"}), 404

        validated_ticker = stock_data['ticker']
        logger.info(f"ç­–ç•¥æŸ¥è©¢: ä½¿ç”¨è€…æŸ¥è©¢ '{ticker_query}', æ¨™æº–åŒ–ç‚º '{validated_ticker}'")

        # --- æ­¥é©Ÿ 2: æŸ¥è©¢è³‡æ–™åº« ---
        sql_query = """
            SELECT 
                user_id, stock_ticker, strategy_rank, 
                ai_strategy_gene AS gene, 
                strategy_details, 
                game_start_date AS train_start_date, 
                game_end_date AS train_end_date,
                period_return_pct,
                win_rate_pct,
                average_trade_return_pct,
                max_drawdown_pct,
                sharpe_ratio,              
                total_trades,
                max_trade_drop_pct,
                max_trade_gain_pct
            FROM ai_vs_user_games 
            WHERE 
                stock_ticker = %s AND 
                strategy_rank = 1 AND 
                user_id IN (2, 3)
            ORDER BY 
                user_id;
        """
        
        found_strategies = execute_db_query(sql_query, (validated_ticker,), fetch_all=True)

        if not found_strategies:
            return jsonify({'success': True, 'found': False, 'message': f'è³‡æ–™åº«ä¸­å°šç„¡ {validated_ticker} çš„æœ€ä½³ç­–ç•¥ï¼Œè«‹è‡³è¨“ç·´å™¨è‡ªè¡Œè¨“ç·´ã€‚'})

        # --- æ­¥é©Ÿ 3: æ ¼å¼åŒ–è¿”å›çš„æ•¸æ“šï¼Œä½¿å…¶èˆ‡å‰ç«¯çš„æ•¸æ“šçµæ§‹ä¸€è‡´ ---
        results = []
        for strategy in found_strategies:
            # å°‡Decimalé¡å‹è½‰æ›ç‚ºfloatï¼Œä»¥ç¢ºä¿JSONåºåˆ—åŒ–æ­£å¸¸
            for key, value in strategy.items():
                if isinstance(value, (datetime, date)):
                    strategy[key] = value.isoformat().split('T')[0]
                elif hasattr(value, 'to_eng_string'): # è™•ç†Decimal
                    strategy[key] = float(value.to_eng_string())
            
            # å°‡åŸºå› å­—ä¸²è§£æç‚ºJSONé™£åˆ—
            try:
                strategy['gene'] = json.loads(strategy.get('gene', '[]'))
            except (json.JSONDecodeError, TypeError):
                strategy['gene'] = []

            # å‰µå»ºèˆ‡å‰ç«¯ 'metrics' å°æ‡‰çš„åµŒå¥—å°è±¡
            metrics = {
                'total_return': strategy.get('period_return_pct', 0) / 100.0,
                'win_rate_pct': strategy.get('win_rate_pct', 0),
                'average_trade_return': strategy.get('average_trade_return_pct', 0) / 100.0,
                'max_drawdown': strategy.get('max_drawdown_pct', 0) / 100.0,
                'sharpe_ratio': strategy.get('sharpe_ratio', 0.0),  
                'trade_count': strategy.get('total_trades', 0),
                'max_trade_drop_pct': strategy.get('max_trade_drop_pct', 0),
                'max_trade_gain_pct': strategy.get('max_trade_gain_pct', 0)
            }
            
            # æ§‹å»ºèˆ‡å‰ç«¯è¨“ç·´çµæœå¡ç‰‡ä¸€è‡´çš„æ•¸æ“šçµæ§‹
            formatted_strategy = {
                'strategy_type_name': 'ç­–ç•¥ 1' if strategy['user_id'] == 2 else 'ç­–ç•¥ 2',
                'ticker': strategy['stock_ticker'],
                'train_start_date': strategy['train_start_date'],
                'train_end_date': strategy['train_end_date'],
                'gene': strategy['gene'],
                'strategy_details': strategy.get('strategy_details', ''), 
                'metrics': metrics
            }
            results.append(formatted_strategy)

        logger.info(f"æˆåŠŸç‚º {validated_ticker} æ‰¾åˆ° {len(results)} å€‹æœ€ä½³ç­–ç•¥ã€‚")
        return jsonify({'success': True, 'found': True, 'strategies': results})

    except Exception as e:
        logger.error(f"æŸ¥è©¢ç­–ç•¥APIæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({'success': False, 'message': f'ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤: {str(e)}'}), 500


    
# === ä¾†è‡ª program.py çš„åŸå§‹ API ç«¯é» ===
# é€™æ˜¯ main_app.py ä¸­çš„ä¸€å€‹å‡½å¼ï¼Œè«‹å®Œæ•´æ›¿æ›
@app.route('/api/enhanced-analyze', methods=['POST'])
def enhanced_analyze_stock():
    """å¢å¼·ç‰ˆè‚¡ç¥¨åˆ†æAPI - åŒ…å«å®Œæ•´æŒ‡æ¨™ã€å›æ¸¬æ™‚é–“ï¼Œä¸¦åŒæ™‚ç”Ÿæˆéœæ…‹åœ–ç‰‡èˆ‡äº’å‹•HTMLåœ–è¡¨"""
    try:
        data = request.get_json()
        ticker = data.get('ticker', '').strip()
        if not ticker: 
            return jsonify({"success": False, "message": "è«‹æä¾›è‚¡ç¥¨ä»£è™Ÿ"})
        
        logger.info(f"é–‹å§‹å¢å¼·åˆ†æï¼š{ticker}")
        analyzer = EnhancedStockAnalyzer(ticker)
        
        stock_data = analyzer.get_basic_stock_data()
        if not stock_data["success"]: 
            return jsonify({"success": False, "message": f"ç„¡æ³•ç²å–è‚¡ç¥¨è³‡æ–™ï¼š{stock_data.get('error', 'æœªçŸ¥éŒ¯èª¤')}"})
        
         # ==================== åœ¨é€™è£¡åŠ å…¥æ–°çš„ç¨‹å¼ç¢¼ ====================
        # æˆåŠŸç²å–è‚¡ç¥¨è³‡æ–™å¾Œï¼Œå‘¼å«å‡½å¼è¨˜éŒ„æ–°çš„ä»£è™Ÿ
        log_new_ticker_to_csv(stock_data['ticker'], stock_data['market'])
        # ============================================================
        tech_indicators = analyzer.get_technical_indicators(stock_data['historical_data'])
        strategies_data = analyzer.get_ai_strategies_data()
        
        # <<<<<<< é€™æ˜¯ä¿®æ”¹å¾Œçš„åœ–è¡¨ç”Ÿæˆå‘¼å« >>>>>>>
        chart_image_url, chart_interactive_url = create_enhanced_stock_chart(
            stock_data['ticker'], stock_data['company_name'], 
            stock_data['historical_data']
        )
        # <<<<<<< ä¿®æ”¹çµæŸ >>>>>>>
        
        logger.info("æ­£åœ¨ç²å–æœ€æ–°çš„VIXæŒ‡æ•¸å’Œå¸‚å ´æƒ…ç·’åˆ†æ•¸...")
        latest_vix = get_latest_vix()
        latest_sentiment = get_latest_sentiment_from_csv()
        
        ai_analysis = generate_enhanced_news_analysis(
            stock_data, tech_indicators, strategies_data, latest_vix, latest_sentiment
        )
        
        if stock_data.get('market_cap'):
            stock_data['market_cap_formatted'] = format_market_cap(
                stock_data['market_cap'], stock_data['currency']
            )
        
        # æ ¼å¼åŒ–ç­–ç•¥æ•¸æ“š
        if strategies_data.get('system_a'):
            for s in strategies_data['system_a']:
                s['formatted_metrics'] = {
                    'average_trade_return_formatted': f"{s.get('average_trade_return_pct',0):.3f}%",
                    'max_drawdown_formatted': f"{s.get('max_drawdown_pct',0):.2f}%",
                    'max_drop_formatted': f"{s.get('max_trade_drop_pct',0):.2f}%",
                    'max_gain_formatted': f"{s.get('max_trade_gain_pct',0):.2f}%"
                }
        
        if strategies_data.get('system_b'):
            for s in strategies_data['system_b']:
                s['formatted_metrics'] = {
                    'average_trade_return_formatted': f"{s.get('average_trade_return_pct',0):.3f}%",
                    'max_drawdown_formatted': f"{s.get('max_drawdown_pct',0):.2f}%",
                    'max_drop_formatted': f"{s.get('max_trade_drop_pct',0):.2f}%",
                    'max_gain_formatted': f"{s.get('max_trade_gain_pct',0):.2f}%"
                }
        
        del stock_data['historical_data']
        
        logger.info(f"å¢å¼·åˆ†æå®Œæˆï¼š{ticker}")
        
        # <<<<<<< é€™æ˜¯ä¿®æ”¹å¾Œçš„APIå›å‚³å…§å®¹ >>>>>>>
        return jsonify({
            "success": True,
            "data": {
                **stock_data,
                "technical_indicators": tech_indicators,
                "ai_strategies": strategies_data,
                "gemini_analysis": ai_analysis,
                "chart_image_url": chart_image_url,           # éœæ…‹åœ–ç‰‡URL
                "chart_interactive_url": chart_interactive_url # äº’å‹•HTMLçš„URL
            }
        })
        # <<<<<<< ä¿®æ”¹çµæŸ >>>>>>>
        
    except Exception as e:
        logger.error(f"å¢å¼·è‚¡ç¥¨åˆ†æAPIéŒ¯èª¤ï¼š{e}")
        return jsonify({"success": False, "message": f"åˆ†æå¤±æ•—ï¼š{str(e)}"})

@app.route('/api/news/search', methods=['POST'])
def api_news_search():
    """ä½¿ç”¨ Gemini Tools æœå°‹æœ€æ–°æ–°è"""
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query: 
            return jsonify({"success": False, "message": "è«‹æä¾›æœå°‹é—œéµå­—"})
        
        if not gemini_client: 
            return jsonify({"success": False, "message": "Gemini AI æœå‹™ä¸å¯ç”¨"})
        
        news_prompt = f"""è«‹æœå°‹é—œæ–¼ "{query}" çš„æœ€æ–°æ–°èå’Œäº‹ä»¶ï¼Œä¸¦æä¾›ä»¥ä¸‹è³‡è¨Šï¼š

1. æœå°‹æœ€è¿‘7å¤©å…§çš„ç›¸é—œæ–°è
2. é‡é»é—œæ³¨è²¡ç¶“ã€ç§‘æŠ€ã€æ”¿ç­–ç­‰å½±éŸ¿æŠ•è³‡çš„æ–°è
3. æ•´ç†æˆçµæ§‹åŒ–å ±å‘Š

è«‹æŒ‰ä»¥ä¸‹æ ¼å¼å›æ‡‰ï¼š

##  æœ€æ–°æ–°èæ‘˜è¦
[åˆ—å‡º3-5å‰‡æœ€é‡è¦çš„æ–°èï¼Œæ¯å‰‡åŒ…å«æ¨™é¡Œã€æ™‚é–“ã€é‡é»å…§å®¹](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)(150-200å­—)

##  å¸‚å ´å½±éŸ¿åˆ†æ
[åˆ†æé€™äº›æ–°èå°ç›¸é—œè‚¡ç¥¨æˆ–å¸‚å ´çš„æ½›åœ¨å½±éŸ¿](æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)(100-150å­—)

##  æ©Ÿæœƒèˆ‡é¢¨éšª(æ¯å€‹å°æ®µè½éƒ½è¦æ›è¡Œï¼Œå°æ¨™é¡Œä¸è¦åŠ **)
[åŸºæ–¼æ–°èå…§å®¹æŒ‡å‡ºå¯èƒ½çš„æŠ•è³‡æ©Ÿæœƒå’Œé¢¨éšªé»](100-150å­—)

è«‹ç¢ºä¿è³‡è¨Šæº–ç¢ºä¸”å…·æœ‰æ™‚æ•ˆæ€§ã€‚"""

        config = genai_types.GenerateContentConfig(
            temperature=0.6,
            max_output_tokens=4000,
            tools=[genai_types.Tool(google_search=genai_types.GoogleSearch())],
            safety_settings=safety_settings_gemini
        )
        
        response = gemini_client.models.generate_content(
            model='models/gemini-2.5-flash',
            contents=news_prompt,
            config=config
        )
        
        if response and hasattr(response, 'text') and response.text:
            return jsonify({
                "success": True,
                "data": {
                    "query": query,
                    "news_analysis": response.text.strip(),
                    "search_time": datetime.now().isoformat()
                }
            })
        else:
            return jsonify({"success": False, "message": "ç„¡æ³•ç²å–æ–°èæœå°‹çµæœ"})
            
    except Exception as e:
        logger.error(f"æ–°èæœå°‹APIéŒ¯èª¤: {e}")
        return jsonify({"success": False, "message": f"æ–°èæœå°‹å¤±æ•—ï¼š{str(e)}"})

# æª”æ¡ˆ: main_app.py
# è«‹ç”¨æ­¤å‡½å¼å®Œæ•´æ›¿æ›åŸæœ‰çš„ api_strategy_signals å‡½å¼

@app.route('/api/strategy-signals', methods=['GET'])
def api_strategy_signals():
    """
    (V3.3 ç›®æ¨™ä¸€è‡´ç‰ˆ) AIç­–ç•¥ä¿¡è™Ÿ API - é¡¯ç¤ºåŸå§‹è¨“ç·´ç¸¾æ•ˆï¼Œä½†ä¿¡è™Ÿä¾†è‡ªè¿‘æœŸå›æ¸¬
    """
    try:
        market = request.args.get('market', 'TW')
        signal_type_filter = request.args.get('type', 'buy').upper()
        filter_by_win_rate = request.args.get('min_win_rate_50', 'false').lower() == 'true'
        
        # ç¯©é¸æ¢ä»¶ç¾åœ¨æœƒæ‡‰ç”¨æ–¼ 'a' è¡¨ (ai_vs_user_games) ä¸­çš„åŸå§‹å‹ç‡
        win_rate_filter_sql = "AND a.win_rate_pct >= 50" if filter_by_win_rate else ""
        
        query = f"""
        SELECT 
            -- 1. å¾è¿‘æœŸå›æ¸¬ä¸­ç²å–ä¿¡è™Ÿæœ¬èº«çš„è³‡è¨Š
            bs.stock_ticker, bs.market_type, bs.system_type, bs.strategy_rank,
            bs.signal_type, bs.signal_date, bs.buy_price, bs.sell_price,

            -- 2. å¾åŸå§‹è¨“ç·´æ•¸æ“šåº«ä¸­ç²å–ä¸€è‡´çš„ç¸¾æ•ˆæŒ‡æ¨™
            a.period_return_pct AS return_pct,
            a.win_rate_pct AS win_rate,
            a.ai_strategy_gene, a.strategy_details, a.game_start_date, a.game_end_date,
            a.total_trades, a.average_trade_return_pct, a.max_drawdown_pct,
            a.sharpe_ratio, a.max_trade_drop_pct, a.max_trade_gain_pct
        FROM 
            backtest_signals bs
        JOIN 
            ai_vs_user_games a ON bs.stock_ticker = a.stock_ticker COLLATE utf8mb4_unicode_ci
                               AND bs.strategy_rank = a.strategy_rank
                               AND bs.system_type = (CASE WHEN a.user_id = 2 THEN 'SystemA' ELSE 'SystemB' END) COLLATE utf8mb4_unicode_ci
        WHERE 
            bs.market_type = %s AND bs.signal_type = %s
            {win_rate_filter_sql}
        ORDER BY bs.signal_date DESC, a.win_rate_pct DESC;
        """
        
        signals = execute_db_query(query, (market, signal_type_filter), fetch_all=True)
        
        if signals:
            for signal in signals:
                # é€™éƒ¨åˆ†çš„æ ¼å¼åŒ–é‚è¼¯ä¸éœ€æ”¹è®Š
                if isinstance(signal.get('signal_date'), date):
                    signal['signal_date_only'] = signal['signal_date'].strftime('%Y-%m-%d')
                if isinstance(signal.get('game_start_date'), date):
                    signal['game_start_date'] = signal['game_start_date'].isoformat()
                if isinstance(signal.get('game_end_date'), date):
                    signal['game_end_date'] = signal['game_end_date'].isoformat()
                if signal.get('win_rate') is not None: 
                    signal['win_rate'] = round(signal['win_rate'], 2)
                if signal.get('return_pct') is not None: 
                    signal['return_pct'] = round(signal['return_pct'], 2)

        return jsonify({"success": True, "data": signals or []})
        
    except Exception as e:
        logger.error(f"AIç­–ç•¥ä¿¡è™ŸAPIéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({"success": False, "message": "å…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤ï¼Œç­–ç•¥ä¿¡è™ŸæŸ¥è©¢å¤±æ•—"})

# --- å…¨å±€è¨­å®šèˆ‡é–‹é—œ --

# ==============================================================================
#           >>> ä»¥ä¸‹ç‚ºæ–°åŠ å…¥çš„æ’ç¨‹å›æ¸¬åŠŸèƒ½ (ç¨ç«‹å€å¡Š) <<<
# ==============================================================================

class StrategyBacktesterWithSignals:
    """ç­–ç•¥å›æ¸¬å™¨ - (å¾ backtest.py é·ç§»ä¸¦æ•´åˆï¼Œä½¿ç”¨ logger)"""
    
    def __init__(self):
        self.backtest_months = 12
        self.signal_check_days = 7
        self.start_date, self.end_date = self._get_date_range()
        self.charts_dir = "charts"
        self.data_cache_a = {}
        self.data_cache_b = {}
        os.makedirs(self.charts_dir, exist_ok=True)
        logger.info(f"ğŸ¯ [æ’ç¨‹å›æ¸¬] å›æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“… [æ’ç¨‹å›æ¸¬] å›æ¸¬æœŸé–“: {self.start_date} ~ {self.end_date}")
        logger.info(f"ğŸ“ [æ’ç¨‹å›æ¸¬] åœ–è¡¨ç›®éŒ„: {self.charts_dir}")


    def _get_date_range(self):
        end_date_obj = datetime.now(pytz.timezone('Asia/Taipei')).date()
        start_date_obj = end_date_obj - timedelta(days=self.backtest_months * 30)
        inclusive_end_date_for_yf = end_date_obj + timedelta(days=1)
        
        return start_date_obj.strftime("%Y-%m-%d"), inclusive_end_date_for_yf.strftime("%Y-%m-%d")

    
    # æª”æ¡ˆ: main_app.py
# åœ¨ StrategyBacktesterWithSignals é¡åˆ¥ä¸­...

    def create_signals_table(self):
        """æª¢æŸ¥ä¸¦å‰µå»º backtest_signals è³‡æ–™åº«è¡¨ - (ä¿®æ­£ç‰ˆï¼šæ–°å¢ signal_date æ¬„ä½)"""
        query = """
        CREATE TABLE IF NOT EXISTS `backtest_signals` (
          `id` INT AUTO_INCREMENT PRIMARY KEY, `stock_ticker` VARCHAR(20) NOT NULL,
          `stock_name` VARCHAR(100), `market_type` VARCHAR(10) NOT NULL,
          `system_type` VARCHAR(20) NOT NULL, `strategy_rank` INT NOT NULL,
          `signal_type` ENUM('BUY', 'SELL', 'BUY_SELL') NOT NULL, `signal_reason` TEXT,
          `signal_date` DATE NULL,
          `buy_price` FLOAT NULL, `sell_price` FLOAT NULL, `return_pct` FLOAT,
          `win_rate` FLOAT NULL, `chart_path` VARCHAR(255), `processed_at` DATETIME NOT NULL,
          INDEX `idx_market_signal` (`market_type`, `signal_type`)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;"""
        try:
            execute_db_query(query)
            logger.info("âœ… [æ’ç¨‹å›æ¸¬] `backtest_signals` è¡¨å·²ç¢ºèªå­˜åœ¨ (å« signal_date æ¬„ä½)")
        except Exception as e:
            logger.error(f"âŒ [æ’ç¨‹å›æ¸¬] å‰µå»º `backtest_signals` è¡¨å¤±æ•—: {e}")

    def save_results_to_db(self, results):
        """å°‡æœ‰ä¿¡è™Ÿçš„çµæœå„²å­˜åˆ°è³‡æ–™åº« - (ä¿®æ­£ç‰ˆï¼šå¯«å…¥ signal_date æ¬„ä½)"""
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cursor:
                cursor.execute("TRUNCATE TABLE backtest_signals")
                logger.info("ğŸ—‘ï¸ [æ’ç¨‹å›æ¸¬] å·²æ¸…ç©ºèˆŠçš„ä¿¡è™Ÿè³‡æ–™")
                query = """INSERT INTO backtest_signals (stock_ticker, stock_name, market_type, system_type, strategy_rank, 
                    signal_type, signal_reason, signal_date, buy_price, sell_price, return_pct, win_rate, chart_path, processed_at) 
                    VALUES (%(ticker)s, NULL, %(market_type)s, %(system)s, %(rank)s, %(signal_type)s, %(signal_reason)s, 
                    %(signal_date)s, %(buy_price)s, %(sell_price)s, %(return_pct)s, %(win_rate)s, %(chart_path)s, %(processed_at)s)"""
                
                to_save = [res for res in results if res.get('signal_type')]
                
                if to_save:
                    cursor.executemany(query, to_save)
                    conn.commit()
                    logger.info(f"ğŸ’¾ [æ’ç¨‹å›æ¸¬] æˆåŠŸå°‡ {len(to_save)} ç­†æ–°ä¿¡è™Ÿå„²å­˜åˆ°è³‡æ–™åº«")
                else:
                    logger.info("â„¹ï¸ [æ’ç¨‹å›æ¸¬] æœ¬æ¬¡é‹è¡Œæ²’æœ‰ç™¼ç¾ä»»ä½•æ–°ä¿¡è™Ÿå¯å„²å­˜")
        except Exception as e:
            if conn: conn.rollback()
            logger.error(f"âŒ [æ’ç¨‹å›æ¸¬] å„²å­˜ä¿¡è™Ÿåˆ°è³‡æ–™åº«å¤±æ•—: {e}\n{traceback.format_exc()}")
        finally:
            if conn: conn.close()

    def get_all_strategies(self):
        """å¾è³‡æ–™åº«ç²å–æ‰€æœ‰å¾…å›æ¸¬çš„ç­–ç•¥"""
        query = """SELECT user_id, market_type, stock_ticker, ai_strategy_gene, strategy_details, strategy_rank
                   FROM ai_vs_user_games WHERE strategy_rank = 1 AND ai_strategy_gene IS NOT NULL 
                   AND (user_id = 2 OR user_id = 3) ORDER BY stock_ticker, user_id, strategy_rank"""
        strategies = execute_db_query(query, fetch_all=True)
        if strategies:
            logger.info(f"ğŸ“Š [æ’ç¨‹å›æ¸¬] å¾è³‡æ–™åº«ç²å–åˆ° {len(strategies)} å€‹ç­–ç•¥")
            return strategies
        logger.warning("âŒ [æ’ç¨‹å›æ¸¬] è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç­–ç•¥")
        return []
    
    def parse_strategy_gene(self, gene_json_str):
        try:
            return json.loads(gene_json_str) if isinstance(gene_json_str, str) else None
        except (json.JSONDecodeError, TypeError):
            return None
    
    def backtest_system_a_with_signals(self, gene, ticker):
        try:
            if ticker in self.data_cache_a:
                prices, dates, stock_df, vix_series, sentiment_series = self.data_cache_a[ticker]
            else:
                prices, dates, stock_df, vix_series, sentiment_series = ga_load_data(ticker, start_date=self.start_date, end_date=self.end_date, verbose=False)
                if prices is not None and len(prices) > 0: self.data_cache_a[ticker] = (prices, dates, stock_df, vix_series, sentiment_series)
            if not prices or len(prices) < 30: return None, None, None, None, None
            precalculated, ready = ga_precompute_indicators(stock_df, vix_series, STRATEGY_CONFIG_SHARED_GA, sentiment_series=sentiment_series, verbose=False)
            if not ready: return None, None, None, None, None
            def get_ind(name, g_indices, opt_keys):
                params = [GA_PARAMS_CONFIG[k][gene[g_idx]] for g_idx, k in zip(g_indices, opt_keys)]
                key = tuple(params) if len(params) > 1 else params[0]
                return np.array(precalculated.get(name, {}).get(key, [np.nan]*len(prices)), dtype=np.float64)
            result = run_strategy_numba_core(np.array(gene, dtype=np.float64), np.array(prices, dtype=np.float64),
                get_ind('vix_ma', [GENE_MAP['vix_ma_p']], ['vix_ma_period_options']), get_ind('sentiment_ma', [GENE_MAP['sentiment_ma_p']], ['sentiment_ma_period_options']),
                get_ind('rsi', [GENE_MAP['rsi_p']], ['rsi_period_options']), get_ind('adx', [GENE_MAP['adx_p']], ['adx_period_options']),
                get_ind('bbl', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']), get_ind('bbm', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']),
                get_ind('bbu', [GENE_MAP['bb_l_p'], GENE_MAP['bb_s_p']], ['bb_length_options', 'bb_std_options']), get_ind('ma', [GENE_MAP['ma_s_p']], ['ma_period_options']),
                get_ind('ma', [GENE_MAP['ma_l_p']], ['ma_period_options']), get_ind('ema_s', [GENE_MAP['ema_s_p']], ['ema_s_period_options']),
                get_ind('ema_m', [GENE_MAP['ema_m_p']], ['ema_m_period_options']), get_ind('ema_l', [GENE_MAP['ema_l_p']], ['ema_l_period_options']),
                get_ind('atr', [GENE_MAP['atr_p']], ['atr_period_options']), get_ind('atr_ma', [GENE_MAP['atr_p']], ['atr_period_options']),
                get_ind('kd_k', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']], ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                get_ind('kd_d', [GENE_MAP['kd_k_p'], GENE_MAP['kd_d_p'], GENE_MAP['kd_s_p']], ['kd_k_period_options', 'kd_d_period_options', 'kd_smooth_period_options']),
                get_ind('macd_line', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']], ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                get_ind('macd_signal', [GENE_MAP['macd_f_p'], GENE_MAP['macd_s_p'], GENE_MAP['macd_sig_p']], ['macd_fast_period_options', 'macd_slow_period_options', 'macd_signal_period_options']),
                GA_PARAMS_CONFIG.get('commission_rate', 0.003), 61)
            if result is None or len(result) < 6: return None, None, None, None, None
            portfolio_values, buy_indices, buy_prices, sell_indices, sell_prices, _ = result
            buy_signals = [{'date': dates[i], 'price': buy_prices[idx], 'index': i} for idx, i in enumerate(buy_indices) if i < len(dates) and idx < len(buy_prices)]
            sell_signals = [{'date': dates[i], 'price': sell_prices[idx], 'index': i} for idx, i in enumerate(sell_indices) if i < len(dates) and idx < len(sell_prices)]
            return portfolio_values, dates, prices, buy_signals, sell_signals
        except Exception: return None, None, None, None, None

    def backtest_system_b_with_signals(self, gene, ticker):
        try:
            if ticker in self.data_cache_b: prices, dates, stock_df, vix_series = self.data_cache_b[ticker]
            else:
                prices, dates, stock_df, vix_series = load_stock_data_b(ticker, start_date=self.start_date, end_date=self.end_date, verbose=False)
                if prices is not None and len(prices) > 0: self.data_cache_b[ticker] = (prices, dates, stock_df, vix_series)
            if not prices or len(prices) < 30: return None, None, None, None, None
            precalculated, ready = precompute_indicators_b(stock_df, vix_series, STRATEGY_CONFIG_B, verbose=False)
            if not ready: return None, None, None, None, None
            rsi_buy_entry, rsi_exit, vix_threshold = gene[0], gene[1], gene[2]
            low_vol_exit, rsi_period_choice, vix_ma_choice = int(gene[3]), int(gene[4]), int(gene[5])
            bb_len_choice, bb_std_choice, adx_thresh, high_vol_entry_choice = int(gene[6]), int(gene[7]), gene[8], int(gene[9])
            rsi_p, vix_ma_p = STRATEGY_CONFIG_B['rsi_period_options'][rsi_period_choice], STRATEGY_CONFIG_B['vix_ma_period_options'][vix_ma_choice]
            bb_l, bb_s = STRATEGY_CONFIG_B['bb_length_options'][bb_len_choice], STRATEGY_CONFIG_B['bb_std_options'][bb_std_choice]
            rsi_arr, vix_ma_arr = np.array(precalculated['rsi'][rsi_p], dtype=np.float64), np.array(precalculated['vix_ma'][vix_ma_p], dtype=np.float64)
            bbl_arr, bbm_arr = np.array(precalculated['bbl'][(bb_l, bb_s)], dtype=np.float64), np.array(precalculated['bbm'][(bb_l, bb_s)], dtype=np.float64)
            adx_arr, ma_s_arr, ma_l_arr = np.array(precalculated['fixed']['adx_list'], dtype=np.float64), np.array(precalculated['fixed']['ma_short_list'], dtype=np.float64), np.array(precalculated['fixed']['ma_long_list'], dtype=np.float64)
            def get_valid_iloc(arr):
                valid_indices = np.where(np.isfinite(arr))[0]
                return valid_indices[0] if len(valid_indices) > 0 else len(prices)
            start_iloc = max(get_valid_iloc(arr) for arr in [rsi_arr, vix_ma_arr, bbl_arr, bbm_arr, adx_arr, ma_s_arr, ma_l_arr]) + 1
            if start_iloc >= len(prices): return None, None, None, None, None
            result = run_strategy_numba_core_b(float(rsi_buy_entry), float(rsi_exit), float(adx_thresh), float(vix_threshold), low_vol_exit, high_vol_entry_choice,
                float(STRATEGY_CONFIG_B['commission_pct']), np.array(prices, dtype=np.float64), rsi_arr, bbl_arr, bbm_arr, adx_arr, vix_ma_arr, ma_s_arr, ma_l_arr, start_iloc)
            if result is None or len(result) < 7: return None, None, None, None, None
            portfolio_values, buy_indices, _, _, sell_indices, _, _ = result
            buy_signals = [{'date': dates[i], 'price': prices[i], 'index': i} for i in buy_indices if i < len(dates)]
            sell_signals = [{'date': dates[i], 'price': prices[i], 'index': i} for i in sell_indices if i < len(dates)]
            return portfolio_values, dates, prices, buy_signals, sell_signals
        except Exception: return None, None, None, None, None
    
    def check_recent_signals(self, signals, signal_type_text):
        if not signals: return False, f"ç„¡{signal_type_text}ä¿¡è™Ÿ", None, None
        recent_signals_info = []
        today = datetime.now().date()
        latest_signal_date = None
        
        for signal in signals: # æª¢æŸ¥æ‰€æœ‰ä¿¡è™Ÿä»¥æ‰¾åˆ°æœ€è¿‘çš„
            s_date = pd.to_datetime(signal['date']).date()
            if 0 <= (today - s_date).days < self.signal_check_days:
                if latest_signal_date is None or s_date > latest_signal_date:
                    latest_signal_date = s_date
                recent_signals_info.append(signal)

        if not recent_signals_info:
            return False, f"è¿‘æœŸç„¡{signal_type_text}ä¿¡è™Ÿ", None, None

        latest_signal = max(recent_signals_info, key=lambda x: pd.to_datetime(x['date']))
        latest_price = latest_signal['price']
        reason = f"åœ¨ ({latest_signal_date.strftime('%Y-%m-%d')}) æª¢æ¸¬åˆ°{signal_type_text}ä¿¡è™Ÿ"
        
        return True, reason, latest_price, latest_signal_date

    def create_strategy_backtest_chart(self, ticker, system_type, rank, portfolio, prices, dates, buys, sells, details, final_return):
        try:
            fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, row_heights=[0.7, 0.3],
                                subplot_titles=[f'{ticker} {system_type} Rank{rank} - è‚¡åƒ¹èˆ‡è²·è³£é»', 'æŠ•è³‡çµ„åˆåƒ¹å€¼æ›²ç·š'])
            if prices is not None and len(prices) > 0 and dates is not None: fig.add_trace(go.Scatter(x=dates, y=prices, mode='lines', name='è‚¡åƒ¹', line=dict(color='white', width=1)), row=1, col=1)
            if buys: fig.add_trace(go.Scatter(x=[s['date'] for s in buys], y=[s['price'] for s in buys], mode='markers', name='è²·å…¥é»', marker=dict(symbol='triangle-up', size=12, color='lime')), row=1, col=1)
            if sells: fig.add_trace(go.Scatter(x=[s['date'] for s in sells], y=[s['price'] for s in sells], mode='markers', name='è³£å‡ºé»', marker=dict(symbol='triangle-down', size=12, color='red')), row=1, col=1)
            if portfolio is not None and portfolio.size > 0 and dates is not None:
                ret_pct = (portfolio - 1.0) * 100
                line_color = 'lime' if final_return >= 0 else 'red'
                fig.add_trace(go.Scatter(x=dates, y=ret_pct, mode='lines', name=f'å ±é…¬ç‡ ({final_return:.2f}%)', line=dict(color=line_color, width=2), fill='tozeroy' if final_return >= 0 else None), row=2, col=1)
            fig.update_layout(title=f"{ticker} {system_type} Rank{rank} (å ±é…¬ç‡: {final_return:.2f}%)", template='plotly_dark', height=800)
            filename = f"{ticker.replace('.', '_')}_{system_type}_Rank{rank}_backtest.html"
            path = os.path.join(self.charts_dir, filename)
            fig.write_html(path)
            return path
        except Exception as e:
            logger.error(f"    âŒ [æ’ç¨‹å›æ¸¬] ç‚º {ticker} å‰µå»ºåœ–è¡¨å¤±æ•—: {e}")
            return None

    def _calculate_win_rate(self, buy_signals, sell_signals):
        if not buy_signals or not sell_signals: return 0.0
        buys, sells = sorted(buy_signals, key=lambda x: x['index']), sorted(sell_signals, key=lambda x: x['index'])
        total, wins = 0, 0
        num_trades = min(len(buys), len(sells))
        for i in range(num_trades):
            if sells[i]['index'] > buys[i]['index']:
                total += 1
                if sells[i]['price'] > buys[i]['price']: wins += 1
        return (wins / total) * 100 if total > 0 else 0.0

    def process_single_strategy(self, strategy):
        """è™•ç†å–®ä¸€ç­–ç•¥ - (ä¿®æ­£ç‰ˆï¼šæ•æ‰ä¸¦å„²å­˜çœŸå¯¦ä¿¡è™Ÿæ—¥æœŸ)"""
        try:
            ticker, sys_type, rank = strategy['stock_ticker'], "SystemA" if strategy['user_id'] == 2 else "SystemB", strategy['strategy_rank']
            logger.info(f"\n[{self.current_strategy_index}/{self.total_strategies}] ğŸ“Š [æ’ç¨‹å›æ¸¬] æ­£åœ¨å›æ¸¬ {ticker} {sys_type} rank{rank}...")
            gene = self.parse_strategy_gene(strategy['ai_strategy_gene'])
            if not gene:
                logger.warning(f"    âš ï¸ ç„¡æ³•è§£æ {ticker} çš„ç­–ç•¥åŸºå› ï¼Œå·²è·³éã€‚")
                return None
            
            portfolio, dates, prices, buys, sells = (None,)*5
            if sys_type == "SystemA": portfolio, dates, prices, buys, sells = self.backtest_system_a_with_signals(gene, ticker)
            else: portfolio, dates, prices, buys, sells = self.backtest_system_b_with_signals(gene, ticker)
            
            if portfolio is None or buys is None or sells is None:
                logger.warning(f"    âš ï¸ {ticker} å›æ¸¬æ•¸æ“šä¸è¶³æˆ–å¤±æ•—ï¼Œå·²è·³éã€‚")
                return None
            
            final_return = (portfolio[-1] - 1.0) * 100 if portfolio.size > 0 else 0.0
            win_rate = self._calculate_win_rate(buys, sells)
            
            has_buy, buy_reason, buy_price, last_buy_date = self.check_recent_signals(buys, 'è²·å…¥')
            has_sell, sell_reason, sell_price, last_sell_date = self.check_recent_signals(sells, 'è³£å‡º')

            has_recent_signal = has_buy or has_sell
            final_signal_type = None
            signal_reason = "ç„¡"
            actual_signal_date = None

            if has_recent_signal:
                if has_buy and (not has_sell or last_buy_date >= last_sell_date):
                    final_signal_type = 'BUY'
                    signal_reason = buy_reason
                    actual_signal_date = last_buy_date
                elif has_sell:
                    final_signal_type = 'SELL'
                    signal_reason = sell_reason
                    actual_signal_date = last_sell_date
            
            result = {
                'ticker': ticker, 'system': sys_type, 'rank': rank, 
                'market_type': strategy['market_type'], 'return_pct': final_return, 
                'win_rate': win_rate, 'signal_type': final_signal_type, 
                'signal_reason': signal_reason,
                'signal_date': actual_signal_date,
                'buy_price': buy_price, 
                'sell_price': sell_price, 'processed_at': datetime.now()
            }
            
            if final_signal_type:
                chart_path = self.create_strategy_backtest_chart(ticker, sys_type, rank, portfolio, prices, dates, buys, sells, strategy.get('strategy_details', ''), final_return)
                if chart_path: result['chart_path'] = os.path.basename(chart_path)
            
            return result
        except Exception as e:
            logger.error(f"    âŒ [æ’ç¨‹å›æ¸¬] è™•ç†ç­–ç•¥ {strategy.get('stock_ticker')} å¤±æ•—: {e}\n{traceback.format_exc()}")
            return None

    def run_full_backtest_with_signals(self):
        logger.info("ğŸš€ [æ’ç¨‹å›æ¸¬] é–‹å§‹åŸ·è¡Œç­–ç•¥æ‰¹é‡å›æ¸¬...")
        start_time = time.time()
        strategies = self.get_all_strategies()
        if not strategies: return []
        
        self.total_strategies = len(strategies)
        logger.info(f"ğŸ“‹ [æ’ç¨‹å›æ¸¬] æ‰¾åˆ° {self.total_strategies} å€‹ç­–ç•¥å¾…å›æ¸¬")
        
        results = []
        for i, strategy in enumerate(strategies, 1):
            self.current_strategy_index = i
            result = self.process_single_strategy(strategy)
            if result: results.append(result)
        
        elapsed = time.time() - start_time
        logger.info("\n" + "=" * 70 + "\nğŸ“Š [æ’ç¨‹å›æ¸¬] å›æ¸¬ç¸½çµ\n" + "=" * 70)
        
        # =================== ã€æ ¸å¿ƒä¿®æ­£é»ã€‘ ===================
        # ä½¿ç”¨ res.get('signal_type') ä¾†åˆ¤æ–·æ˜¯å¦æœ‰ä¿¡è™Ÿï¼Œé€™æ¯” res['has_recent_signal'] æ›´å®‰å…¨ä¸”ç¬¦åˆæ–°é‚è¼¯
        signals_found = [res for res in results if res.get('signal_type')]
        # =======================================================

        logger.info(f"â±ï¸ [æ’ç¨‹å›æ¸¬] ç¸½è€—æ™‚: {elapsed:.2f} ç§’")
        logger.info(f"ğŸ¯ [æ’ç¨‹å›æ¸¬] ç™¼ç¾ä¿¡è™Ÿ: {len(signals_found)}")
        
        if signals_found:
            logger.info("\nğŸ¯ [æ’ç¨‹å›æ¸¬] ã€è¿‘æœŸæœ‰è²·è³£ä¿¡è™Ÿçš„ç­–ç•¥ã€‘")
            for res in signals_found:
                # =================== ã€æ ¸å¿ƒä¿®æ­£é»ã€‘ ===================
                # é‡å¯«æ—¥èªŒè¨˜éŒ„é‚è¼¯ï¼Œä»¥é©æ‡‰æ–°çš„ 'signal_type' æ¬„ä½
                is_buy = res['signal_type'] == 'BUY'
                signal_icon = "ğŸŸ¢" if is_buy else "ğŸ”´"
                signal_text = "è²·å…¥" if is_buy else "è³£å‡º"
                price_key = 'buy_price' if is_buy else 'sell_price'
                price = res.get(price_key)
                price_info = f"@ {price:.2f}" if price is not None else ""
                
                logger.info(f"  - {res['ticker']} | {res['system']} R{res['rank']} | å‹ç‡: {res['win_rate']:.2f}% | {signal_icon} {signal_text} {price_info}")
                # =======================================================
        
        return results

def run_scheduled_backtest():
    """æ¯æ—¥è‡ªå‹•åŸ·è¡Œçš„ä¸»ä»»å‹™ (åœ¨ App Context ä¸­é‹è¡Œ)"""
    with app.app_context():
        logger.info("="*50 + f"\nâ° [æ’ç¨‹ä»»å‹™] å•Ÿå‹•æ¯æ—¥è‡ªå‹•å›æ¸¬... (å°ç£æ™‚é–“: {datetime.now(pytz.timezone('Asia/Taipei'))})\n" + "="*50)
        try:
            if not os.getenv("DB_PASSWORD"):
                logger.error("âŒ [æ’ç¨‹ä»»å‹™] éŒ¯èª¤: DB_PASSWORD ç’°å¢ƒè®Šæ•¸æœªè¨­å®šã€‚ä»»å‹™ä¸­æ­¢ã€‚")
                return
            if not ENGINES_IMPORTED:
                logger.error("âŒ [æ’ç¨‹ä»»å‹™] å›æ¸¬å¼•æ“æ¨¡çµ„æœªæˆåŠŸå°å…¥ã€‚ä»»å‹™ä¸­æ­¢ã€‚")
                return
            
            backtester = StrategyBacktesterWithSignals()
            backtester.create_signals_table()
            results = backtester.run_full_backtest_with_signals()
            if results:
                backtester.save_results_to_db(results)
            
            logger.info("âœ… [æ’ç¨‹ä»»å‹™] æ¯æ—¥è‡ªå‹•å›æ¸¬ä»»å‹™åŸ·è¡Œå®Œç•¢ã€‚")
        except Exception as e:
            logger.error(f"\nâŒ [æ’ç¨‹ä»»å‹™] åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}\n{traceback.format_exc()}")
        finally:
            logger.info("=" * 50)

# ==============================================================================
#           >>> ã€æ–°å¢ã€‘åœ–è¡¨æª”æ¡ˆæœå‹™è·¯ç”± <<<
# ==============================================================================

@app.route('/charts/<path:filename>')
def serve_chart(filename):

    return send_from_directory('charts', filename)

# ==============================================================================
# >>> Flask App å•Ÿå‹•å€å¡Š (æ•´åˆç‰ˆ) <<<
# ==============================================================================

if __name__ == '__main__':
    # ç¢ºä¿å¿…è¦ç›®éŒ„å­˜åœ¨
    os.makedirs('templates', exist_ok=True)
    os.makedirs('charts', exist_ok=True)
    os.makedirs('static/charts', exist_ok=True)
    
    # å»ºç«‹ç°¡å–®çš„æ¨¡æ¿æ–‡ä»¶ä»¥å… Flask å ±éŒ¯
    if not os.path.exists('templates/index.html'):
        with open('templates/index.html', 'w', encoding='utf-8') as f:
            f.write("""<!DOCTYPE html>
<html>
<head><title>Market Analysis Platform</title></head>
<body><h1>å¸‚å ´åˆ†æå¹³å°é‹è¡Œä¸­</h1></body>
</html>""")
    
       # ã€æ–°å¢ç¨‹å¼ç¢¼ STARTã€‘
    # --- å•Ÿå‹•æˆ‘å€‘çš„èƒŒæ™¯å·¥ä½œåŸ·è¡Œç·’ ---
    # å°‡åŸ·è¡Œç·’è¨­å®šç‚º daemon=Trueï¼Œé€™æ¨£ç•¶ä¸»ç¨‹å¼ (Flask app) çµæŸæ™‚ï¼Œ
    # é€™å€‹èƒŒæ™¯åŸ·è¡Œç·’ä¹Ÿæœƒè‡ªå‹•è·Ÿè‘—é—œé–‰ï¼Œä¸æœƒå¡ä½ã€‚
    logger.info("âš™ï¸ æ­£åœ¨å•Ÿå‹•èƒŒæ™¯è¨“ç·´å·¥ä½œåŸ·è¡Œç·’...")
    worker_thread = threading.Thread(target=training_worker_function, daemon=True)
    worker_thread.start()
    # ã€æ–°å¢ç¨‹å¼ç¢¼ ENDã€‘

    # è¨­å®šä¸¦å•Ÿå‹•æ’ç¨‹å™¨
    logger.info("âš™ï¸ æ­£åœ¨è¨­å®šæ’ç¨‹å™¨...")
    scheduler = BackgroundScheduler(timezone=pytz.timezone('Asia/Taipei'))
    
    if ENGINES_IMPORTED:
        # æ–°å¢ä»»å‹™ï¼šæ¯æ—¥å›æ¸¬
        scheduler.add_job(
            func=run_scheduled_backtest,
            trigger='cron',
            hour=21,
            minute=35,
            id='daily_backtest_job',
            name='æ¯æ—¥å°ç£æ™‚é–“ 17:30 åŸ·è¡Œç­–ç•¥å›æ¸¬',
            replace_existing=True
        )
        logger.info("âœ… å·²è¨­å®šæ¯æ—¥ç­–ç•¥å›æ¸¬æ’ç¨‹ (17:30)ã€‚")
        scheduler.add_job(
            func=run_scheduled_backtest,
            trigger='cron',
            hour=12,
            minute=0,
            id='daily_backtest_job',
            name='æ¯æ—¥å°ç£æ™‚é–“ 09:30 åŸ·è¡Œç­–ç•¥å›æ¸¬',
            replace_existing=True
        )
        logger.info("âœ… å·²è¨­å®šæ¯æ—¥ç­–ç•¥å›æ¸¬æ’ç¨‹ (17:30)ã€‚")
        scheduler.add_job(
            func=run_scheduled_backtest,
            trigger='cron',
            hour=22,
            minute=30,
            id='daily_backtest_job',
            name='æ¯æ—¥å°ç£æ™‚é–“ 22:00 åŸ·è¡Œç­–ç•¥å›æ¸¬',
            replace_existing=True
        )
        logger.info("âœ… å·²è¨­å®šæ¯æ—¥ç­–ç•¥å›æ¸¬æ’ç¨‹ (17:30)ã€‚")
    else:
        logger.warning("âš ï¸ ç”±æ–¼æ¨¡çµ„å°å…¥å¤±æ•—ï¼Œæ¯æ—¥è‡ªå‹•å›æ¸¬åŠŸèƒ½å·²åœç”¨ã€‚")
        

  # ==============================================================================
        #           >>> ã€æ­¥é©Ÿ 3: è¨»å†Šæ–°çš„æ’ç¨‹ä»»å‹™ã€‘ <<<
        # ==============================================================================
    scheduler.add_job(
        func=run_user_strategies_scan, # <--- å‘¼å«æˆ‘å€‘çš„æ–°å‡½å¼
        trigger='cron', hour=11, minute=0, # <--- éŒ¯é–‹æ™‚é–“åŸ·è¡Œ
        id='daily_user_strategy_scan_job', # <--- çµ¦å®ƒä¸€å€‹æ–°çš„å”¯ä¸€ ID
        name='æ¯æ—¥å°ç£æ™‚é–“ 11:00 æƒæä½¿ç”¨è€…ç­–ç•¥',
        replace_existing=True
        )
    logger.info("âœ… å·²è¨­å®šæ¯æ—¥ä½¿ç”¨è€…ç­–ç•¥æƒææ’ç¨‹ (11:00)ã€‚")
    scheduler.add_job(
        func=run_user_strategies_scan, # <--- å‘¼å«æˆ‘å€‘çš„æ–°å‡½å¼
        trigger='cron', hour=17, minute=30, # <--- éŒ¯é–‹æ™‚é–“åŸ·è¡Œ
        id='daily_user_strategy_scan_job', # <--- çµ¦å®ƒä¸€å€‹æ–°çš„å”¯ä¸€ ID
        name='æ¯æ—¥å°ç£æ™‚é–“ 17:30 æƒæä½¿ç”¨è€…ç­–ç•¥',
        replace_existing=True
        )
    logger.info("âœ… å·²è¨­å®šæ¯æ—¥ä½¿ç”¨è€…ç­–ç•¥æƒææ’ç¨‹ (17:30)ã€‚")
    scheduler.add_job(
        func=run_user_strategies_scan, # <--- å‘¼å«æˆ‘å€‘çš„æ–°å‡½å¼
        trigger='cron', hour=22, minute=0, # <--- éŒ¯é–‹æ™‚é–“åŸ·è¡Œ
        id='daily_user_strategy_scan_job', # <--- çµ¦å®ƒä¸€å€‹æ–°çš„å”¯ä¸€ ID
        name='æ¯æ—¥å°ç£æ™‚é–“ 22:00 æƒæä½¿ç”¨è€…ç­–ç•¥',
        replace_existing=True
        )
    logger.info("âœ… å·²è¨­å®šæ¯æ—¥ä½¿ç”¨è€…ç­–ç•¥æƒææ’ç¨‹ (22:00)ã€‚")
        # ==============================================================================
   
    # å•Ÿå‹•æ’ç¨‹å™¨
    scheduler.start()
    logger.info("ğŸš€ æ’ç¨‹å™¨å·²å•Ÿå‹•ã€‚")
    
    
    atexit.register(lambda: scheduler.shutdown())
    
    logger.info("ğŸš€ å•Ÿå‹•æ•´åˆç‰ˆ AI ç­–ç•¥åˆ†æèˆ‡å¸‚å ´åˆ†æå¹³å°...")
    logger.info("ğŸ“Š ç­–ç•¥è¨“ç·´å¹³å°è¨ªå•: http://localhost:5001/trainer")
    logger.info("ğŸ“ˆ å¸‚å ´åˆ†æå¹³å°è¨ªå•: http://localhost:5001/")

    app.run(debug=False, host='0.0.0.0', port=5001)
